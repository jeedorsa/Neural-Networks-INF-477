{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  <center> PREDICCIÓN DE ENTALPÍA DE ATOMIZACIÓN <br><img src=\"http://www.exalumnos.usm.cl/wp-content/uploads/2015/06/MARCA-Color.jpg\" title=\"Title text\" width=\"20%\" height=\"15%\" /><br>Andrea Carolina Reales Villalba -- Jesus Eduardo Ortiz Sandoval <BR>Punto 1 </center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify><b>\n",
    "a) Construya un <font color=RED><b>Dataframe</b></font> con los datos a analizar y descríbalo brevemete. Además, realice la división de éste en los conjuntos de entrenamiento, validación y testeo correspondientes. Comente por qué se deben eliminar ciertas columnas.</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.optimizers import SGD, Adam, RMSprop, Adagrad, Adadelta\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD\n",
    "from keras import regularizers\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify>\n",
    "Se ha decidido en la primera celda inicializar todas las librerías que se van a utilizar en el notebook,  a diferencia de que en el enunciado se llamaban individualmente en cada celda, esto se diseño para poder tener un mayor control y solo con la ejecución de esta celda poder trabajar paralalelamente las celdas sin necesidad de correr todo el notebook.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 16242 entries, 0 to 16241\n",
      "Columns: 1278 entries, Unnamed: 0 to Eat\n",
      "dtypes: float64(1276), int64(2)\n",
      "memory usage: 158.4 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>1267</th>\n",
       "      <th>1268</th>\n",
       "      <th>1269</th>\n",
       "      <th>1270</th>\n",
       "      <th>1271</th>\n",
       "      <th>1272</th>\n",
       "      <th>1273</th>\n",
       "      <th>1274</th>\n",
       "      <th>pubchem_id</th>\n",
       "      <th>Eat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>8139.041805</td>\n",
       "      <td>115.715266</td>\n",
       "      <td>22.445723</td>\n",
       "      <td>20.474191</td>\n",
       "      <td>18.529573</td>\n",
       "      <td>17.169350</td>\n",
       "      <td>15.816888</td>\n",
       "      <td>15.133152</td>\n",
       "      <td>14.471534</td>\n",
       "      <td>13.960759</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>33107.484300</td>\n",
       "      <td>-11.178969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4698.182820</td>\n",
       "      <td>113.198503</td>\n",
       "      <td>8.659586</td>\n",
       "      <td>7.670481</td>\n",
       "      <td>6.485777</td>\n",
       "      <td>5.512560</td>\n",
       "      <td>4.179691</td>\n",
       "      <td>3.885091</td>\n",
       "      <td>3.503075</td>\n",
       "      <td>3.357136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.043869</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.032755</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.024472</td>\n",
       "      <td>23456.785147</td>\n",
       "      <td>3.659133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>36.858105</td>\n",
       "      <td>2.906146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-23.245373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4068.250000</td>\n",
       "      <td>73.516695</td>\n",
       "      <td>17.969345</td>\n",
       "      <td>16.228071</td>\n",
       "      <td>15.165862</td>\n",
       "      <td>13.744092</td>\n",
       "      <td>13.653146</td>\n",
       "      <td>13.637784</td>\n",
       "      <td>12.759519</td>\n",
       "      <td>12.587359</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12298.250000</td>\n",
       "      <td>-13.475805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>8142.500000</td>\n",
       "      <td>73.516695</td>\n",
       "      <td>20.662511</td>\n",
       "      <td>18.631287</td>\n",
       "      <td>17.690729</td>\n",
       "      <td>16.020040</td>\n",
       "      <td>15.156646</td>\n",
       "      <td>13.848274</td>\n",
       "      <td>13.659233</td>\n",
       "      <td>13.652832</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27731.500000</td>\n",
       "      <td>-10.835211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>12207.750000</td>\n",
       "      <td>73.516695</td>\n",
       "      <td>21.132432</td>\n",
       "      <td>20.739496</td>\n",
       "      <td>18.712895</td>\n",
       "      <td>18.297501</td>\n",
       "      <td>17.639688</td>\n",
       "      <td>16.154918</td>\n",
       "      <td>15.499474</td>\n",
       "      <td>14.900585</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>55020.750000</td>\n",
       "      <td>-8.623903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>16272.000000</td>\n",
       "      <td>388.023441</td>\n",
       "      <td>73.563510</td>\n",
       "      <td>66.269180</td>\n",
       "      <td>66.268891</td>\n",
       "      <td>66.268756</td>\n",
       "      <td>66.268196</td>\n",
       "      <td>66.264158</td>\n",
       "      <td>66.258487</td>\n",
       "      <td>66.258177</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062225</td>\n",
       "      <td>0.061999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.061534</td>\n",
       "      <td>0.059760</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.057834</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>74980.000000</td>\n",
       "      <td>-0.789513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1278 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0             0             1             2             3  \\\n",
       "count  16242.000000  16242.000000  16242.000000  16242.000000  16242.000000   \n",
       "mean    8139.041805    115.715266     22.445723     20.474191     18.529573   \n",
       "std     4698.182820    113.198503      8.659586      7.670481      6.485777   \n",
       "min        0.000000     36.858105      2.906146      0.000000      0.000000   \n",
       "25%     4068.250000     73.516695     17.969345     16.228071     15.165862   \n",
       "50%     8142.500000     73.516695     20.662511     18.631287     17.690729   \n",
       "75%    12207.750000     73.516695     21.132432     20.739496     18.712895   \n",
       "max    16272.000000    388.023441     73.563510     66.269180     66.268891   \n",
       "\n",
       "                  4             5             6             7             8  \\\n",
       "count  16242.000000  16242.000000  16242.000000  16242.000000  16242.000000   \n",
       "mean      17.169350     15.816888     15.133152     14.471534     13.960759   \n",
       "std        5.512560      4.179691      3.885091      3.503075      3.357136   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       13.744092     13.653146     13.637784     12.759519     12.587359   \n",
       "50%       16.020040     15.156646     13.848274     13.659233     13.652832   \n",
       "75%       18.297501     17.639688     16.154918     15.499474     14.900585   \n",
       "max       66.268756     66.268196     66.264158     66.258487     66.258177   \n",
       "\n",
       "           ...               1267          1268          1269          1270  \\\n",
       "count      ...       16242.000000  16242.000000  16242.000000  16242.000000   \n",
       "mean       ...           0.000134      0.000133      0.003879      0.000131   \n",
       "std        ...           0.002728      0.002705      0.043869      0.002676   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "max        ...           0.062225      0.061999      0.500000      0.061534   \n",
       "\n",
       "               1271          1272          1273          1274    pubchem_id  \\\n",
       "count  16242.000000  16242.000000  16242.000000  16242.000000  16242.000000   \n",
       "mean       0.000129      0.002155      0.000127      0.001201  33107.484300   \n",
       "std        0.002633      0.032755      0.002594      0.024472  23456.785147   \n",
       "min        0.000000      0.000000      0.000000      0.000000      1.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000  12298.250000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000  27731.500000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000  55020.750000   \n",
       "max        0.059760      0.500000      0.057834      0.500000  74980.000000   \n",
       "\n",
       "                Eat  \n",
       "count  16242.000000  \n",
       "mean     -11.178969  \n",
       "std        3.659133  \n",
       "min      -23.245373  \n",
       "25%      -13.475805  \n",
       "50%      -10.835211  \n",
       "75%       -8.623903  \n",
       "max       -0.789513  \n",
       "\n",
       "[8 rows x 1278 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos= pd.read_csv(\"C:/Users/Jesus/Documents/GitHub/roboBohr.csv\")\n",
    "datos.shape\n",
    "datos.info()\n",
    "datos.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify>\n",
    "    Se puede analizar que en este <font color=\"red\"><B>DATAFRAME</b></font> encontramos dos columnas con un comportamiento muy disperso respecto a las demás, <font color=\"blue\"><b>unnamed:0</b> </font> y <font color=\"blue\"><b>Pubchem_id</b></font> si llevaramos este dataframe a entrenamiento la dispersión en estas columnas muy seguramente causarían que nuestro modelo no convergiera, por este motivo es mejor eliminarlos del dataframe.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1266</th>\n",
       "      <th>1267</th>\n",
       "      <th>1268</th>\n",
       "      <th>1269</th>\n",
       "      <th>1270</th>\n",
       "      <th>1271</th>\n",
       "      <th>1272</th>\n",
       "      <th>1273</th>\n",
       "      <th>1274</th>\n",
       "      <th>Eat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "      <td>16242.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>115.715266</td>\n",
       "      <td>22.445723</td>\n",
       "      <td>20.474191</td>\n",
       "      <td>18.529573</td>\n",
       "      <td>17.169350</td>\n",
       "      <td>15.816888</td>\n",
       "      <td>15.133152</td>\n",
       "      <td>14.471534</td>\n",
       "      <td>13.960759</td>\n",
       "      <td>13.464842</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.000134</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.003879</td>\n",
       "      <td>0.000131</td>\n",
       "      <td>0.000129</td>\n",
       "      <td>0.002155</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.001201</td>\n",
       "      <td>-11.178969</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>113.198503</td>\n",
       "      <td>8.659586</td>\n",
       "      <td>7.670481</td>\n",
       "      <td>6.485777</td>\n",
       "      <td>5.512560</td>\n",
       "      <td>4.179691</td>\n",
       "      <td>3.885091</td>\n",
       "      <td>3.503075</td>\n",
       "      <td>3.357136</td>\n",
       "      <td>3.140732</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002748</td>\n",
       "      <td>0.002728</td>\n",
       "      <td>0.002705</td>\n",
       "      <td>0.043869</td>\n",
       "      <td>0.002676</td>\n",
       "      <td>0.002633</td>\n",
       "      <td>0.032755</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.024472</td>\n",
       "      <td>3.659133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>36.858105</td>\n",
       "      <td>2.906146</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-23.245373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>73.516695</td>\n",
       "      <td>17.969345</td>\n",
       "      <td>16.228071</td>\n",
       "      <td>15.165862</td>\n",
       "      <td>13.744092</td>\n",
       "      <td>13.653146</td>\n",
       "      <td>13.637784</td>\n",
       "      <td>12.759519</td>\n",
       "      <td>12.587359</td>\n",
       "      <td>12.489127</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-13.475805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>73.516695</td>\n",
       "      <td>20.662511</td>\n",
       "      <td>18.631287</td>\n",
       "      <td>17.690729</td>\n",
       "      <td>16.020040</td>\n",
       "      <td>15.156646</td>\n",
       "      <td>13.848274</td>\n",
       "      <td>13.659233</td>\n",
       "      <td>13.652832</td>\n",
       "      <td>13.648992</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-10.835211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>73.516695</td>\n",
       "      <td>21.132432</td>\n",
       "      <td>20.739496</td>\n",
       "      <td>18.712895</td>\n",
       "      <td>18.297501</td>\n",
       "      <td>17.639688</td>\n",
       "      <td>16.154918</td>\n",
       "      <td>15.499474</td>\n",
       "      <td>14.900585</td>\n",
       "      <td>13.801184</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-8.623903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>388.023441</td>\n",
       "      <td>73.563510</td>\n",
       "      <td>66.269180</td>\n",
       "      <td>66.268891</td>\n",
       "      <td>66.268756</td>\n",
       "      <td>66.268196</td>\n",
       "      <td>66.264158</td>\n",
       "      <td>66.258487</td>\n",
       "      <td>66.258177</td>\n",
       "      <td>60.365756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.062496</td>\n",
       "      <td>0.062225</td>\n",
       "      <td>0.061999</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.061534</td>\n",
       "      <td>0.059760</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.057834</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-0.789513</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1276 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  16242.000000  16242.000000  16242.000000  16242.000000  16242.000000   \n",
       "mean     115.715266     22.445723     20.474191     18.529573     17.169350   \n",
       "std      113.198503      8.659586      7.670481      6.485777      5.512560   \n",
       "min       36.858105      2.906146      0.000000      0.000000      0.000000   \n",
       "25%       73.516695     17.969345     16.228071     15.165862     13.744092   \n",
       "50%       73.516695     20.662511     18.631287     17.690729     16.020040   \n",
       "75%       73.516695     21.132432     20.739496     18.712895     18.297501   \n",
       "max      388.023441     73.563510     66.269180     66.268891     66.268756   \n",
       "\n",
       "                  5             6             7             8             9  \\\n",
       "count  16242.000000  16242.000000  16242.000000  16242.000000  16242.000000   \n",
       "mean      15.816888     15.133152     14.471534     13.960759     13.464842   \n",
       "std        4.179691      3.885091      3.503075      3.357136      3.140732   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%       13.653146     13.637784     12.759519     12.587359     12.489127   \n",
       "50%       15.156646     13.848274     13.659233     13.652832     13.648992   \n",
       "75%       17.639688     16.154918     15.499474     14.900585     13.801184   \n",
       "max       66.268196     66.264158     66.258487     66.258177     60.365756   \n",
       "\n",
       "           ...               1266          1267          1268          1269  \\\n",
       "count      ...       16242.000000  16242.000000  16242.000000  16242.000000   \n",
       "mean       ...           0.000135      0.000134      0.000133      0.003879   \n",
       "std        ...           0.002748      0.002728      0.002705      0.043869   \n",
       "min        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "25%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "50%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "75%        ...           0.000000      0.000000      0.000000      0.000000   \n",
       "max        ...           0.062496      0.062225      0.061999      0.500000   \n",
       "\n",
       "               1270          1271          1272          1273          1274  \\\n",
       "count  16242.000000  16242.000000  16242.000000  16242.000000  16242.000000   \n",
       "mean       0.000131      0.000129      0.002155      0.000127      0.001201   \n",
       "std        0.002676      0.002633      0.032755      0.002594      0.024472   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "max        0.061534      0.059760      0.500000      0.057834      0.500000   \n",
       "\n",
       "                Eat  \n",
       "count  16242.000000  \n",
       "mean     -11.178969  \n",
       "std        3.659133  \n",
       "min      -23.245373  \n",
       "25%      -13.475805  \n",
       "50%      -10.835211  \n",
       "75%       -8.623903  \n",
       "max       -0.789513  \n",
       "\n",
       "[8 rows x 1276 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos.drop(columns=['Unnamed: 0','pubchem_id'],axis=1,inplace=True)\n",
    "datos.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total muestras entrenamiento: 9745\n",
      "Total muestras validación: 4060\n",
      "Total muestras testeo: 2437\n"
     ]
    }
   ],
   "source": [
    "total=len(datos)\n",
    "df_train=datos[:int(0.6*total)]                       \n",
    "df_val=datos[int(0.6*total):int(0.85*total)]         \n",
    "df_test=datos[int(0.85*total)::]                     \n",
    "tra1=len(df_train)\n",
    "val1=len(df_val)\n",
    "test1=len(df_test)\n",
    "print('Total muestras entrenamiento: %d'%(tra1))\n",
    "print('Total muestras validación: %d'%(val1))\n",
    "print('Total muestras testeo: %d'%(test1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify>\n",
    "Para realizar la predicción de la entalpía tenemos un dataset de 16242 muestras con 1276 características cada una, distribuidas con un 60% de los datos para el <j><b>training set</j></b>, 25% para  <j><b>validation set</j></b> y  15% para el <j><b>test set</j></b>.\n",
    "</div>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify><b> a.1) Una buena práctica es la de normalizar los datos antes de trabajar con el modelo. Explique por qué se aconseja dicho preprocesamiento</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler().fit(df_train)\n",
    "X_train_scaled = pd.DataFrame(scaler.transform(df_train),columns=df_train.columns)\n",
    "X_val_scaled =  pd.DataFrame(scaler.transform(df_val),columns=df_val.columns)\n",
    "X_test_scaled =  pd.DataFrame(scaler.transform(df_test),columns=df_test.columns)\n",
    "y_train = df_train.pop('Eat').values.reshape(-1,1)\n",
    "y_val = df_val.pop('Eat').values.reshape(-1,1)\n",
    "X_train_scaled.drop(columns=['Eat'],axis=1,inplace=True)\n",
    "X_val_scaled.drop(columns=['Eat'],axis=1,inplace=True)\n",
    "X_test_scaled.drop(columns=['Eat'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify>\n",
    "    Para poder tener un buen dataset, es necesario ejecutar sobre él algunos procedimientos que nos aseguren la calidad de la información, ya sea el preprocesamiento de los datos, observar el comportamiento de las muestras, análisis de posible ruido, tamaño de las muestras, etc; esto se hace para poder garantizar la eficiencia del algoritmo de aprendizaje y obtener los resultados deseados. Cuando en un dataset se tienen muestras con un valor nominal muy alto y/o gran dispersión entre las mismas, puede ser uno de los motivos para que el arreglo neuronal no pueda converger, incluso puede que se bloquee el entrenamiento o hasta la máquina donde se está ejecutando el algoritmo, Para evitar este tipo de daño la solución es normalizar el set de datos en una escala que se considere adeacuada <b>((0,1),(-1,1))</b>, teniendo claro que no se pierde nada de información y que la forma de onda de la señal es identica a la original.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify> <b>b) Muestre en un gráfico el error cuadrático (MSE) para el conjunto de entrenamiento y de pruebas vs número de *epochs* de entrenamiento, para una red *feedforward* de 3 capas, con 256 unidades ocultas y función de activación sigmoidal. Entrene la red usando gradiente descendente estocástico con tasa de aprendizaje (learning rate) 0.01 y 250 epochs de entrenamiento, en el conjunto de entrenamiento y de validación. Comente. Si observara divergencia durante el entrenamiento, determine si esto ocurre para cada repetición del experimento.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 1.5160 - val_loss: 0.6598\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.6154 - val_loss: 0.4925\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.5100 - val_loss: 0.4267\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.4474 - val_loss: 0.4328\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.3921 - val_loss: 0.3718\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.3401 - val_loss: 0.2764\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2925 - val_loss: 0.2365\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.2506 - val_loss: 0.2257\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.2210 - val_loss: 0.2666 0.2\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.1908 - val_loss: 0.1699\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.1711 - val_loss: 0.1659\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.1513 - val_loss: 0.1542\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.1362 - val_loss: 0.1405\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.1252 - val_loss: 0.1271\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.1148 - val_loss: 0.1217\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.1055 - val_loss: 0.1148\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0992 - val_loss: 0.1154\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0918 - val_loss: 0.1046\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0865 - val_loss: 0.1244\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0823 - val_loss: 0.1316\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0775 - val_loss: 0.0964\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0756 - val_loss: 0.0860\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0723 - val_loss: 0.0799\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0709 - val_loss: 0.0818\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0673 - val_loss: 0.0836\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0646 - val_loss: 0.0720\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.0644 - val_loss: 0.0743\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.0599 - val_loss: 0.0759\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0611 - val_loss: 0.0692\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0595 - val_loss: 0.0765\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 0.0575 - val_loss: 0.0693\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.0549 - val_loss: 0.0655\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0546 - val_loss: 0.0669\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0533 - val_loss: 0.0679\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0516 - val_loss: 0.0904\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0514 - val_loss: 0.0693\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0503 - val_loss: 0.0659\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0487 - val_loss: 0.0595\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 190us/step - loss: 0.0474 - val_loss: 0.0702\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.0471 - val_loss: 0.0606\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.0472 - val_loss: 0.0635\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0465 - val_loss: 0.0579\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0443 - val_loss: 0.0618\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.0455 - val_loss: 0.0569\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0436 - val_loss: 0.0642\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0437 - val_loss: 0.0668\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 0.0426 - val_loss: 0.0725\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0428 - val_loss: 0.0587\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0423 - val_loss: 0.0580\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 3s 278us/step - loss: 0.0402 - val_loss: 0.0559\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.0398 - val_loss: 0.0655\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0389 - val_loss: 0.0546\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.0396 - val_loss: 0.0612\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0376 - val_loss: 0.0560\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.0388 - val_loss: 0.0595\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.0363 - val_loss: 0.0524\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.0368 - val_loss: 0.0546\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.0377 - val_loss: 0.0571\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.0356 - val_loss: 0.0972\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.0352 - val_loss: 0.0498\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.0344 - val_loss: 0.0590\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.0355 - val_loss: 0.0521\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 240us/step - loss: 0.0355 - val_loss: 0.0501\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.0342 - val_loss: 0.0489\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.0345 - val_loss: 0.0507\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.0324 - val_loss: 0.0495\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.0339 - val_loss: 0.0489\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.0326 - val_loss: 0.0552\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0327 - val_loss: 0.0583\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0323 - val_loss: 0.0566\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0327 - val_loss: 0.0531\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.0324 - val_loss: 0.0721\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.0307 - val_loss: 0.0752\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.0310 - val_loss: 0.0494\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.0300 - val_loss: 0.0564\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.0307 - val_loss: 0.0611\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 0.0298 - val_loss: 0.0662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0292 - val_loss: 0.0489\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0307 - val_loss: 0.0581\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0306 - val_loss: 0.0504\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0292 - val_loss: 0.0516\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0292 - val_loss: 0.0558\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0284 - val_loss: 0.0481\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0286 - val_loss: 0.0489\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0285 - val_loss: 0.0528\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0278 - val_loss: 0.0472\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0277 - val_loss: 0.0492\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0285 - val_loss: 0.0912\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0277 - val_loss: 0.0440\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0264 - val_loss: 0.0602\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0285 - val_loss: 0.0591\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0271 - val_loss: 0.0472\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.0262 - val_loss: 0.0509\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0254 - val_loss: 0.0455\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.0265 - val_loss: 0.0470\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.0257 - val_loss: 0.0470\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0260 - val_loss: 0.0587\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0251 - val_loss: 0.0462\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0252 - val_loss: 0.0447\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0252 - val_loss: 0.0479\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0254 - val_loss: 0.0469\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.0251 - val_loss: 0.0439\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0250 - val_loss: 0.0477\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0248 - val_loss: 0.0473\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0243 - val_loss: 0.0464\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0238 - val_loss: 0.0483\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0242 - val_loss: 0.0439\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0235 - val_loss: 0.0532\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0238 - val_loss: 0.0487\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0234 - val_loss: 0.0441\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.0230 - val_loss: 0.0429\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0239 - val_loss: 0.0449\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0236 - val_loss: 0.0430\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0230 - val_loss: 0.0452\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0229 - val_loss: 0.0457\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0231 - val_loss: 0.0503\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0228 - val_loss: 0.0437\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0229 - val_loss: 0.0536\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0226 - val_loss: 0.0665\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0220 - val_loss: 0.0448\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0222 - val_loss: 0.0439\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0224 - val_loss: 0.0644\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0221 - val_loss: 0.0469\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0226 - val_loss: 0.0441\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - ETA: 0s - loss: 0.023 - 2s 178us/step - loss: 0.0230 - val_loss: 0.0442\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0220 - val_loss: 0.0503\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0219 - val_loss: 0.0426\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0212 - val_loss: 0.0563\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0216 - val_loss: 0.0510\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0213 - val_loss: 0.0440\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0209 - val_loss: 0.0485\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0217 - val_loss: 0.0419\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0211 - val_loss: 0.0409\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0219 - val_loss: 0.0454\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0208 - val_loss: 0.0426\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0201 - val_loss: 0.0415\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.0204 - val_loss: 0.0527loss: 0.\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.0209 - val_loss: 0.0531\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0207 - val_loss: 0.0482\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0198 - val_loss: 0.0494\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.0207 - val_loss: 0.0427\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.0200 - val_loss: 0.0404\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0199 - val_loss: 0.0414\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0198 - val_loss: 0.0435\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0204 - val_loss: 0.0423\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0205 - val_loss: 0.0502\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0203 - val_loss: 0.0477\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0199 - val_loss: 0.0497\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0199 - val_loss: 0.0435\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0199 - val_loss: 0.0444\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0195 - val_loss: 0.0416\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.0199 - val_loss: 0.0453\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.0190 - val_loss: 0.0467s: \n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.0195 - val_loss: 0.0406\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 4s 365us/step - loss: 0.0196 - val_loss: 0.0448\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 3s 323us/step - loss: 0.0192 - val_loss: 0.0415\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 4s 395us/step - loss: 0.0188 - val_loss: 0.0469 ETA: 3s - ETA:\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.0189 - val_loss: 0.0441\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0191 - val_loss: 0.0411\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0188 - val_loss: 0.0401\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.0188 - val_loss: 0.0407\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0183 - val_loss: 0.0426\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0189 - val_loss: 0.0736\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0190 - val_loss: 0.0398\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0188 - val_loss: 0.0458\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0182 - val_loss: 0.0414\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0183 - val_loss: 0.0414\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0189 - val_loss: 0.0397\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0185 - val_loss: 0.0436\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0186 - val_loss: 0.0468\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0188 - val_loss: 0.0508\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0183 - val_loss: 0.0485\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0177 - val_loss: 0.0442\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0177 - val_loss: 0.0477\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0180 - val_loss: 0.0471\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0180 - val_loss: 0.0405\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0182 - val_loss: 0.0494\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0180 - val_loss: 0.0407\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0182 - val_loss: 0.0397\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0178 - val_loss: 0.0429\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0178 - val_loss: 0.0428\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0168 - val_loss: 0.0395\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0174 - val_loss: 0.0435\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0178 - val_loss: 0.0430\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0174 - val_loss: 0.0500\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0173 - val_loss: 0.0432\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0170 - val_loss: 0.0653\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0177 - val_loss: 0.0404\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0173 - val_loss: 0.0414\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0176 - val_loss: 0.0476\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0171 - val_loss: 0.0415\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0165 - val_loss: 0.0391\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0167 - val_loss: 0.0417\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0164 - val_loss: 0.0449\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0172 - val_loss: 0.0392\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0167 - val_loss: 0.0420\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.0174 - val_loss: 0.0411\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0169 - val_loss: 0.0382\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0168 - val_loss: 0.0410\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0165 - val_loss: 0.0470\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0160 - val_loss: 0.0436\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0165 - val_loss: 0.0422\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0163 - val_loss: 0.0403\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0164 - val_loss: 0.0416\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0163 - val_loss: 0.0382\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0157 - val_loss: 0.0471\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0163 - val_loss: 0.0432\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0157 - val_loss: 0.0407\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0164 - val_loss: 0.0391\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0159 - val_loss: 0.0490\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0161 - val_loss: 0.0387\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0161 - val_loss: 0.0455\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0163 - val_loss: 0.0386\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0169 - val_loss: 0.0388\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0163 - val_loss: 0.0412\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0165 - val_loss: 0.0378\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0162 - val_loss: 0.0431\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0158 - val_loss: 0.0412\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0153 - val_loss: 0.0744\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0157 - val_loss: 0.0390\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0157 - val_loss: 0.0383\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0161 - val_loss: 0.0426\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0156 - val_loss: 0.0484\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0155 - val_loss: 0.0382\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0163 - val_loss: 0.0376\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0153 - val_loss: 0.0446\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0156 - val_loss: 0.0378\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0151 - val_loss: 0.0396\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0158 - val_loss: 0.0386\n",
      "Epoch 230/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0153 - val_loss: 0.0373\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0150 - val_loss: 0.0417\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0152 - val_loss: 0.0381\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0151 - val_loss: 0.0372\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0147 - val_loss: 0.0378\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0154 - val_loss: 0.0371\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0160 - val_loss: 0.0469\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0150 - val_loss: 0.0377\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0154 - val_loss: 0.0380\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0147 - val_loss: 0.0388\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0142 - val_loss: 0.0382\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0146 - val_loss: 0.0407\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0150 - val_loss: 0.0382\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0150 - val_loss: 0.0386\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0150 - val_loss: 0.0400\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0146 - val_loss: 0.0379\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0145 - val_loss: 0.0377\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.0152 - val_loss: 0.0468\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0150 - val_loss: 0.0365\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0146 - val_loss: 0.0372\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0146 - val_loss: 0.0404\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "model.compile(optimizer=SGD(lr=0.01),loss='mean_squared_error')\n",
    "history = model.fit(X_train_scaled, y_train, epochs=250, verbose=1, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1,figsize=(12,8))\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('RED NEURONAL CON FUNCIÓN DE ACTIVACIÓN SIGMOIDE')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify>Durante el entrenamiento no tuvimos problema, desde el primer intento mostró converger rápidamente a un valor de error pequeño, en la grafica observamos que la función de pérdida de validación que se grafica de color <font color=blue><b>AZUL</b></font> tiene muchas variaciones con poca magnitud que nos permiten deducir que aunque tiene buen comportamiento no muestra el mismo error de la señal <font color=orange><b> NARANJA</b></font> que representa la función de perdida en el entrenamiento.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify><b>c) Repita el paso anterior, utilizado ReLU como función de activación y compare con lo obtenido en b).</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 3s 319us/step - loss: 9.7783 - val_loss: 3.4933\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 2.0130 - val_loss: 1.8270\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.7881 - val_loss: 1.8616\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 4s 381us/step - loss: 0.6961 - val_loss: 1.4928\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 4s 380us/step - loss: 0.7280 - val_loss: 1.2428\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 3s 314us/step - loss: 0.4989 - val_loss: 1.5811\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 3s 332us/step - loss: 0.4899 - val_loss: 1.0598\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 3s 301us/step - loss: 0.4602 - val_loss: 1.0211\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 3s 321us/step - loss: 0.3752 - val_loss: 1.0599\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 3s 300us/step - loss: 0.3886 - val_loss: 0.8703\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 3s 275us/step - loss: 0.3050 - val_loss: 0.8740\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 3s 295us/step - loss: 0.2445 - val_loss: 0.8882\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 3s 289us/step - loss: 0.2232 - val_loss: 0.7171\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.2144 - val_loss: 0.8123\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 0.2220 - val_loss: 0.7455\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.1785 - val_loss: 0.7002\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.1852 - val_loss: 0.6365\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.2009 - val_loss: 0.6606\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.1686 - val_loss: 0.6070\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.1595 - val_loss: 0.8394\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.1629 - val_loss: 0.5895\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.1692 - val_loss: 0.7863\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.1355 - val_loss: 0.5715\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.1320 - val_loss: 0.5927\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.1221 - val_loss: 0.6102\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.1191 - val_loss: 0.5568\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1136 - val_loss: 0.5858\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.1143 - val_loss: 0.5504\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.1111 - val_loss: 0.7116\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.1063 - val_loss: 0.6385\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.1048 - val_loss: 0.5467\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.1056 - val_loss: 0.5623\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.1017 - val_loss: 0.5149\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.1045 - val_loss: 0.5376\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.0975 - val_loss: 0.5438\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.1016 - val_loss: 0.6364\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.0960 - val_loss: 0.5365\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0899 - val_loss: 0.5476\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.0860 - val_loss: 0.4741\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0845 - val_loss: 0.5057\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.0894 - val_loss: 0.4895\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.0827 - val_loss: 0.4550\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0817 - val_loss: 0.4791\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0810 - val_loss: 0.4987\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.0766 - val_loss: 0.4529\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.0885 - val_loss: 0.4959\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.0819 - val_loss: 0.4756\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.0704 - val_loss: 0.4413\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0678 - val_loss: 0.4666\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.0714 - val_loss: 0.4605\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.0676 - val_loss: 0.5588\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.0645 - val_loss: 0.4398\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0661 - val_loss: 0.4669\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.0815 - val_loss: 0.4672\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0647 - val_loss: 0.4417\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0603 - val_loss: 0.4388\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0619 - val_loss: 0.4358\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.0589 - val_loss: 0.4772\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.0571 - val_loss: 0.4394\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 0.0604 - val_loss: 0.4818\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0647 - val_loss: 0.4395\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0621 - val_loss: 0.3978\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.0691 - val_loss: 0.4615\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.0560 - val_loss: 0.5183\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.0571 - val_loss: 0.4542\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.0577 - val_loss: 0.4479\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.0630 - val_loss: 0.4231\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.0558 - val_loss: 0.4220\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.0564 - val_loss: 0.4233\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.0518 - val_loss: 0.3879\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 3s 274us/step - loss: 0.0531 - val_loss: 0.4296\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0652 - val_loss: 0.3944\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.0632 - val_loss: 0.4522\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.0739 - val_loss: 0.5206\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.1723 - val_loss: 0.3986\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.1123 - val_loss: 0.4539\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.0534 - val_loss: 0.3966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.0549 - val_loss: 0.3836\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.0643 - val_loss: 0.3871\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.0543 - val_loss: 0.4071\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.0495 - val_loss: 0.3964\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.0529 - val_loss: 0.4166\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.0579 - val_loss: 0.4148\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.0524 - val_loss: 0.4312\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.0500 - val_loss: 0.4504\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.0472 - val_loss: 0.3810\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.0449 - val_loss: 0.4552\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.0541 - val_loss: 0.3749\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.0459 - val_loss: 0.3721\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.0432 - val_loss: 0.3968\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 0.0441 - val_loss: 0.3936\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.0460 - val_loss: 0.4397\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.0429 - val_loss: 0.3907\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.0434 - val_loss: 0.3772\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.0441 - val_loss: 0.4039\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.0411 - val_loss: 0.4039\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0406 - val_loss: 0.3892\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.0397 - val_loss: 0.3959\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.0402 - val_loss: 0.4212\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.0409 - val_loss: 0.4115\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.0401 - val_loss: 0.4167\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.0387 - val_loss: 0.3929\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.0383 - val_loss: 0.4053\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.0409 - val_loss: 0.3937\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0436 - val_loss: 0.4160\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.0393 - val_loss: 0.4146\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.0385 - val_loss: 0.3901\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0376 - val_loss: 0.3878\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0372 - val_loss: 0.4306\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.0451 - val_loss: 0.3979\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.0411 - val_loss: 0.4066\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.0395 - val_loss: 0.3911\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 0.0363 - val_loss: 0.4141\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0374 - val_loss: 0.3930\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.0362 - val_loss: 0.4136\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0354 - val_loss: 0.4439\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0362 - val_loss: 0.4053\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0359 - val_loss: 0.4060\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0361 - val_loss: 0.4109\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0381 - val_loss: 0.4063\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.0358 - val_loss: 0.4136\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0332 - val_loss: 0.4062\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0351 - val_loss: 0.4163\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0391 - val_loss: 0.4781\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0341 - val_loss: 0.4043\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0337 - val_loss: 0.4066\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0349 - val_loss: 0.4030\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0342 - val_loss: 0.4231\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0368 - val_loss: 0.4038\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0329 - val_loss: 0.3952\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0317 - val_loss: 0.4250\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0315 - val_loss: 0.4015\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.0312 - val_loss: 0.4193\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.0306 - val_loss: 0.4366\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0324 - val_loss: 0.4366\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0312 - val_loss: 0.3958\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.0411 - val_loss: 0.4222\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.0335 - val_loss: 0.4075\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0306 - val_loss: 0.4163\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0313 - val_loss: 0.4508\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.0316 - val_loss: 0.4301\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.0317 - val_loss: 0.4243\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.0295 - val_loss: 0.4168\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.0312 - val_loss: 0.4357\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0343 - val_loss: 0.4072\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.0314 - val_loss: 0.4105\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.0393 - val_loss: 0.4103\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0408 - val_loss: 0.4191\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0298 - val_loss: 0.4168\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0300 - val_loss: 0.4078\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.0337 - val_loss: 0.4243\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0293 - val_loss: 0.4176\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0301 - val_loss: 0.5278\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.0302 - val_loss: 0.4217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0276 - val_loss: 0.4326\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.0306 - val_loss: 0.4167\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0285 - val_loss: 0.4238\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0288 - val_loss: 0.4069\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.0288 - val_loss: 0.4174\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0292 - val_loss: 0.4308\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0293 - val_loss: 0.4470\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0391 - val_loss: 0.4182\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0500 - val_loss: 0.4648\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0295 - val_loss: 0.4215\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0299 - val_loss: 0.4145\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0274 - val_loss: 0.4296\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.0299 - val_loss: 0.4431\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0310 - val_loss: 0.4068\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.0291 - val_loss: 0.4526\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0291 - val_loss: 0.4557\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.0273 - val_loss: 0.4139\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0313 - val_loss: 0.5118\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.0306 - val_loss: 0.4270\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.0268 - val_loss: 0.4184\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.0269 - val_loss: 0.4414\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.0254 - val_loss: 0.4071\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0286 - val_loss: 0.4376\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 0.0272 - val_loss: 0.4181\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0252 - val_loss: 0.4387\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.0264 - val_loss: 0.4257\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.0254 - val_loss: 0.4202\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0261 - val_loss: 0.4350\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0262 - val_loss: 0.4316\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0261 - val_loss: 0.4840\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0266 - val_loss: 0.4393\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.0357 - val_loss: 0.4490\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.0284 - val_loss: 0.4202\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0256 - val_loss: 0.4469\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 0.0259 - val_loss: 0.4340\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.0251 - val_loss: 0.4352\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.0255 - val_loss: 0.4495\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.0241 - val_loss: 0.4356\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.0247 - val_loss: 0.4277\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 240us/step - loss: 0.0250 - val_loss: 0.4254\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.0246 - val_loss: 0.5108\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.0250 - val_loss: 0.4395\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.0250 - val_loss: 0.4277\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.0238 - val_loss: 0.4360\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.0238 - val_loss: 0.4348\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.0239 - val_loss: 0.4332\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0238 - val_loss: 0.4177\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0260 - val_loss: 0.4298\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.0262 - val_loss: 0.4642\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.0261 - val_loss: 0.4139\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0228 - val_loss: 0.4564\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.0248 - val_loss: 0.4262\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0240 - val_loss: 0.4811\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.0230 - val_loss: 0.4355\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0241 - val_loss: 0.4288\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0235 - val_loss: 0.4439\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0245 - val_loss: 0.4347\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0255 - val_loss: 0.4576\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0220 - val_loss: 0.4351\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0241 - val_loss: 0.4550\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0258 - val_loss: 0.4622\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0234 - val_loss: 0.4786\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0231 - val_loss: 0.4476\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0236 - val_loss: 0.4485\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0225 - val_loss: 0.4311\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0226 - val_loss: 0.4344\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0238 - val_loss: 0.4643\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0213 - val_loss: 0.4441\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.0235 - val_loss: 0.4641\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.0224 - val_loss: 0.4532\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0222 - val_loss: 0.4214\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0221 - val_loss: 0.4751\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0214 - val_loss: 0.4411\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0248 - val_loss: 0.4396\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0215 - val_loss: 0.4434\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.0239 - val_loss: 0.4365\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.0257 - val_loss: 0.4639\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.0216 - val_loss: 0.4525\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0232 - val_loss: 0.4490\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0244 - val_loss: 0.4337\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0233 - val_loss: 0.4815\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 0.0321 - val_loss: 0.4492\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.0263 - val_loss: 0.4686\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0298 - val_loss: 0.4786\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.0241 - val_loss: 0.4486\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0213 - val_loss: 0.4480\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.0226 - val_loss: 0.4764\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0224 - val_loss: 0.4465\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.0240 - val_loss: 0.4637\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0281 - val_loss: 0.4432\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.0325 - val_loss: 0.4752\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0260 - val_loss: 0.4553\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0216 - val_loss: 0.4670\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.0211 - val_loss: 0.4572\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.0226 - val_loss: 0.4472\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0206 - val_loss: 0.4449\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "model.compile(optimizer=SGD(lr=0.001),loss='mean_squared_error')\n",
    "history = model.fit(X_train_scaled, y_train, epochs=250, verbose=1, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(1,figsize=(12,8))\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.plot(history.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('RED NEURONAL CON FUNCIÓN DE ACTIVACIÓN RELU')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify>El tiempo de ejecución de cada algoritmo es de 7 minutos con 24 segundos, en este caso, cuando mantuvimos el <b>\"lr\"</b> con el mismo valor del modelo anterior obteniamos en las funciones de pérdidas todos valores <font color=red><b>NaN</b></font>. Tuvimos que reajustar ese valor a 0.001 para obtener un resultado positivo. En este caso comparandolo con el modelo que tiene activación sigmoidal hay un valor de pérdida superior con respecto a la función de pérdida del  entrenamiento, se obtiene además las mismas variaciones en la forma de onda pero con magnitud superior, esto era señal de que en un punto determinado no encontraba los valores minimos globales y su error se incrementaba.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify><b>d) Repita b) y c) variando la tasa de aprendizaje (learning rate) en un rango sensible. Comente. Si observara divergencia durante el entrenamiento, determine si esto ocurre para cada repetición del experimento.</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.25490s - loss: 132.718\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549s - l\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 132.6967 - val_loss: 152.2549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 132.6967 - val_loss: 152.2549 loss: 13\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 132.6967 - val_loss: 152.25490s - loss: 131\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 132.6967 - val_loss: 152.2549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 132.6967 - val_loss: 152.2549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 132.6967 - val_loss: 152.2549\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: nan - val_loss: nan\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: nan - val_loss: nan\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: nan - val_loss: nan\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan - l\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: nan - val_loss: nan\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: nan - val_loss: nan\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: nan - val_loss: nan\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: nan - val_loss: nan\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 132/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: nan - val_loss: nan\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: nan - val_loss: nan\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: nan - val_loss: nan\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: nan - val_loss: nan\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: nan - val_loss: nan\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: nan - val_loss: nan\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: nan - val_loss: nan\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: nan - val_loss: nan\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: nan - val_loss: nan\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: nan - val_loss: nan\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: nan - val_loss: nan\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: nan - val_loss: nan\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 44/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: nan - val_loss: nan\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: nan - val_loss: nan\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: nan - val_loss: nan\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 207/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: nan - val_loss: nan\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: nan - val_loss: nan\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: nan - val_loss: nan\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: nan - val_loss: nan\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: nan - val_loss: nan\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: nan - val_loss: nan\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: nan - val_loss: nan\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 3s 277us/step - loss: nan - val_loss: nan\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: nan - val_loss: nan\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: nan - val_loss: nan\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: nan - val_loss: nan\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: nan - val_loss: nan\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: nan - val_loss: nan\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: nan - val_loss: nan\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: nan - val_loss: nan\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: nan - val_loss: nan\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: nan - val_loss: nan\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: nan - val_loss: nan\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: nan - val_loss: nan\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: nan - val_loss: nan\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: nan - val_loss: nan\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: nan - val_loss: nan\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: nan - val_loss: nan\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 201/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: nan - val_loss: nan\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: nan - val_loss: nan\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: nan - val_loss: nan\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: nan - val_loss: nan\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: nan - val_loss: nan\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: nan - val_loss: nan\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: nan - val_loss: nan\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: nan - val_loss: nan\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: nan - val_loss: nan\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: nan - val_loss: nan\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: nan - val_loss: nan\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: nan - val_loss: nan\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: nan - val_loss: nan\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: nan - val_loss: nan\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: nan - val_loss: nan\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: nan - val_loss: nan\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: nan - val_loss: nan\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: nan - val_loss: nan\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: nan - val_loss: nan\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: nan - val_loss: nan\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: nan - val_loss: nan\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: nan - val_loss: nan\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: nan - val_loss: nan\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: nan - val_loss: nan\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: nan - val_loss: nan\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: nan - val_loss: nan\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: nan - val_loss: nan\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: nan - val_loss: nan\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: nan - val_loss: nan\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: nan - val_loss: nan\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: nan - val_loss: nan\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: nan - val_loss: nan\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: nan - val_loss: nan\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: nan - val_loss: nan\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 3s 282us/step - loss: nan - val_loss: nan\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 3s 284us/step - loss: nan - val_loss: nan\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 3s 297us/step - loss: nan - val_loss: nan\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 3s 290us/step - loss: nan - val_loss: nan\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 3s 292us/step - loss: nan - val_loss: nan\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: nan - val_loss: nan\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: nan - val_loss: nan\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: nan - val_loss: nan\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: nan - val_loss: nan\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: nan - val_loss: nan\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: nan - val_loss: nan\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: nan - val_loss: nan\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: nan - val_loss: nan\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: nan - val_loss: nan\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 3s 276us/step - loss: nan - val_loss: nan\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: nan - val_loss: nan\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 3s 271us/step - loss: nan - val_loss: nan\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: nan - val_loss: nan\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: nan - val_loss: nan\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: nan - val_loss: nan\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: nan - val_loss: nan\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: nan - val_loss: nan\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 3s 274us/step - loss: nan - val_loss: nan\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: nan - val_loss: nan\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: nan - val_loss: nan\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: nan - val_loss: nan\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: nan - val_loss: nan\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: nan - val_loss: nan\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: nan - val_loss: nan\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: nan - val_loss: nan\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: nan - val_loss: nan\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: nan - val_loss: nan\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: nan - val_loss: nan\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 3s 285us/step - loss: nan - val_loss: nan\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 3s 282us/step - loss: nan - val_loss: nan\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: nan - val_loss: nan\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: nan - val_loss: nan\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: nan - val_loss: nan\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: nan - val_loss: nan\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: nan - val_loss: nan\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 3s 279us/step - loss: nan - val_loss: nan\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: nan - val_loss: nan\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 3s 271us/step - loss: nan - val_loss: nan\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 3s 309us/step - loss: nan - val_loss: nan\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 3s 301us/step - loss: nan - val_loss: nan\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 3s 282us/step - loss: nan - val_loss: nan\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: nan - val_loss: nan\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: nan - val_loss: nan\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 3s 272us/step - loss: nan - val_loss: nan\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: nan - val_loss: nan\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: nan - val_loss: nan\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: nan - val_loss: nan\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: nan - val_loss: nan\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: nan - val_loss: nan\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: nan - val_loss: nan\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 3s 281us/step - loss: nan - val_loss: nan\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: nan - val_loss: nan\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: nan - val_loss: nan\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: nan - val_loss: nan\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 3s 327us/step - loss: nan - val_loss: nan\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 4s 386us/step - loss: nan - val_loss: nan\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 3s 345us/step - loss: nan - val_loss: nan\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 3s 356us/step - loss: nan - val_loss: nan\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 4s 359us/step - loss: nan - val_loss: nan\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 3s 358us/step - loss: nan - val_loss: nan\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 3s 308us/step - loss: nan - val_loss: nan\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 3s 306us/step - loss: nan - val_loss: nan\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 3s 324us/step - loss: nan - val_loss: nan\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 3s 320us/step - loss: nan - val_loss: nan\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: nan - val_loss: nan\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: nan - val_loss: nan\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: nan - val_loss: nan\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: nan - val_loss: nan\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: nan - val_loss: nan\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 3s 297us/step - loss: nan - val_loss: nan\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 3s 271us/step - loss: nan - val_loss: nan\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: nan - val_loss: nan\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: nan - val_loss: nan\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: nan - val_loss: nan\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: nan - val_loss: nan\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: nan - val_loss: nan\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: nan - val_loss: nan\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: nan - val_loss: nan\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 195/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 224us/step - loss: nan - val_loss: nan\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: nan - val_loss: nan\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: nan - val_loss: nan\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: nan - val_loss: nan\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: nan - val_loss: nan\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: nan - val_loss: nan\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: nan - val_loss: nan\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: nan - val_loss: nan\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: nan - val_loss: nan\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: nan - val_loss: nan\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: nan - val_loss: nan\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: nan - val_loss: nan\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: nan - val_loss: nan\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: nan - val_loss: nan\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: nan - val_loss: nan\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: nan - val_loss: nan\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: nan - val_loss: nan\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: nan - val_loss: nan\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: nan - val_loss: nan\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: nan - val_loss: nan\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: nan - val_loss: nan\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: nan - val_loss: nan\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 3s 282us/step - loss: nan - val_loss: nan\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 3s 289us/step - loss: nan - val_loss: nan\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: nan - val_loss: nan\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: nan - val_loss: nan\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: nan - val_loss: nan\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: nan - val_loss: nan\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 3s 285us/step - loss: nan - val_loss: nan\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: nan - val_loss: nan\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: nan - val_loss: nan\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 3s 276us/step - loss: nan - val_loss: nan\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 3s 304us/step - loss: nan - val_loss: nan\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 3s 295us/step - loss: nan - val_loss: nan\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: nan - val_loss: nan\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: nan - val_loss: nan\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: nan - val_loss: nan\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: nan - val_loss: nan\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: nan - val_loss: nan\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: nan - val_loss: nan\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: nan - val_loss: nan\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "n_lr = 5\n",
    "lear_rate = np.linspace(0,1,n_lr)\n",
    "for i in range (0,len(lear_rate)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "    model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "    model.compile(optimizer=SGD(lr=lear_rate[i]),loss='mean_squared_error')\n",
    "    history = model.fit(X_train_scaled, y_train, epochs=250, verbose=1, validation_data=(X_val_scaled, y_val))\n",
    "    plt.figure(1,figsize=(12,8))\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.legend(('Val_Loss', 'Loss' ))\n",
    "    plt.title('RED NEURONAL CON FUNCIÓN DE ACTIVACIÓN SIGMOIDE Y LEARNING RATE VARIABLE')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epochs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify>\n",
    "    Cuando aumentamos el <b>lear rate</b> observamos que el algoritma no logra converger obteniendo como  resultado todos los valores de perdida NaN, esto nos indica que hay un punto en el que <b> learning rate</b> vuelve inutil el algoritmo, por que en lugar de generar mejor aprendizaje, encuentra valores imposibles de computar.\n",
    " </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 3s 278us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 149/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 137.8833 - val_loss: 160.3649\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 137.8833 - val_loss: 160.3649\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 137.8833 - val_loss: 160.3649\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-512ec8927034>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'uniform'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"linear\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mSGD\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlear_rate\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mean_squared_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m250\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val_scaled\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'val_loss'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'history' is not defined"
     ]
    }
   ],
   "source": [
    "n_lr = 20\n",
    "lear_rate = np.linspace(0,1,n_lr)\n",
    "for i in range (0,len(lear_rate)):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"relu\"))\n",
    "    model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "    model.compile(optimizer=SGD(lr=lear_rate[i]),loss='mean_squared_error')\n",
    "    history = model.fit(X_train_scaled, y_train, epochs=250, verbose=1, validation_data=(X_val_scaled, y_val))\n",
    "    plt.figure(1,figsize=(12,8))\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.legend(('Val_Loss', 'Loss' ))\n",
    "    plt.title('RED NEURONAL CON FUNCIÓN DE ACTIVACIÓN RELU Y LEARNING RATE VARIABLE')\n",
    "    plt.ylabel('MSE')\n",
    "    plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify>En este caso como se habia observado en el punto anterior con <b> learning rate </b> altos, el algoritmo no logra hacer los cómputos obteniedo como resultado en las funciones de pérdida valores NaN, cuando el ya comienza a converger se encuentran errores muy significativos, en este caso particular se tiene los mejores resultados con un <b> learning rate </b> muy pequeño.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify> <b>e) Entrene los modelos considerados en b) y c) usando progressive decay. Compare y comente.</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 1.5457 - val_loss: 0.8011\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.6031 - val_loss: 0.4205\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.4850 - val_loss: 0.3598\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.4090 - val_loss: 0.4440\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.3421 - val_loss: 0.2906\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.3003 - val_loss: 0.2929\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.2619 - val_loss: 0.2310\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2341 - val_loss: 0.3604\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.2074 - val_loss: 0.2275\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.1856 - val_loss: 0.1688\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1658 - val_loss: 0.1902\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.1517 - val_loss: 0.1497\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1419 - val_loss: 0.1477\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.1293 - val_loss: 0.1351\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.1177 - val_loss: 0.1486\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1088 - val_loss: 0.2181\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1027 - val_loss: 0.1059\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0970 - val_loss: 0.1119\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0898 - val_loss: 0.1104\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0865 - val_loss: 0.1722\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0834 - val_loss: 0.0918\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0782 - val_loss: 0.1170\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0763 - val_loss: 0.0892\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0725 - val_loss: 0.1106\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0689 - val_loss: 0.0984\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0689 - val_loss: 0.0931\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0667 - val_loss: 0.0896\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0630 - val_loss: 0.1063\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0627 - val_loss: 0.0853\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0599 - val_loss: 0.1136\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0598 - val_loss: 0.0810\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0585 - val_loss: 0.0688\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0569 - val_loss: 0.1022\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0549 - val_loss: 0.0763\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0540 - val_loss: 0.0676\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.0516 - val_loss: 0.0641\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0512 - val_loss: 0.0727\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0501 - val_loss: 0.0742\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0493 - val_loss: 0.0647\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0494 - val_loss: 0.0592\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0476 - val_loss: 0.0789\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0473 - val_loss: 0.0613\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0471 - val_loss: 0.0599\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0460 - val_loss: 0.0851\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0459 - val_loss: 0.0863\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0431 - val_loss: 0.0572\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0451 - val_loss: 0.0858\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0418 - val_loss: 0.0583\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0430 - val_loss: 0.0560\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0411 - val_loss: 0.0639\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0429 - val_loss: 0.0759\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0405 - val_loss: 0.0550\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0405 - val_loss: 0.0572\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0399 - val_loss: 0.0523\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0397 - val_loss: 0.0881\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0391 - val_loss: 0.0507\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0379 - val_loss: 0.0507\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0373 - val_loss: 0.0580\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0384 - val_loss: 0.0521\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0370 - val_loss: 0.0499\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0374 - val_loss: 0.0727\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0364 - val_loss: 0.0566\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0357 - val_loss: 0.0490\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0345 - val_loss: 0.0482\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0349 - val_loss: 0.0594\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0344 - val_loss: 0.0481\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0343 - val_loss: 0.0509\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0340 - val_loss: 0.0775\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0342 - val_loss: 0.0545\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0338 - val_loss: 0.0554\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0337 - val_loss: 0.0893\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0336 - val_loss: 0.0506\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0323 - val_loss: 0.0624\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0323 - val_loss: 0.0460\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0321 - val_loss: 0.0473\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0313 - val_loss: 0.0486\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0315 - val_loss: 0.0509\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0326 - val_loss: 0.0491\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0316 - val_loss: 0.0501\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0306 - val_loss: 0.0519\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0298 - val_loss: 0.0439\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0299 - val_loss: 0.0444\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0306 - val_loss: 0.0432\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0294 - val_loss: 0.0476\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0289 - val_loss: 0.0446\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0292 - val_loss: 0.0494\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0285 - val_loss: 0.0475\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0281 - val_loss: 0.0443\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0285 - val_loss: 0.0439\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.0283 - val_loss: 0.0461\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0288 - val_loss: 0.0454\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0286 - val_loss: 0.0411\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0284 - val_loss: 0.0490\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0276 - val_loss: 0.0630\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0282 - val_loss: 0.0423\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0282 - val_loss: 0.0424\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0272 - val_loss: 0.0585\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0272 - val_loss: 0.0536\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0271 - val_loss: 0.0421\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0267 - val_loss: 0.0447\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0263 - val_loss: 0.0421\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0264 - val_loss: 0.0454\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0267 - val_loss: 0.0425\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0256 - val_loss: 0.0419\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0257 - val_loss: 0.0487\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0254 - val_loss: 0.0408\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0260 - val_loss: 0.0401\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0253 - val_loss: 0.0414\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0245 - val_loss: 0.0503\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0252 - val_loss: 0.0468\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0242 - val_loss: 0.0420\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0246 - val_loss: 0.0489\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0244 - val_loss: 0.0401\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0247 - val_loss: 0.0493\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0244 - val_loss: 0.0415\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0244 - val_loss: 0.0401\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0237 - val_loss: 0.0395\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0239 - val_loss: 0.0394\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0228 - val_loss: 0.0398\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0234 - val_loss: 0.0527\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0232 - val_loss: 0.0413\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0227 - val_loss: 0.0460\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0227 - val_loss: 0.0392\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0231 - val_loss: 0.0385\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0231 - val_loss: 0.0439\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0225 - val_loss: 0.0433\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0230 - val_loss: 0.0409\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0225 - val_loss: 0.0386\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0230 - val_loss: 0.0397\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0232 - val_loss: 0.0472\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0232 - val_loss: 0.0384\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0221 - val_loss: 0.0450\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0221 - val_loss: 0.0392\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0223 - val_loss: 0.0410\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0223 - val_loss: 0.0429\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0217 - val_loss: 0.0426\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0218 - val_loss: 0.0403\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0216 - val_loss: 0.0397\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0211 - val_loss: 0.0388\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0213 - val_loss: 0.0534\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0215 - val_loss: 0.0424\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0217 - val_loss: 0.0407\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0208 - val_loss: 0.0432\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0212 - val_loss: 0.0455\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0208 - val_loss: 0.0379\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0209 - val_loss: 0.0797\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0211 - val_loss: 0.0395\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0202 - val_loss: 0.0389\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0210 - val_loss: 0.0420\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0204 - val_loss: 0.0526\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0205 - val_loss: 0.0412\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0203 - val_loss: 0.0367\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0206 - val_loss: 0.0366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0198 - val_loss: 0.0437\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0199 - val_loss: 0.0370\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0202 - val_loss: 0.0559\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0199 - val_loss: 0.0376\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0198 - val_loss: 0.0393\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0199 - val_loss: 0.0406\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0192 - val_loss: 0.0438\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0197 - val_loss: 0.0413\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0203 - val_loss: 0.0365\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0201 - val_loss: 0.0353\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0198 - val_loss: 0.0408\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0195 - val_loss: 0.0421\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0192 - val_loss: 0.0444\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0188 - val_loss: 0.0422\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0194 - val_loss: 0.0403\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0194 - val_loss: 0.0359\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0189 - val_loss: 0.0369\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0188 - val_loss: 0.0366\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0189 - val_loss: 0.0487\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0192 - val_loss: 0.0377\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0187 - val_loss: 0.0374\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0188 - val_loss: 0.0361\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0191 - val_loss: 0.0391\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0183 - val_loss: 0.0379\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0185 - val_loss: 0.0391\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0183 - val_loss: 0.0408\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0184 - val_loss: 0.0461\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0187 - val_loss: 0.0394\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0182 - val_loss: 0.0359\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0179 - val_loss: 0.0410\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0180 - val_loss: 0.0356\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0180 - val_loss: 0.0384\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0177 - val_loss: 0.0368\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0180 - val_loss: 0.0378\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0178 - val_loss: 0.0359\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0178 - val_loss: 0.0356\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0177 - val_loss: 0.0354\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0179 - val_loss: 0.0350\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0176 - val_loss: 0.0352\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0179 - val_loss: 0.0376\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0175 - val_loss: 0.0406\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0176 - val_loss: 0.0345\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0177 - val_loss: 0.0380\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0176 - val_loss: 0.0356\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0172 - val_loss: 0.0384\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0176 - val_loss: 0.0357\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0169 - val_loss: 0.0426\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0169 - val_loss: 0.0451\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0169 - val_loss: 0.0367\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0169 - val_loss: 0.0353\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0170 - val_loss: 0.0345\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0167 - val_loss: 0.0370\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0167 - val_loss: 0.0430\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0171 - val_loss: 0.0389\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0168 - val_loss: 0.0345\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.0164 - val_loss: 0.0341\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.0161 - val_loss: 0.0334\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0168 - val_loss: 0.0372\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0167 - val_loss: 0.0367\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0172 - val_loss: 0.0353\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0165 - val_loss: 0.0422\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0168 - val_loss: 0.0353\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0167 - val_loss: 0.0356\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0164 - val_loss: 0.0347\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0165 - val_loss: 0.0369\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0163 - val_loss: 0.0347\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0162 - val_loss: 0.0349\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0167 - val_loss: 0.0334\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0163 - val_loss: 0.0358\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0162 - val_loss: 0.0377\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0162 - val_loss: 0.0390\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0160 - val_loss: 0.0375\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0159 - val_loss: 0.0406\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0159 - val_loss: 0.0368\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0159 - val_loss: 0.0348\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0155 - val_loss: 0.0388\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0159 - val_loss: 0.0438\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0156 - val_loss: 0.0379\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0156 - val_loss: 0.0356\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0156 - val_loss: 0.0336\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0158 - val_loss: 0.0343\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0155 - val_loss: 0.0343\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0159 - val_loss: 0.0409\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0154 - val_loss: 0.0364\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0154 - val_loss: 0.0413\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0157 - val_loss: 0.0411\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0154 - val_loss: 0.0372\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0155 - val_loss: 0.0433\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0152 - val_loss: 0.0340\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0155 - val_loss: 0.0339\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0151 - val_loss: 0.0367\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0153 - val_loss: 0.0342\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0152 - val_loss: 0.0335\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0152 - val_loss: 0.0403\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0152 - val_loss: 0.0379\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.0154 - val_loss: 0.0376\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0152 - val_loss: 0.0367\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 8.3547 - val_loss: 2.5057\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 1.3152 - val_loss: 2.3772\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.8454 - val_loss: 1.7297\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.7069 - val_loss: 1.6691\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.5195 - val_loss: 1.7478\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.4828 - val_loss: 1.7255\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.4191 - val_loss: 1.4365\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.3613 - val_loss: 1.2274\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.3345 - val_loss: 2.0444\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.3193 - val_loss: 1.1835\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.2683 - val_loss: 1.1158\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2542 - val_loss: 1.2380\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2377 - val_loss: 1.0380\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1995 - val_loss: 1.0783\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2133 - val_loss: 0.9738\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1971 - val_loss: 1.2157\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.1810 - val_loss: 1.0546\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.1607 - val_loss: 0.9431\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1728 - val_loss: 0.9149\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1585 - val_loss: 0.9242\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1577 - val_loss: 0.9728\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1614 - val_loss: 0.9029\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1446 - val_loss: 0.9098\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1369 - val_loss: 0.8098\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1288 - val_loss: 0.9980\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1286 - val_loss: 0.8041\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1184 - val_loss: 0.8515\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1129 - val_loss: 0.7885\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1181 - val_loss: 0.8106\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1070 - val_loss: 0.7961\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1092 - val_loss: 0.7615\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1071 - val_loss: 0.8040\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.1134 - val_loss: 0.7317\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0954 - val_loss: 0.6991\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1495 - val_loss: 0.7971\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1266 - val_loss: 0.7473\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.1013 - val_loss: 0.7745\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0925 - val_loss: 0.7008\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0871 - val_loss: 0.7014\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0878 - val_loss: 0.6789\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0808 - val_loss: 0.6801\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0843 - val_loss: 0.7232\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0907 - val_loss: 0.6792\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0909 - val_loss: 0.6616\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0799 - val_loss: 0.7713\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0800 - val_loss: 0.6944\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0790 - val_loss: 0.6563\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0766 - val_loss: 0.6841\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0795 - val_loss: 0.6516\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0738 - val_loss: 0.6757\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0720 - val_loss: 0.7261\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0719 - val_loss: 0.6321\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - ETA: 0s - loss: 0.071 - 2s 180us/step - loss: 0.0717 - val_loss: 0.6198\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0732 - val_loss: 0.6189\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0670 - val_loss: 0.6910\n",
      "Epoch 56/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0727 - val_loss: 0.6424\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0902 - val_loss: 0.9023\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0810 - val_loss: 0.6382\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0681 - val_loss: 0.6534\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0639 - val_loss: 0.6367\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0645 - val_loss: 0.6502\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0642 - val_loss: 0.6401\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0602 - val_loss: 0.6188\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0596 - val_loss: 0.6373\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0584 - val_loss: 0.6232\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0592 - val_loss: 0.6162\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0565 - val_loss: 0.6083\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0624 - val_loss: 0.5862\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0569 - val_loss: 0.6129\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0686 - val_loss: 0.6378\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0528 - val_loss: 0.6182\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0531 - val_loss: 0.6517\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0514 - val_loss: 0.5839\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0502 - val_loss: 0.6059\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0570 - val_loss: 0.5730\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0589 - val_loss: 0.6286\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0512 - val_loss: 0.6305\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0508 - val_loss: 0.6244\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0517 - val_loss: 0.5778\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0488 - val_loss: 0.6822\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0479 - val_loss: 0.5839\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0477 - val_loss: 0.6129\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0548 - val_loss: 0.5954\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0496 - val_loss: 0.6874\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0463 - val_loss: 0.5648\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0460 - val_loss: 0.5695\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0472 - val_loss: 0.5862\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0470 - val_loss: 0.5856\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0460 - val_loss: 0.6128\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0457 - val_loss: 0.6695\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0493 - val_loss: 0.5800\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0601 - val_loss: 0.6094\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0486 - val_loss: 0.5776\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0476 - val_loss: 0.5866\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.0476 - val_loss: 0.7281\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0468 - val_loss: 0.5812\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0422 - val_loss: 0.5942\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0416 - val_loss: 0.5757\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0405 - val_loss: 0.5767\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0413 - val_loss: 0.5806\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0422 - val_loss: 0.5766\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0407 - val_loss: 0.6003\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0376 - val_loss: 0.5847\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0420 - val_loss: 0.5873\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0451 - val_loss: 0.6389\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0454 - val_loss: 0.6135\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0463 - val_loss: 0.6636\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0451 - val_loss: 0.6652\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0399 - val_loss: 0.5866\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0408 - val_loss: 0.6072\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0377 - val_loss: 0.5967\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0409 - val_loss: 0.6243\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0400 - val_loss: 0.5908\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0428 - val_loss: 0.6052\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0388 - val_loss: 0.6965\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0403 - val_loss: 0.5833\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0377 - val_loss: 0.5757\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0361 - val_loss: 0.5776\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0562 - val_loss: 0.5817\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0388 - val_loss: 0.6059\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0365 - val_loss: 0.6490\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0364 - val_loss: 0.6054\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0390 - val_loss: 0.5960\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0347 - val_loss: 0.6060\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0373 - val_loss: 0.5647\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0355 - val_loss: 0.6209\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0367 - val_loss: 0.5748\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0336 - val_loss: 0.6383\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0398 - val_loss: 0.6393\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0342 - val_loss: 0.6200\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0337 - val_loss: 0.5931\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0341 - val_loss: 0.5961\n",
      "Epoch 133/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0340 - val_loss: 0.6048\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0327 - val_loss: 0.5900\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0330 - val_loss: 0.5969\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0329 - val_loss: 0.5861\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0315 - val_loss: 0.5912\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0318 - val_loss: 0.6123\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0300 - val_loss: 0.5903\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0385 - val_loss: 0.5855\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0356 - val_loss: 0.6269\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0308 - val_loss: 0.5988\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0301 - val_loss: 0.6232\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0315 - val_loss: 0.6032\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0307 - val_loss: 0.5931\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0320 - val_loss: 0.6117\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0322 - val_loss: 0.5933\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0313 - val_loss: 0.5999\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0309 - val_loss: 0.6170\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0312 - val_loss: 0.6178\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0300 - val_loss: 0.6075\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0287 - val_loss: 0.5909\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0300 - val_loss: 0.5940\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.0297 - val_loss: 0.5783\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0274 - val_loss: 0.5975\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0329 - val_loss: 0.5834\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0337 - val_loss: 0.6063\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0284 - val_loss: 0.6175\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0296 - val_loss: 0.6023\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.0299 - val_loss: 0.5916\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0290 - val_loss: 0.6139\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.0324 - val_loss: 0.6030\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0318 - val_loss: 0.6217\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0369 - val_loss: 0.6073\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0323 - val_loss: 0.6085\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0298 - val_loss: 0.7445\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0378 - val_loss: 0.6406\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0344 - val_loss: 0.6001\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0376 - val_loss: 0.6353\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0367 - val_loss: 0.6313\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0335 - val_loss: 0.6158\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0356 - val_loss: 0.6279\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0282 - val_loss: 0.6138\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0285 - val_loss: 0.6541\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0270 - val_loss: 0.6446\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0270 - val_loss: 0.6203\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0300 - val_loss: 0.6174\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0358 - val_loss: 0.6103\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0271 - val_loss: 0.6646\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.0285 - val_loss: 0.6144\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0280 - val_loss: 0.6221\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0264 - val_loss: 0.6198\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0257 - val_loss: 0.6422\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0295 - val_loss: 0.6437\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0327 - val_loss: 0.6631\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0265 - val_loss: 0.6327\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0252 - val_loss: 0.6141\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0251 - val_loss: 0.6295\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0261 - val_loss: 0.6068\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0257 - val_loss: 0.6413\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0268 - val_loss: 0.6248\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0247 - val_loss: 0.6329\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0250 - val_loss: 0.8065\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0257 - val_loss: 0.6172\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0269 - val_loss: 0.6340\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0258 - val_loss: 0.6224\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0247 - val_loss: 0.6280\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0242 - val_loss: 0.6187\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0245 - val_loss: 0.6287\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0251 - val_loss: 0.6431\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0240 - val_loss: 0.6437\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0238 - val_loss: 0.6289\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0250 - val_loss: 0.6219\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0244 - val_loss: 0.6267\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0262 - val_loss: 0.6303\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0250 - val_loss: 0.6519\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0250 - val_loss: 0.6533\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0236 - val_loss: 0.6244\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0228 - val_loss: 0.6421\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0239 - val_loss: 0.6255\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0236 - val_loss: 0.6157\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0240 - val_loss: 0.6566\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0241 - val_loss: 0.6097\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0223 - val_loss: 0.6367\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0228 - val_loss: 0.6748\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0235 - val_loss: 0.6341\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0226 - val_loss: 0.6393\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0226 - val_loss: 0.6278\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0227 - val_loss: 0.6396\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0239 - val_loss: 0.6466\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0268 - val_loss: 0.6266\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0260 - val_loss: 0.6482\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0231 - val_loss: 0.6511\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0228 - val_loss: 0.6360\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0214 - val_loss: 0.6654\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.0221 - val_loss: 0.6580\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0212 - val_loss: 0.6228\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0225 - val_loss: 0.6679\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0224 - val_loss: 0.6623\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0223 - val_loss: 0.6563\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0219 - val_loss: 0.6744\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0217 - val_loss: 0.6508\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0223 - val_loss: 0.6473\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0215 - val_loss: 0.6499\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0211 - val_loss: 0.6421\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0225 - val_loss: 0.6497\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0214 - val_loss: 0.6469\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0232 - val_loss: 0.6330\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0227 - val_loss: 0.6470\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0222 - val_loss: 0.6306\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0215 - val_loss: 0.6406\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0220 - val_loss: 0.6388\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0211 - val_loss: 0.6307\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0251 - val_loss: 0.6473\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0224 - val_loss: 0.6426\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0209 - val_loss: 0.6506\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0209 - val_loss: 0.6566\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0208 - val_loss: 0.6981\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0263 - val_loss: 0.6576\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0208 - val_loss: 0.6384\n"
     ]
    }
   ],
   "source": [
    "n_decay = 10\n",
    "lear_decay = np.logspace(-6,0,n_decay)\n",
    "sgd1 = SGD(lr=0.01, decay=1e-6)\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "model.compile(optimizer=sgd1,loss='mean_squared_error')\n",
    "history_decay_sig = model.fit(X_train_scaled, y_train, epochs=250, verbose=1, validation_data=(X_val_scaled, y_val))\n",
    "n_decay = 10\n",
    "lear_decay = np.logspace(-6,0,n_decay)\n",
    "sgd2 = SGD(lr=0.001, decay=1e-6)\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "model.compile(optimizer=sgd2,loss='mean_squared_error')\n",
    "history_decay_relu = model.fit(X_train_scaled, y_train, epochs=250, verbose=1, validation_data=(X_val_scaled, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2,figsize=(16,10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history_decay_sig.history['val_loss'])\n",
    "plt.plot(history_decay_sig.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDE--DECAY')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history_decay_relu.history['val_loss'])\n",
    "plt.plot(history_decay_relu.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO RELU--DECAY')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify> En el modelo <b>Sigmoidal</b> al principio de la forma de onda de la función de pérdida se puede observar variaciones muy altas que pueden ser que no le permitan al modelo converger con menor número de iteraciones, la escala de error es bastante aceptable comparada con el modelo <b>ReLU</b> que aunque no presenta el comportamiento variante tan marcado si posee un error bastante significativo, casi 10 veces mas alto.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify><b>f) Entrene los modelos considerados en b) y c) utilizando SGD en mini-*batches*. Experimente con diferentes tamaños del batch. Comente.</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 1.7701 - val_loss: 0.6504\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.6718 - val_loss: 0.4983\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.5759 - val_loss: 0.4800\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.5234 - val_loss: 0.4244\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.4719 - val_loss: 0.3849\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.4302 - val_loss: 0.3406\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.3907 - val_loss: 0.3396\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.3562 - val_loss: 0.2937\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.3264 - val_loss: 0.2768\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2970 - val_loss: 0.2533\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.2715 - val_loss: 0.2372\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2454 - val_loss: 0.2260\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.2261 - val_loss: 0.2045\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2104 - val_loss: 0.2164\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.1949 - val_loss: 0.1812\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1790 - val_loss: 0.1747\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1660 - val_loss: 0.1616\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.1536 - val_loss: 0.1516\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1458 - val_loss: 0.1499\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.1346 - val_loss: 0.1479\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1275 - val_loss: 0.1388\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.1182 - val_loss: 0.1257\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1132 - val_loss: 0.1344\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.1050 - val_loss: 0.1219\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1026 - val_loss: 0.1192\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0992 - val_loss: 0.1396\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0944 - val_loss: 0.1079\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0895 - val_loss: 0.1042\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0872 - val_loss: 0.0964\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0857 - val_loss: 0.0936\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0808 - val_loss: 0.1061\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0778 - val_loss: 0.0924\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0755 - val_loss: 0.0989\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.0755 - val_loss: 0.0908\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0715 - val_loss: 0.0926\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.0700 - val_loss: 0.0803\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0682 - val_loss: 0.0838\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.0669 - val_loss: 0.0955\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0649 - val_loss: 0.0768\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.0646 - val_loss: 0.0797\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0626 - val_loss: 0.0777\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.0619 - val_loss: 0.0723\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.0604 - val_loss: 0.0742\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0585 - val_loss: 0.0763\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0589 - val_loss: 0.0700\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.0566 - val_loss: 0.0746\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.0558 - val_loss: 0.0678\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0553 - val_loss: 0.0699\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0540 - val_loss: 0.0722\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.0533 - val_loss: 0.0678\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.0517 - val_loss: 0.0699\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0506 - val_loss: 0.0634\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.0499 - val_loss: 0.0661\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0515 - val_loss: 0.0679\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0492 - val_loss: 0.0615\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0483 - val_loss: 0.0645\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0484 - val_loss: 0.0635\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0458 - val_loss: 0.0734\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.0461 - val_loss: 0.0593\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0470 - val_loss: 0.0644\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.0452 - val_loss: 0.0599\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0450 - val_loss: 0.0633\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.0444 - val_loss: 0.0582\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0437 - val_loss: 0.0602\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.0432 - val_loss: 0.0589\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0427 - val_loss: 0.0612\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0436 - val_loss: 0.0597\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0444 - val_loss: 0.0677\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0435 - val_loss: 0.0616\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0424 - val_loss: 0.0576\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0403 - val_loss: 0.0580\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0400 - val_loss: 0.0558\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.0399 - val_loss: 0.0588\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 0.0398 - val_loss: 0.0601\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.0385 - val_loss: 0.0630\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0383 - val_loss: 0.0555\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.0375 - val_loss: 0.0642\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 3s 277us/step - loss: 0.0384 - val_loss: 0.0547\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.0380 - val_loss: 0.0532\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.0368 - val_loss: 0.0531\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 3s 272us/step - loss: 0.0374 - val_loss: 0.0530\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.0362 - val_loss: 0.0548\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0375 - val_loss: 0.0648\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0368 - val_loss: 0.0552\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0365 - val_loss: 0.0539\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0366 - val_loss: 0.0516\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0344 - val_loss: 0.0519\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.0369 - val_loss: 0.0543\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.0349 - val_loss: 0.0533\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.0345 - val_loss: 0.0519\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.0344 - val_loss: 0.0538\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.0344 - val_loss: 0.0502\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.0341 - val_loss: 0.0505\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0335 - val_loss: 0.0500\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.0333 - val_loss: 0.0556\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0333 - val_loss: 0.0571\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0333 - val_loss: 0.0627\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0323 - val_loss: 0.0505\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.0325 - val_loss: 0.0486\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0312 - val_loss: 0.0514\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0319 - val_loss: 0.0501\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0321 - val_loss: 0.0540\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.0320 - val_loss: 0.0483\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0321 - val_loss: 0.0627\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0319 - val_loss: 0.0489\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.0311 - val_loss: 0.0555\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0309 - val_loss: 0.0513\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.0300 - val_loss: 0.0561\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0313 - val_loss: 0.0539\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.0297 - val_loss: 0.0483\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0303 - val_loss: 0.0533\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.0305 - val_loss: 0.0488\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.0298 - val_loss: 0.0481\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0303 - val_loss: 0.0499\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0295 - val_loss: 0.0486\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.0294 - val_loss: 0.0706\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.0302 - val_loss: 0.0538\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 0.0290 - val_loss: 0.0521\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.0296 - val_loss: 0.0469\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.0288 - val_loss: 0.0474\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.0295 - val_loss: 0.0460\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0292 - val_loss: 0.0496\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0278 - val_loss: 0.0486\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0283 - val_loss: 0.0461\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0272 - val_loss: 0.0488\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 190us/step - loss: 0.0287 - val_loss: 0.0452\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.0275 - val_loss: 0.0454\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.0281 - val_loss: 0.0451\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 0.0279 - val_loss: 0.0455\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.0278 - val_loss: 0.0458\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0265 - val_loss: 0.0494\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0272 - val_loss: 0.0537\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.0268 - val_loss: 0.0466\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.0263 - val_loss: 0.0536\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0267 - val_loss: 0.0666\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.0271 - val_loss: 0.0466\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0272 - val_loss: 0.0483\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0261 - val_loss: 0.0439\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.0261 - val_loss: 0.0455\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 0.0252 - val_loss: 0.0550\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0252 - val_loss: 0.0467\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0264 - val_loss: 0.0445\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0266 - val_loss: 0.0465\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.0258 - val_loss: 0.0447\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0259 - val_loss: 0.0443\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.0253 - val_loss: 0.0447\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0251 - val_loss: 0.0444\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 0.0249 - val_loss: 0.0469\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.0251 - val_loss: 0.0469\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0244 - val_loss: 0.0472\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.0244 - val_loss: 0.0457\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.0249 - val_loss: 0.0520\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0244 - val_loss: 0.0447\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.0245 - val_loss: 0.0530\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.0245 - val_loss: 0.0447\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0235 - val_loss: 0.0460\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 0.0240 - val_loss: 0.0463\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.0250 - val_loss: 0.0456\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 0.0242 - val_loss: 0.0462\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0231 - val_loss: 0.0429\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.0237 - val_loss: 0.0469\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.0241 - val_loss: 0.0482\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0242 - val_loss: 0.0458\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.0237 - val_loss: 0.0426\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0234 - val_loss: 0.0464\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0233 - val_loss: 0.0454\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0231 - val_loss: 0.0525\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0235 - val_loss: 0.0422\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0239 - val_loss: 0.0571\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.0232 - val_loss: 0.0443\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.0227 - val_loss: 0.0435\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0224 - val_loss: 0.0437\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0226 - val_loss: 0.0429\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.0225 - val_loss: 0.0453\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0224 - val_loss: 0.0425\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 190us/step - loss: 0.0232 - val_loss: 0.0469\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0232 - val_loss: 0.0488\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.0233 - val_loss: 0.0431\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0224 - val_loss: 0.0488\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.0221 - val_loss: 0.0424\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.0227 - val_loss: 0.0425\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.0223 - val_loss: 0.0412\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 0.0225 - val_loss: 0.0415\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.0225 - val_loss: 0.0420\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.0219 - val_loss: 0.0456\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 0.0217 - val_loss: 0.0427\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.0219 - val_loss: 0.0418\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.0211 - val_loss: 0.0424\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.0223 - val_loss: 0.0459\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.0220 - val_loss: 0.0438\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 257us/step - loss: 0.0214 - val_loss: 0.0423\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.0212 - val_loss: 0.0598\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.0215 - val_loss: 0.0437\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.0209 - val_loss: 0.0484\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 3s 296us/step - loss: 0.0217 - val_loss: 0.0406\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 0.0217 - val_loss: 0.0426\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 0.0210 - val_loss: 0.0458\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.0216 - val_loss: 0.0500\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0203 - val_loss: 0.0436\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0205 - val_loss: 0.0432\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.0212 - val_loss: 0.0408\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.0217 - val_loss: 0.0484\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0206 - val_loss: 0.0401\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0207 - val_loss: 0.0445\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 0.0208 - val_loss: 0.0411\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0205 - val_loss: 0.0395\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0202 - val_loss: 0.0418\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0208 - val_loss: 0.0412\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.0204 - val_loss: 0.0406\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0202 - val_loss: 0.0426\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0205 - val_loss: 0.0453\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0201 - val_loss: 0.0401\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0199 - val_loss: 0.0423\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 190us/step - loss: 0.0197 - val_loss: 0.0415\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0196 - val_loss: 0.0401\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0203 - val_loss: 0.0406\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.0195 - val_loss: 0.0407\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.0196 - val_loss: 0.0470\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.0193 - val_loss: 0.04280\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.0193 - val_loss: 0.0400\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.0196 - val_loss: 0.0387\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.0195 - val_loss: 0.0429\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.0194 - val_loss: 0.0410\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.0198 - val_loss: 0.0401\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0189 - val_loss: 0.0401\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 190us/step - loss: 0.0197 - val_loss: 0.0414\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.0202 - val_loss: 0.0390\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0192 - val_loss: 0.0401\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0192 - val_loss: 0.0442\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0201 - val_loss: 0.0402\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0190 - val_loss: 0.0403\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0198 - val_loss: 0.0396\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0193 - val_loss: 0.0428\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0189 - val_loss: 0.0397\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.0193 - val_loss: 0.0404\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.0182 - val_loss: 0.0445\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0187 - val_loss: 0.0392\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0199 - val_loss: 0.0457\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 190us/step - loss: 0.0181 - val_loss: 0.0403\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.0183 - val_loss: 0.0404\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.0183 - val_loss: 0.0387\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0185 - val_loss: 0.0401\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.0180 - val_loss: 0.0385\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.0184 - val_loss: 0.0390\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0176 - val_loss: 0.0414\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.0192 - val_loss: 0.0398\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.0187 - val_loss: 0.0423\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0181 - val_loss: 0.0464\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0180 - val_loss: 0.0434\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0187 - val_loss: 0.0432\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 157us/step - loss: 2.5702 - val_loss: 0.8053\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 1s 142us/step - loss: 0.7863 - val_loss: 0.6884\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.6759 - val_loss: 0.5334\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.6127 - val_loss: 0.4990\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 1s 142us/step - loss: 0.5722 - val_loss: 0.4745\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.5352 - val_loss: 0.4360\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 1s 139us/step - loss: 0.5100 - val_loss: 0.4395\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 1s 135us/step - loss: 0.4791 - val_loss: 0.4489\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 1s 135us/step - loss: 0.4548 - val_loss: 0.4132\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 1s 142us/step - loss: 0.4331 - val_loss: 0.3814\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 1s 135us/step - loss: 0.4096 - val_loss: 0.3667\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 1s 145us/step - loss: 0.3881 - val_loss: 0.3248\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 1s 134us/step - loss: 0.3675 - val_loss: 0.3180\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 1s 135us/step - loss: 0.3502 - val_loss: 0.3051\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 1s 142us/step - loss: 0.3329 - val_loss: 0.2968\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 1s 137us/step - loss: 0.3164 - val_loss: 0.2903\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 1s 147us/step - loss: 0.2985 - val_loss: 0.3028\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.2861 - val_loss: 0.2680\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 1s 139us/step - loss: 0.2698 - val_loss: 0.2487\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 1s 143us/step - loss: 0.2595 - val_loss: 0.2469\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.2453 - val_loss: 0.2251\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 1s 142us/step - loss: 0.2343 - val_loss: 0.2284\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.2219 - val_loss: 0.2294\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 1s 134us/step - loss: 0.2152 - val_loss: 0.2308\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 1s 135us/step - loss: 0.2023 - val_loss: 0.1989\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.1945 - val_loss: 0.1945\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 1s 142us/step - loss: 0.1858 - val_loss: 0.1868\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.1767 - val_loss: 0.1902\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 1s 137us/step - loss: 0.1717 - val_loss: 0.1764\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 1s 135us/step - loss: 0.1619 - val_loss: 0.1690\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.1568 - val_loss: 0.1939\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 1s 140us/step - loss: 0.1489 - val_loss: 0.1504\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.1422 - val_loss: 0.1499\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 1s 137us/step - loss: 0.1366 - val_loss: 0.1634\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 1s 137us/step - loss: 0.1315 - val_loss: 0.1386\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.1253 - val_loss: 0.1393\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 1s 139us/step - loss: 0.1234 - val_loss: 0.1410\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.1179 - val_loss: 0.1325\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 1s 138us/step - loss: 0.1128 - val_loss: 0.1330\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 1s 134us/step - loss: 0.1087 - val_loss: 0.1229\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.1056 - val_loss: 0.1919\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 1s 140us/step - loss: 0.1032 - val_loss: 0.1171\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.1005 - val_loss: 0.1174\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 1s 135us/step - loss: 0.0973 - val_loss: 0.1125\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.0939 - val_loss: 0.1060\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0910 - val_loss: 0.1028\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 1s 142us/step - loss: 0.0891 - val_loss: 0.1134\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0866 - val_loss: 0.1008\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 1s 137us/step - loss: 0.0838 - val_loss: 0.0987\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 1s 136us/step - loss: 0.0828 - val_loss: 0.0950\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 1s 136us/step - loss: 0.0800 - val_loss: 0.0997\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 1s 144us/step - loss: 0.0792 - val_loss: 0.1201\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0771 - val_loss: 0.0910\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 1s 141us/step - loss: 0.0763 - val_loss: 0.0990\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 1s 136us/step - loss: 0.0734 - val_loss: 0.0941\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.0736 - val_loss: 0.0986\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 1s 144us/step - loss: 0.0717 - val_loss: 0.0841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0697 - val_loss: 0.0964\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 1s 137us/step - loss: 0.0692 - val_loss: 0.0954\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.0678 - val_loss: 0.0999\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 1s 139us/step - loss: 0.0669 - val_loss: 0.0871\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 1s 135us/step - loss: 0.0662 - val_loss: 0.0823\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.0644 - val_loss: 0.0800\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 1s 138us/step - loss: 0.0640 - val_loss: 0.0937\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0630 - val_loss: 0.0785\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 1s 140us/step - loss: 0.0605 - val_loss: 0.0805\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0605 - val_loss: 0.1143\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0594 - val_loss: 0.0850\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 1s 139us/step - loss: 0.0594 - val_loss: 0.0798\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0581 - val_loss: 0.0970\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 1s 140us/step - loss: 0.0577 - val_loss: 0.0719\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0566 - val_loss: 0.0709\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0565 - val_loss: 0.0828\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0546 - val_loss: 0.0759\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 1s 138us/step - loss: 0.0548 - val_loss: 0.0808\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 155us/step - loss: 0.0549 - val_loss: 0.0741\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 1s 148us/step - loss: 0.0532 - val_loss: 0.0671\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 1s 152us/step - loss: 0.0531 - val_loss: 0.0708\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0512 - val_loss: 0.0684\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0516 - val_loss: 0.0899\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0510 - val_loss: 0.0687\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0506 - val_loss: 0.0641\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0500 - val_loss: 0.0754\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0493 - val_loss: 0.0773\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0492 - val_loss: 0.0701\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.0490 - val_loss: 0.0765\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0485 - val_loss: 0.0683\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0479 - val_loss: 0.0663\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0467 - val_loss: 0.0665\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0463 - val_loss: 0.0607\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0468 - val_loss: 0.0600\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0460 - val_loss: 0.0657\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0451 - val_loss: 0.0622\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0454 - val_loss: 0.0623\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0458 - val_loss: 0.0616\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0439 - val_loss: 0.1524\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0459 - val_loss: 0.0697\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0446 - val_loss: 0.0614\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0428 - val_loss: 0.0587\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0426 - val_loss: 0.0668\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0429 - val_loss: 0.0591\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 1s 137us/step - loss: 0.0428 - val_loss: 0.0584\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0434 - val_loss: 0.0584\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0418 - val_loss: 0.0562\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0409 - val_loss: 0.0661\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0409 - val_loss: 0.0593\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 1s 135us/step - loss: 0.0416 - val_loss: 0.0568\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0412 - val_loss: 0.0584\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 1s 134us/step - loss: 0.0405 - val_loss: 0.0586\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0409 - val_loss: 0.0552\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0406 - val_loss: 0.0544\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 1s 137us/step - loss: 0.0392 - val_loss: 0.0541\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0394 - val_loss: 0.0535\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0395 - val_loss: 0.0543\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0385 - val_loss: 0.0555\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0379 - val_loss: 0.0525\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0377 - val_loss: 0.0684\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0382 - val_loss: 0.0564\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0386 - val_loss: 0.0579\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0384 - val_loss: 0.0642\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0373 - val_loss: 0.0539\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0365 - val_loss: 0.0860\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0369 - val_loss: 0.0655\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0368 - val_loss: 0.0565\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0372 - val_loss: 0.0513\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0364 - val_loss: 0.0584\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.0358 - val_loss: 0.0530\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0356 - val_loss: 0.0563\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0358 - val_loss: 0.0636\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0359 - val_loss: 0.0517\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0356 - val_loss: 0.0592\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0357 - val_loss: 0.0542\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0349 - val_loss: 0.0546\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0351 - val_loss: 0.0537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0338 - val_loss: 0.0527\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0341 - val_loss: 0.0551\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0330 - val_loss: 0.0613\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0340 - val_loss: 0.0594\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0335 - val_loss: 0.0534\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0347 - val_loss: 0.0509\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0330 - val_loss: 0.0489\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0328 - val_loss: 0.0523\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0341 - val_loss: 0.0525\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0331 - val_loss: 0.0494\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0325 - val_loss: 0.0567\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0341 - val_loss: 0.0509\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0325 - val_loss: 0.0479\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0321 - val_loss: 0.0522\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0320 - val_loss: 0.0494\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0324 - val_loss: 0.0549\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0320 - val_loss: 0.0490\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0315 - val_loss: 0.0683\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.0308 - val_loss: 0.0518\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0313 - val_loss: 0.0503\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 1s 134us/step - loss: 0.0318 - val_loss: 0.0717\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0324 - val_loss: 0.0508\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0309 - val_loss: 0.0497\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0310 - val_loss: 0.0504\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0307 - val_loss: 0.0463\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0306 - val_loss: 0.0472\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0301 - val_loss: 0.0571\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0324 - val_loss: 0.0468\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0305 - val_loss: 0.0502\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0301 - val_loss: 0.0474\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0320 - val_loss: 0.0502\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.0303 - val_loss: 0.0646\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0310 - val_loss: 0.0445\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0302 - val_loss: 0.0464\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0299 - val_loss: 0.0451\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0295 - val_loss: 0.0685\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0292 - val_loss: 0.0491\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0297 - val_loss: 0.0465\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0288 - val_loss: 0.0508\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0284 - val_loss: 0.0486\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0291 - val_loss: 0.0448\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0284 - val_loss: 0.0634\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0299 - val_loss: 0.0612\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0292 - val_loss: 0.0783\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0294 - val_loss: 0.0442\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0287 - val_loss: 0.0493\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0284 - val_loss: 0.0433\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0279 - val_loss: 0.0587\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0283 - val_loss: 0.0659\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0283 - val_loss: 0.0450\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0276 - val_loss: 0.0434\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0279 - val_loss: 0.0437\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0276 - val_loss: 0.0463\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0283 - val_loss: 0.0434\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0277 - val_loss: 0.0447\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0277 - val_loss: 0.0544\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0272 - val_loss: 0.0595\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0284 - val_loss: 0.0524\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0284 - val_loss: 0.0473\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0268 - val_loss: 0.0550\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0276 - val_loss: 0.0436\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0271 - val_loss: 0.0436\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0266 - val_loss: 0.0455\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0268 - val_loss: 0.0503\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0272 - val_loss: 0.0471\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0263 - val_loss: 0.0453\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0263 - val_loss: 0.0498\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0259 - val_loss: 0.0474\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0261 - val_loss: 0.0429\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0265 - val_loss: 0.0459\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0258 - val_loss: 0.0415\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0260 - val_loss: 0.0465\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0266 - val_loss: 0.0505\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0258 - val_loss: 0.0429\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0252 - val_loss: 0.0423\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 1s 140us/step - loss: 0.0258 - val_loss: 0.0451\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0252 - val_loss: 0.0465\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0254 - val_loss: 0.0419\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0258 - val_loss: 0.0557\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0262 - val_loss: 0.0454\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 1s 136us/step - loss: 0.0251 - val_loss: 0.0409\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0251 - val_loss: 0.0600\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0254 - val_loss: 0.0467\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0257 - val_loss: 0.0461\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0255 - val_loss: 0.0443\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0248 - val_loss: 0.0442\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0249 - val_loss: 0.0500\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0250 - val_loss: 0.0447\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0246 - val_loss: 0.0513\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0249 - val_loss: 0.0526\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0247 - val_loss: 0.0447\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0247 - val_loss: 0.0546\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0243 - val_loss: 0.0432\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.0244 - val_loss: 0.0530\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0244 - val_loss: 0.0524\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0237 - val_loss: 0.0526\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0247 - val_loss: 0.0414\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0239 - val_loss: 0.0398\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0237 - val_loss: 0.0416\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0249 - val_loss: 0.0467\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0244 - val_loss: 0.0559\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0252 - val_loss: 0.0405\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0240 - val_loss: 0.0418\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0235 - val_loss: 0.0418\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0237 - val_loss: 0.0487\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0241 - val_loss: 0.0442\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0229 - val_loss: 0.0428\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0238 - val_loss: 0.0500\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0238 - val_loss: 0.0396\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0233 - val_loss: 0.0433\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0227 - val_loss: 0.0438\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0227 - val_loss: 0.0430\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0232 - val_loss: 0.0422\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0231 - val_loss: 0.0421\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0228 - val_loss: 0.0400\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0230 - val_loss: 0.0414\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 11.9577 - val_loss: 2.9749\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 1.5912 - val_loss: 2.0598\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.9142 - val_loss: 1.7500\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.7120 - val_loss: 1.6403\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.6036 - val_loss: 1.5448\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.5272 - val_loss: 1.4924\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.4514 - val_loss: 1.3198\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.4520 - val_loss: 1.3122\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.3917 - val_loss: 1.2185\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.3465 - val_loss: 1.1778\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.3530 - val_loss: 1.2261\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.3474 - val_loss: 1.1060\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.3432 - val_loss: 1.1867\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.2873 - val_loss: 1.0312\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.2638 - val_loss: 0.9797\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.2402 - val_loss: 0.9993\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.2298 - val_loss: 0.9456\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.2205 - val_loss: 1.0250\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.2120 - val_loss: 0.9307\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.2087 - val_loss: 1.0003\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.1877 - val_loss: 0.8725\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.1803 - val_loss: 0.9171\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.1686 - val_loss: 0.8552\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.2062 - val_loss: 0.8127\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.1706 - val_loss: 0.9061\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.1678 - val_loss: 0.8172\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.1604 - val_loss: 0.8054\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.1590 - val_loss: 0.7604\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.1593 - val_loss: 0.7857\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.1507 - val_loss: 0.7421\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.1361 - val_loss: 0.8116\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.1346 - val_loss: 0.7085\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.1607 - val_loss: 0.7079\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.1277 - val_loss: 0.7809\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.1293 - val_loss: 0.7028\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.1304 - val_loss: 0.6912\n",
      "Epoch 37/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.1448 - val_loss: 0.6661\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.1308 - val_loss: 0.6551\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.1208 - val_loss: 0.6741\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.1125 - val_loss: 0.6879\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.1534 - val_loss: 0.6644\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.1074 - val_loss: 0.6686\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.1043 - val_loss: 0.6044\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1039 - val_loss: 0.6235\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.1048 - val_loss: 0.6147\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.1165 - val_loss: 0.6918\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.1016 - val_loss: 0.5818\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.1037 - val_loss: 0.5864\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.1093 - val_loss: 0.5809\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.1138 - val_loss: 0.5858\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0982 - val_loss: 0.5803\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0918 - val_loss: 0.5568\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.0894 - val_loss: 0.5569\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0987 - val_loss: 0.5316\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0870 - val_loss: 0.5922\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0869 - val_loss: 0.5880\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1269 - val_loss: 0.5292\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0913 - val_loss: 0.5299\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.0901 - val_loss: 0.5226\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.0831 - val_loss: 0.5105\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0933 - val_loss: 0.5384\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.0946 - val_loss: 0.5081\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0834 - val_loss: 0.5065\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0784 - val_loss: 0.5153\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0795 - val_loss: 0.5079\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0751 - val_loss: 0.5296\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0824 - val_loss: 0.4708\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.1045 - val_loss: 0.4939\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.1063 - val_loss: 0.6412\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.1413 - val_loss: 0.5092\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.1011 - val_loss: 0.4714\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0755 - val_loss: 0.4826\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0713 - val_loss: 0.5474\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0714 - val_loss: 0.4956\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0699 - val_loss: 0.5387\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0744 - val_loss: 0.5281\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0669 - val_loss: 0.4953\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0702 - val_loss: 0.4839\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0720 - val_loss: 0.4602\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0660 - val_loss: 0.4544\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0696 - val_loss: 0.4594\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0698 - val_loss: 0.4576\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0647 - val_loss: 0.4504\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0635 - val_loss: 0.4196\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0602 - val_loss: 0.4156\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0638 - val_loss: 0.4180\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0645 - val_loss: 0.5189\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0620 - val_loss: 0.4178\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0607 - val_loss: 0.4373\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0609 - val_loss: 0.4807\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0577 - val_loss: 0.4075\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0590 - val_loss: 0.3901\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0562 - val_loss: 0.4230\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0564 - val_loss: 0.3999\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.0568 - val_loss: 0.4067\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0552 - val_loss: 0.3866\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0548 - val_loss: 0.3802\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0570 - val_loss: 0.3822\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0614 - val_loss: 0.3798\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0565 - val_loss: 0.3883\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0598 - val_loss: 0.4140\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0569 - val_loss: 0.3833\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0631 - val_loss: 0.4237\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0576 - val_loss: 0.3808\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0507 - val_loss: 0.3638\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0545 - val_loss: 0.3624\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0580 - val_loss: 0.3973\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0527 - val_loss: 0.3766\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0507 - val_loss: 0.3897\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0618 - val_loss: 0.3679\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - ETA: 0s - loss: 0.050 - 2s 164us/step - loss: 0.0509 - val_loss: 0.4049\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0477 - val_loss: 0.3693\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0524 - val_loss: 0.3792\n",
      "Epoch 114/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0506 - val_loss: 0.3851\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0502 - val_loss: 0.3930\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0477 - val_loss: 0.3754\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0504 - val_loss: 0.3914\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0460 - val_loss: 0.3864\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0472 - val_loss: 0.3967\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0461 - val_loss: 0.3468\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.0523 - val_loss: 0.3652\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0499 - val_loss: 0.3455\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0476 - val_loss: 0.3460\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.0465 - val_loss: 0.3648\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0448 - val_loss: 0.3401\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.0446 - val_loss: 0.3447\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0457 - val_loss: 0.3381\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0417 - val_loss: 0.3629\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0419 - val_loss: 0.3435\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0425 - val_loss: 0.3298\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0426 - val_loss: 0.3597\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0464 - val_loss: 0.3622\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0417 - val_loss: 0.3484\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0405 - val_loss: 0.3333\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0405 - val_loss: 0.3416\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0426 - val_loss: 0.3329\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0420 - val_loss: 0.3357\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0426 - val_loss: 0.3762\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0418 - val_loss: 0.3183\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0479 - val_loss: 0.3419\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0414 - val_loss: 0.3189\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0462 - val_loss: 0.3325\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0393 - val_loss: 0.3183\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0404 - val_loss: 0.3250\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0380 - val_loss: 0.3161\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0386 - val_loss: 0.3187\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0389 - val_loss: 0.3152\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0399 - val_loss: 0.3155\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0382 - val_loss: 0.3418\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0397 - val_loss: 0.3223\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0394 - val_loss: 0.3242\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0416 - val_loss: 0.3255\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0373 - val_loss: 0.3141\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0371 - val_loss: 0.3303\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0389 - val_loss: 0.3131\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0374 - val_loss: 0.3221\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0378 - val_loss: 0.3530\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0378 - val_loss: 0.3608\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0382 - val_loss: 0.3284\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0346 - val_loss: 0.3040\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0373 - val_loss: 0.3145\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0365 - val_loss: 0.3156\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0344 - val_loss: 0.3027\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0359 - val_loss: 0.3153\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0347 - val_loss: 0.3172\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0364 - val_loss: 0.3241\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0346 - val_loss: 0.2995\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0350 - val_loss: 0.3015\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0339 - val_loss: 0.3650\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0347 - val_loss: 0.3080\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0322 - val_loss: 0.3073\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0333 - val_loss: 0.3157\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0355 - val_loss: 0.3345\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0346 - val_loss: 0.3222\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0342 - val_loss: 0.3135\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0349 - val_loss: 0.3056\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0324 - val_loss: 0.3038\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0313 - val_loss: 0.3242\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0342 - val_loss: 0.3031\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0352 - val_loss: 0.3142\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0345 - val_loss: 0.3146\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0334 - val_loss: 0.2981\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0312 - val_loss: 0.3105\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0317 - val_loss: 0.2996\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0316 - val_loss: 0.3036\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0329 - val_loss: 0.3024\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0330 - val_loss: 0.3242\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0339 - val_loss: 0.3443\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0329 - val_loss: 0.3164\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0354 - val_loss: 0.3034\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0338 - val_loss: 0.3262\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0329 - val_loss: 0.3069\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.0329 - val_loss: 0.2989\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0309 - val_loss: 0.3176\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0304 - val_loss: 0.3297\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0318 - val_loss: 0.3157\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0321 - val_loss: 0.3254\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0309 - val_loss: 0.3118\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0304 - val_loss: 0.3064\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0289 - val_loss: 0.3166\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0302 - val_loss: 0.3126\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0319 - val_loss: 0.3228\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - ETA: 0s - loss: 0.028 - 2s 165us/step - loss: 0.0285 - val_loss: 0.3025\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0292 - val_loss: 0.3127\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0324 - val_loss: 0.3116\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0292 - val_loss: 0.3369\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0311 - val_loss: 0.3008\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0349 - val_loss: 0.3096\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0314 - val_loss: 0.3124\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0298 - val_loss: 0.3096\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0289 - val_loss: 0.3133\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0321 - val_loss: 0.3215\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.0292 - val_loss: 0.3049\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0285 - val_loss: 0.3007\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0302 - val_loss: 0.3216\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0291 - val_loss: 0.2978\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0283 - val_loss: 0.3362\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.0287 - val_loss: 0.3012\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0320 - val_loss: 0.3182\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0283 - val_loss: 0.3276\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0309 - val_loss: 0.3100\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0294 - val_loss: 0.3335\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0328 - val_loss: 0.3093\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0291 - val_loss: 0.3273\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0326 - val_loss: 0.3147\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0275 - val_loss: 0.3254\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0279 - val_loss: 0.3182\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0276 - val_loss: 0.3232\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0288 - val_loss: 0.3096\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0279 - val_loss: 0.3239\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0276 - val_loss: 0.3063\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0267 - val_loss: 0.3255\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0263 - val_loss: 0.3180\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0286 - val_loss: 0.3184\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0272 - val_loss: 0.3299\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.0268 - val_loss: 0.3233\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0265 - val_loss: 0.3217\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0292 - val_loss: 0.3193\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0265 - val_loss: 0.3106\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0261 - val_loss: 0.3224\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0262 - val_loss: 0.3258\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0259 - val_loss: 0.3104\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.0270 - val_loss: 0.3008\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0268 - val_loss: 0.3135\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.0260 - val_loss: 0.3127\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0259 - val_loss: 0.3157\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0290 - val_loss: 0.3148\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0257 - val_loss: 0.3259\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0260 - val_loss: 0.3310\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.0282 - val_loss: 0.3114\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 1s 154us/step - loss: 16.5350 - val_loss: 6.4149\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 2.6777 - val_loss: 3.5687\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 1s 120us/step - loss: 1.4827 - val_loss: 2.4470\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 1.0392 - val_loss: 2.0824\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.8870 - val_loss: 2.1811\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.7623 - val_loss: 1.8297\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.6602 - val_loss: 1.8414\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 1s 120us/step - loss: 0.6261 - val_loss: 1.9822\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.5599 - val_loss: 1.6271\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.5199 - val_loss: 1.6693\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.4584 - val_loss: 1.6653\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.4321 - val_loss: 1.4637\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.4282 - val_loss: 1.4995\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.3958 - val_loss: 1.6395\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.3832 - val_loss: 1.4608\n",
      "Epoch 16/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.3533 - val_loss: 1.2752\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.3429 - val_loss: 1.3098\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.3547 - val_loss: 1.3038\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.3025 - val_loss: 1.2811\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.2905 - val_loss: 1.2268\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.2758 - val_loss: 1.6114\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.2732 - val_loss: 1.1499\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 1s 136us/step - loss: 0.2586 - val_loss: 1.1441\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.2591 - val_loss: 1.1310\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.2414 - val_loss: 1.2967\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.2459 - val_loss: 1.0700\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.2286 - val_loss: 1.0459\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.2294 - val_loss: 1.0631\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.2171 - val_loss: 1.0910\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.2158 - val_loss: 1.1876\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.2141 - val_loss: 1.0428\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.2057 - val_loss: 0.9861\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.1981 - val_loss: 0.9403\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.2022 - val_loss: 0.9531\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.1907 - val_loss: 0.9192\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.1794 - val_loss: 0.9528\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.1782 - val_loss: 0.9129\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.1781 - val_loss: 0.9395\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.1671 - val_loss: 0.8649\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.1651 - val_loss: 0.8774\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.1582 - val_loss: 0.9605\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.1628 - val_loss: 1.1480\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.1651 - val_loss: 1.8163\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.1771 - val_loss: 0.9281\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.1535 - val_loss: 0.8301\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.1597 - val_loss: 0.8752\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.1513 - val_loss: 0.8739\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.1641 - val_loss: 0.8753\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - ETA: 0s - loss: 0.157 - 1s 131us/step - loss: 0.1566 - val_loss: 0.8806\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.1447 - val_loss: 0.8466\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.1412 - val_loss: 0.8230\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.1385 - val_loss: 0.8094\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.1397 - val_loss: 0.7869\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.1780 - val_loss: 0.8310\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.1442 - val_loss: 0.8002\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.1311 - val_loss: 0.7861\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.1286 - val_loss: 0.7485\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.1261 - val_loss: 0.7454\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.1256 - val_loss: 0.8295\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.1340 - val_loss: 0.7563\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.1355 - val_loss: 0.7450\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.1210 - val_loss: 1.2728\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.1254 - val_loss: 0.7608\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.1172 - val_loss: 0.7336\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.1217 - val_loss: 0.7467\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.1428 - val_loss: 0.7469\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 1s 134us/step - loss: 0.1160 - val_loss: 1.2934\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 1s 120us/step - loss: 0.1207 - val_loss: 0.6868\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.1183 - val_loss: 0.7289\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.1117 - val_loss: 0.7183\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.1200 - val_loss: 0.7283\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.1105 - val_loss: 0.7061\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.1039 - val_loss: 0.7817\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.1097 - val_loss: 0.7014\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 1s 142us/step - loss: 0.1047 - val_loss: 0.6735\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.1015 - val_loss: 0.8172\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0940 - val_loss: 0.6577\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0965 - val_loss: 0.6304\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0991 - val_loss: 0.6776\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0953 - val_loss: 0.6623\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.1460 - val_loss: 0.6860\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.1255 - val_loss: 0.6523\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0923 - val_loss: 0.7864\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.1093 - val_loss: 0.6283\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0894 - val_loss: 0.6211\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0960 - val_loss: 0.6460\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0896 - val_loss: 0.5992\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0895 - val_loss: 0.6785\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0958 - val_loss: 0.7154\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0924 - val_loss: 0.6033\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0841 - val_loss: 0.6453\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0860 - val_loss: 0.6281\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0807 - val_loss: 0.5770\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0835 - val_loss: 0.5978\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0806 - val_loss: 0.6624\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0801 - val_loss: 0.6201\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0857 - val_loss: 0.5865\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0845 - val_loss: 0.6330\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0853 - val_loss: 0.6671\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0826 - val_loss: 0.6018\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - ETA: 0s - loss: 0.080 - 1s 129us/step - loss: 0.0800 - val_loss: 0.6012\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0882 - val_loss: 0.6434\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0794 - val_loss: 0.6222\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0807 - val_loss: 0.8572\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0796 - val_loss: 0.6896\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0762 - val_loss: 0.5506\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0744 - val_loss: 0.6151\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0748 - val_loss: 0.6243\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0751 - val_loss: 0.5604\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0728 - val_loss: 0.5884\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0726 - val_loss: 0.5910\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0767 - val_loss: 0.6454\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0707 - val_loss: 0.5500\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0748 - val_loss: 0.5736\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0720 - val_loss: 0.5513\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0684 - val_loss: 1.5845\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0987 - val_loss: 0.5547\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0728 - val_loss: 0.5677\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0695 - val_loss: 0.5054\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0825 - val_loss: 0.5284\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 1s 136us/step - loss: 0.0746 - val_loss: 0.5618\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0704 - val_loss: 0.5489\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0691 - val_loss: 0.5314\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0687 - val_loss: 0.7959\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0948 - val_loss: 0.5897\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0650 - val_loss: 0.5256\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0730 - val_loss: 0.5634\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0666 - val_loss: 0.5262\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0705 - val_loss: 0.5332\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0646 - val_loss: 0.5487\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0634 - val_loss: 0.5404\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0687 - val_loss: 0.5707\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0689 - val_loss: 0.5213\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0737 - val_loss: 0.5111\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0630 - val_loss: 0.5680\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0609 - val_loss: 0.5787\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0660 - val_loss: 0.5424\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0615 - val_loss: 0.5376\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0566 - val_loss: 0.5015\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0761 - val_loss: 0.5218\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0661 - val_loss: 0.5236\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0717 - val_loss: 0.5119\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0635 - val_loss: 0.4883\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0594 - val_loss: 0.5226\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0587 - val_loss: 0.4955\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0620 - val_loss: 0.5181\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0643 - val_loss: 0.5013\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0566 - val_loss: 0.5774\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 1s 120us/step - loss: 0.0680 - val_loss: 0.4904\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0601 - val_loss: 0.4862\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0596 - val_loss: 0.4932\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.1033 - val_loss: 0.5417\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0636 - val_loss: 0.4807\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0618 - val_loss: 0.5121\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0550 - val_loss: 0.5221\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0564 - val_loss: 0.4942\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0562 - val_loss: 0.5170\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.0561 - val_loss: 0.5398\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0539 - val_loss: 0.5304\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0667 - val_loss: 0.6672\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0689 - val_loss: 0.4796\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0541 - val_loss: 0.4797\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0522 - val_loss: 0.4973\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 1s 120us/step - loss: 0.0715 - val_loss: 0.6085\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0561 - val_loss: 0.4875\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0535 - val_loss: 0.4922\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0527 - val_loss: 0.4860\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0514 - val_loss: 0.4867\n",
      "Epoch 169/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0519 - val_loss: 0.4702\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0499 - val_loss: 0.4929\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0505 - val_loss: 0.5248\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0510 - val_loss: 0.4809\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0500 - val_loss: 0.5059\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0518 - val_loss: 0.4782\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0505 - val_loss: 0.5285\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0502 - val_loss: 0.4954\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0489 - val_loss: 0.5003\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0489 - val_loss: 0.4769\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0523 - val_loss: 0.4878\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0471 - val_loss: 0.4676\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0465 - val_loss: 0.4848\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0476 - val_loss: 0.4925\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0466 - val_loss: 0.4794\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0489 - val_loss: 0.4657\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0500 - val_loss: 0.4796\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0462 - val_loss: 0.4958\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0458 - val_loss: 0.4649\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0455 - val_loss: 0.4699\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0476 - val_loss: 0.5461\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0528 - val_loss: 0.5490\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0494 - val_loss: 0.4944\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0492 - val_loss: 0.4702\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0460 - val_loss: 0.4517\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0486 - val_loss: 0.4728\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0440 - val_loss: 0.4738\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0520 - val_loss: 0.4642\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 1s 132us/step - loss: 0.0474 - val_loss: 0.4646\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0444 - val_loss: 0.4470\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0473 - val_loss: 0.5027\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0447 - val_loss: 0.4623\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0516 - val_loss: 0.4525\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0579 - val_loss: 0.4723\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0431 - val_loss: 0.4652\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0425 - val_loss: 0.4909\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0435 - val_loss: 0.4691\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0440 - val_loss: 0.4825\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0425 - val_loss: 0.4668\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0475 - val_loss: 0.4568\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0420 - val_loss: 0.4508\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 1s 128us/step - loss: 0.0488 - val_loss: 0.5680\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0479 - val_loss: 0.4673\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0445 - val_loss: 0.4735\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 1s 134us/step - loss: 0.0491 - val_loss: 0.4523\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0435 - val_loss: 0.4525\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0428 - val_loss: 0.4896\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0423 - val_loss: 0.4561\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0476 - val_loss: 0.4970\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0498 - val_loss: 0.5179\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 1s 135us/step - loss: 0.0405 - val_loss: 0.4527\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0482 - val_loss: 0.4633\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0404 - val_loss: 0.5458\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0439 - val_loss: 0.4672\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0435 - val_loss: 0.4847\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0396 - val_loss: 0.4704\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0406 - val_loss: 0.4709\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 1s 131us/step - loss: 0.0423 - val_loss: 0.4651\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0381 - val_loss: 0.4661\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0452 - val_loss: 0.4526\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0419 - val_loss: 0.4603\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0404 - val_loss: 0.4511\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0466 - val_loss: 0.4473\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0394 - val_loss: 0.4589\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 1s 122us/step - loss: 0.0505 - val_loss: 0.4694\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.0447 - val_loss: 0.5256\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 1s 120us/step - loss: 0.0389 - val_loss: 0.4549\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0408 - val_loss: 0.4568\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 1s 127us/step - loss: 0.0494 - val_loss: 0.4754\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0381 - val_loss: 0.4627\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0379 - val_loss: 0.4473\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0389 - val_loss: 0.4595\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 1s 125us/step - loss: 0.0396 - val_loss: 0.4565\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 1s 133us/step - loss: 0.0398 - val_loss: 0.4458\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 1s 124us/step - loss: 0.0401 - val_loss: 0.4623\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 1s 126us/step - loss: 0.0419 - val_loss: 0.4444\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0378 - val_loss: 0.5063\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0377 - val_loss: 0.5185\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 1s 129us/step - loss: 0.0360 - val_loss: 0.4955\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 1s 121us/step - loss: 0.0393 - val_loss: 0.4502\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 1s 130us/step - loss: 0.0374 - val_loss: 0.4671\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 1s 123us/step - loss: 0.0367 - val_loss: 0.4484\n"
     ]
    }
   ],
   "source": [
    "n_batches = 21\n",
    "batch_sizes = np.round(np.linspace(1,X_train_scaled.shape[0],n_batches))\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "model.compile(optimizer=SGD(lr=0.01),loss='mean_squared_error')\n",
    "history_batch10_sig = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "n_batches = 21\n",
    "batch_sizes = np.round(np.linspace(1,X_train_scaled.shape[0],n_batches))\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "model.compile(optimizer=SGD(lr=0.01),loss='mean_squared_error')\n",
    "history_batch90_sig = model.fit(X_train_scaled,y_train,batch_size=90,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "n_batches = 21\n",
    "batch_sizes = np.round(np.linspace(1,X_train_scaled.shape[0],n_batches))\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "model.compile(optimizer=SGD(lr=0.001),loss='mean_squared_error')\n",
    "history_batch50_rel = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "\n",
    "n_batches = 21\n",
    "batch_sizes = np.round(np.linspace(1,X_train_scaled.shape[0],n_batches))\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "model.compile(optimizer=SGD(lr=0.001),loss='mean_squared_error')\n",
    "history_batch90_rel = model.fit(X_train_scaled,y_train,batch_size=90,epochs=250,validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1584 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2,figsize=(16,22))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(history_batch10_sig.history['val_loss'])\n",
    "plt.plot(history_batch10_sig.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDE--BATCH 50')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(history_batch90_sig.history['val_loss'])\n",
    "plt.plot(history_batch90_sig.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDE--BATCH 90')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(history_batch50_rel.history['val_loss'])\n",
    "plt.plot(history_batch50_rel.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO RELU-- BATCH 50')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(history_batch90_rel.history['val_loss'])\n",
    "plt.plot(history_batch90_rel.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO RELU-- BATCH 90')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify> En la primera fila observamos los modelos <b>SIGMOIDAL </b>con dos valores diferentes de Batch, acá observamos que en el instante que aumentamos el tamaño, inmediatamente se aumenta el error en las primeras iteraciones y cuando converge tienen un error un poco parecido, en la función de pérdida de validación se observa una mayor estabilidad con un tamaño de Batch de 50, aunque no es tan significativa. En la segunda fila con el modelo <b>ReLU</b>, se observa el mismo comportamiento pero hay un poco más de distorsión en la señal cuando se aumenta el número de batch, asi como el valor nominar de la función de pérdida en la validación, esto no quiere decir que aumentar el número de batch sea una mala herramienta, lo que se puede decir es que en este caso preciso no sería una buena estrategia aumentar el número de batch para tener resultados deseados. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify><b> g) Entrene los modelos obtenidos en b) y c) utilizando estrategias modernas para adaptar la tasa de aprendizaje. Compare los desempeños de adagrad, adadelta, RMSprop y adam. ¿Se observa en algún caso un mejor resultado final? ¿Se observa en algún caso una mayor velocidad de convergencia sobre el dataset de entrenamiento? ¿Sobre el dataset de validación? </b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 8.5725 - val_loss: 2.9723\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 1.4417 - val_loss: 1.2223\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.6949 - val_loss: 0.6360\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.4088 - val_loss: 0.4251\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2919 - val_loss: 0.3017\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.2273 - val_loss: 0.2549\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.1907 - val_loss: 0.2106\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.1645 - val_loss: 0.1843\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.1458 - val_loss: 0.1683\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.1335 - val_loss: 0.1571\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1237 - val_loss: 0.1532\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1167 - val_loss: 0.1383\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.1094 - val_loss: 0.1343\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.1033 - val_loss: 0.1284\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0978 - val_loss: 0.1226\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0937 - val_loss: 0.1186\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0899 - val_loss: 0.1122\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0868 - val_loss: 0.1155\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0839 - val_loss: 0.1100\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0812 - val_loss: 0.1051\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0782 - val_loss: 0.1082\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0761 - val_loss: 0.0992TA: 0s - los\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.0739 - val_loss: 0.0992\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.0723 - val_loss: 0.1036\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0701 - val_loss: 0.0965\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0686 - val_loss: 0.0940\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0666 - val_loss: 0.0967\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.0654 - val_loss: 0.0927\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0638 - val_loss: 0.0937\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.0628 - val_loss: 0.0904.063\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.0617 - val_loss: 0.0899\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.0606 - val_loss: 0.0888\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0598 - val_loss: 0.0892\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0587 - val_loss: 0.0876\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0577 - val_loss: 0.0885\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0573 - val_loss: 0.0876\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0563 - val_loss: 0.0847\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0550 - val_loss: 0.0841\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0542 - val_loss: 0.0856\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0536 - val_loss: 0.0845\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.0529 - val_loss: 0.0844\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0523 - val_loss: 0.0826\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0516 - val_loss: 0.0816\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 157us/step - loss: 0.0511 - val_loss: 0.0814\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 157us/step - loss: 0.0504 - val_loss: 0.0807\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0497 - val_loss: 0.0791\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0494 - val_loss: 0.0796\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0489 - val_loss: 0.0792\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0484 - val_loss: 0.0797\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0478 - val_loss: 0.0785\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.0473 - val_loss: 0.0799\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0467 - val_loss: 0.0802\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.0463 - val_loss: 0.0788\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0461 - val_loss: 0.0777\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0456 - val_loss: 0.0789\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0452 - val_loss: 0.0773\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0449 - val_loss: 0.0768\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0444 - val_loss: 0.0759\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0439 - val_loss: 0.0757\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0438 - val_loss: 0.0760\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0433 - val_loss: 0.0753\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0430 - val_loss: 0.0745\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.0427 - val_loss: 0.0775\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.0424 - val_loss: 0.0757\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.0421 - val_loss: 0.0739\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.0419 - val_loss: 0.0766\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.0413 - val_loss: 0.0761\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0411 - val_loss: 0.0738\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.0409 - val_loss: 0.0730\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0406 - val_loss: 0.0736\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0404 - val_loss: 0.0734\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0400 - val_loss: 0.0735\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0399 - val_loss: 0.0734\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0396 - val_loss: 0.0731\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0394 - val_loss: 0.0716\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0391 - val_loss: 0.0722\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0389 - val_loss: 0.0719\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0385 - val_loss: 0.0712\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0383 - val_loss: 0.0713\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0381 - val_loss: 0.0708\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0377 - val_loss: 0.0709\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0376 - val_loss: 0.0708\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0374 - val_loss: 0.0717\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 158us/step - loss: 0.0372 - val_loss: 0.0708\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0369 - val_loss: 0.0704\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 157us/step - loss: 0.0366 - val_loss: 0.0704\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0365 - val_loss: 0.0700\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 157us/step - loss: 0.0362 - val_loss: 0.0690\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0361 - val_loss: 0.0700\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 157us/step - loss: 0.0358 - val_loss: 0.0690\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0357 - val_loss: 0.0706\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0354 - val_loss: 0.0688\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.0352 - val_loss: 0.0686\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0350 - val_loss: 0.0688\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0350 - val_loss: 0.0681\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0348 - val_loss: 0.0688\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0346 - val_loss: 0.0690\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0344 - val_loss: 0.0683\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0340 - val_loss: 0.0679\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0341 - val_loss: 0.0683\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.0339 - val_loss: 0.0677\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0336 - val_loss: 0.0678\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0335 - val_loss: 0.0680\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.0332 - val_loss: 0.0686\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0331 - val_loss: 0.0688\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.0331 - val_loss: 0.0676\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0327 - val_loss: 0.0665\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0328 - val_loss: 0.0681\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0325 - val_loss: 0.0669\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 157us/step - loss: 0.0324 - val_loss: 0.0667\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0322 - val_loss: 0.0674\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0321 - val_loss: 0.0669\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0320 - val_loss: 0.0671\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0318 - val_loss: 0.0655\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0317 - val_loss: 0.0655\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0315 - val_loss: 0.0656\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.0313 - val_loss: 0.0656\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0312 - val_loss: 0.0660\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0311 - val_loss: 0.0660\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.0310 - val_loss: 0.0657\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0308 - val_loss: 0.0661\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0308 - val_loss: 0.0653\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0306 - val_loss: 0.0657\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0304 - val_loss: 0.0650\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0303 - val_loss: 0.0646\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0302 - val_loss: 0.0658\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0301 - val_loss: 0.0649\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0300 - val_loss: 0.0642\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0298 - val_loss: 0.0648\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0297 - val_loss: 0.0652\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0296 - val_loss: 0.0646\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0294 - val_loss: 0.0645\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.0295 - val_loss: 0.0655\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0294 - val_loss: 0.0645\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0292 - val_loss: 0.0640\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.0291 - val_loss: 0.0637\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0289 - val_loss: 0.0646\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.0288 - val_loss: 0.0639\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.0286 - val_loss: 0.0652\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.0286 - val_loss: 0.0641\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0285 - val_loss: 0.0636\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0283 - val_loss: 0.0638\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0283 - val_loss: 0.0634\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.0282 - val_loss: 0.0638\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.0281 - val_loss: 0.0630\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0279 - val_loss: 0.0634\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.0279 - val_loss: 0.0631\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0277 - val_loss: 0.0630\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0276 - val_loss: 0.0630\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0275 - val_loss: 0.0626\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0275 - val_loss: 0.0628\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0274 - val_loss: 0.0630\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0273 - val_loss: 0.0621\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0272 - val_loss: 0.0631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0271 - val_loss: 0.0629\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0270 - val_loss: 0.0623\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.0269 - val_loss: 0.0626\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.0267 - val_loss: 0.0624\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0268 - val_loss: 0.0625\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0266 - val_loss: 0.0630\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.0266 - val_loss: 0.0624\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0265 - val_loss: 0.0620\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.0264 - val_loss: 0.0618\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.0265 - val_loss: 0.0622\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0262 - val_loss: 0.0616\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0262 - val_loss: 0.0616\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0261 - val_loss: 0.0615\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0260 - val_loss: 0.0620\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0259 - val_loss: 0.0615\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0258 - val_loss: 0.0612\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0257 - val_loss: 0.0617\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.0256 - val_loss: 0.0617\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.0255 - val_loss: 0.0613\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.0256 - val_loss: 0.0616\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0255 - val_loss: 0.0613\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0254 - val_loss: 0.0612\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0253 - val_loss: 0.0608\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0252 - val_loss: 0.0606\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0251 - val_loss: 0.0613\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 157us/step - loss: 0.0250 - val_loss: 0.0605\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0250 - val_loss: 0.0608\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.0248 - val_loss: 0.0611\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0249 - val_loss: 0.0611\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0248 - val_loss: 0.0604\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0247 - val_loss: 0.0605\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.0247 - val_loss: 0.0601\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0246 - val_loss: 0.0603\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0245 - val_loss: 0.0602\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0244 - val_loss: 0.0604\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.0244 - val_loss: 0.0604: 0s - loss: 0.02\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.0243 - val_loss: 0.0602\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.0242 - val_loss: 0.0596\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0242 - val_loss: 0.0599\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0242 - val_loss: 0.0602\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0240 - val_loss: 0.0595\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0239 - val_loss: 0.0598\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0239 - val_loss: 0.0603\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0238 - val_loss: 0.0590\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0238 - val_loss: 0.0598\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0238 - val_loss: 0.0592\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0236 - val_loss: 0.0593\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0236 - val_loss: 0.0588\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0235 - val_loss: 0.0598\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0234 - val_loss: 0.0592\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0234 - val_loss: 0.0591\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0233 - val_loss: 0.0591\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.0232 - val_loss: 0.0595\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0232 - val_loss: 0.0593\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0231 - val_loss: 0.0587\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0232 - val_loss: 0.0585\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0231 - val_loss: 0.0592\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0230 - val_loss: 0.0585\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0229 - val_loss: 0.0590\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0228 - val_loss: 0.0590\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.0229 - val_loss: 0.0590\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0227 - val_loss: 0.0581\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0227 - val_loss: 0.0589\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 157us/step - loss: 0.0226 - val_loss: 0.0585\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0227 - val_loss: 0.0579\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.0226 - val_loss: 0.0583\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.0225 - val_loss: 0.0582\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0224 - val_loss: 0.0582\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0225 - val_loss: 0.0584\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - ETA: 0s - loss: 0.022 - 2s 160us/step - loss: 0.0224 - val_loss: 0.0578\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 159us/step - loss: 0.0223 - val_loss: 0.0585\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.0223 - val_loss: 0.0583\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0222 - val_loss: 0.0578\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0222 - val_loss: 0.0580\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.0220 - val_loss: 0.0574\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0220 - val_loss: 0.0574\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.0220 - val_loss: 0.0578\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0219 - val_loss: 0.0576\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0218 - val_loss: 0.0577\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0219 - val_loss: 0.0581\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0218 - val_loss: 0.0576\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.0217 - val_loss: 0.0584\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0218 - val_loss: 0.0573\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0217 - val_loss: 0.0573\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0216 - val_loss: 0.0574\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0215 - val_loss: 0.0575\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.0215 - val_loss: 0.0577\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0214 - val_loss: 0.0578\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.0214 - val_loss: 0.0571\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.0213 - val_loss: 0.0571\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.0213 - val_loss: 0.0569\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0213 - val_loss: 0.0569\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.0212 - val_loss: 0.0569\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.0211 - val_loss: 0.0569\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0211 - val_loss: 0.0573\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.0211 - val_loss: 0.0567 0s - l\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: 120.0996 - val_loss: 128.6361\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 106.9991 - val_loss: 114.3913\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 94.8023 - val_loss: 101.1856\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 82.9655 - val_loss: 88.1550\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 71.6059 - val_loss: 75.8492\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 60.9035 - val_loss: 64.4240\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 50.9707 - val_loss: 53.7414\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 41.9063 - val_loss: 44.1484\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 33.8489 - val_loss: 35.7011\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 26.8814 - val_loss: 28.3841\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 21.0282 - val_loss: 22.2287\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 16.2185 - val_loss: 17.2351\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 12.3531 - val_loss: 13.2533\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 9.3512 - val_loss: 10.0824\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 7.0938 - val_loss: 7.7395\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 5.4663 - val_loss: 6.0592\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 4.3300 - val_loss: 4.8697\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 3.5438 - val_loss: 4.0411\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 2.9764 - val_loss: 3.4322\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 2.5421 - val_loss: 2.9595\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 2.2115 - val_loss: 2.6084\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 1.9580 - val_loss: 2.3225\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.7521 - val_loss: 2.0874\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 1.5860 - val_loss: 1.8853\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 1.4391 - val_loss: 1.7093\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 1.3150 - val_loss: 1.5608\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 1.2072 - val_loss: 1.4202\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 1.1128 - val_loss: 1.3050\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 1.0357 - val_loss: 1.2079\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.9687 - val_loss: 1.1222\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.9084 - val_loss: 1.0488\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 0.8556 - val_loss: 0.9824\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.8095 - val_loss: 0.9200\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.7683 - val_loss: 0.8678\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 3s 271us/step - loss: 0.7311 - val_loss: 0.8198\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.6983 - val_loss: 0.7740\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 0.6677 - val_loss: 0.7324\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.6408 - val_loss: 0.6990\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.6165 - val_loss: 0.6702\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.5947 - val_loss: 0.6410\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.5741 - val_loss: 0.6108\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.5532 - val_loss: 0.5850\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.5350 - val_loss: 0.5621\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.5178 - val_loss: 0.5401\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.5021 - val_loss: 0.5207\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.4875 - val_loss: 0.5042\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.4735 - val_loss: 0.4867\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.4607 - val_loss: 0.4692\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.4486 - val_loss: 0.4562\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.4372 - val_loss: 0.4422\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.4262 - val_loss: 0.42850s - los\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.4157 - val_loss: 0.4153\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.4056 - val_loss: 0.4049\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.3960 - val_loss: 0.3942\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.3874 - val_loss: 0.3837\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.3793 - val_loss: 0.3750\n",
      "Epoch 57/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.3713 - val_loss: 0.3674\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.3634 - val_loss: 0.3570\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.3559 - val_loss: 0.3490\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.3487 - val_loss: 0.3399\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.3421 - val_loss: 0.3339\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.3357 - val_loss: 0.3260\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.3292 - val_loss: 0.3189\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.3230 - val_loss: 0.3139\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.3171 - val_loss: 0.3067\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.3114 - val_loss: 0.3004\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.3060 - val_loss: 0.2946\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.3007 - val_loss: 0.2899\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.2956 - val_loss: 0.2840\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.2909 - val_loss: 0.2793\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.2861 - val_loss: 0.2754\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.2816 - val_loss: 0.2700\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.2775 - val_loss: 0.2667\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 0.2734 - val_loss: 0.2614 ETA: 1s - ETA: 0s - \n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 3s 274us/step - loss: 0.2691 - val_loss: 0.2584\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.2658 - val_loss: 0.2549\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.2619 - val_loss: 0.2508\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.2584 - val_loss: 0.2478\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.2550 - val_loss: 0.2437\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.2515 - val_loss: 0.2414\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.2485 - val_loss: 0.2376\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 3s 284us/step - loss: 0.2452 - val_loss: 0.2342 - loss: - ETA: 0s \n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 0.2426 - val_loss: 0.2323\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.2397 - val_loss: 0.2293\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.2368 - val_loss: 0.2271\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.2341 - val_loss: 0.2244\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.2317 - val_loss: 0.2223\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.2290 - val_loss: 0.2204\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.2267 - val_loss: 0.2170\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.2241 - val_loss: 0.2162\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.2218 - val_loss: 0.2128\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.2196 - val_loss: 0.2109\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.2171 - val_loss: 0.2098\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.2151 - val_loss: 0.2076\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.2131 - val_loss: 0.2048\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.2111 - val_loss: 0.2029\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.2089 - val_loss: 0.2016\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.2070 - val_loss: 0.2000\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.2050 - val_loss: 0.1982\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.2030 - val_loss: 0.1964\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.2013 - val_loss: 0.1944\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.1994 - val_loss: 0.1924\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.1976 - val_loss: 0.1907\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 0.1958 - val_loss: 0.1898\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.1941 - val_loss: 0.1877\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.1925 - val_loss: 0.1869\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.1909 - val_loss: 0.1852\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.1892 - val_loss: 0.1838\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.1876 - val_loss: 0.1825\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.1863 - val_loss: 0.1810 - loss: 0.1\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.1845 - val_loss: 0.1800\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.1830 - val_loss: 0.1785\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.1818 - val_loss: 0.1774\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.1803 - val_loss: 0.1763\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.1788 - val_loss: 0.1755\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.1774 - val_loss: 0.1744\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 0.1762 - val_loss: 0.1725\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.1748 - val_loss: 0.1717\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1734 - val_loss: 0.1709\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.1721 - val_loss: 0.1704\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.1708 - val_loss: 0.1683\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1696 - val_loss: 0.1670\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1683 - val_loss: 0.1655\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.1671 - val_loss: 0.1651\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1659 - val_loss: 0.1634\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1647 - val_loss: 0.1624\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.1636 - val_loss: 0.1620\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1624 - val_loss: 0.1616\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1613 - val_loss: 0.1607\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1602 - val_loss: 0.1594\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1592 - val_loss: 0.1588\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1581 - val_loss: 0.1578\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1572 - val_loss: 0.1566\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.1561 - val_loss: 0.1553\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1552 - val_loss: 0.1546\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1541 - val_loss: 0.1542\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1532 - val_loss: 0.1533\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1520 - val_loss: 0.1529\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1511 - val_loss: 0.1525\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1502 - val_loss: 0.1507\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.1492 - val_loss: 0.1500\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1484 - val_loss: 0.1495\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.1476 - val_loss: 0.1485\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1466 - val_loss: 0.1484\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1457 - val_loss: 0.1484\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1450 - val_loss: 0.1463\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1441 - val_loss: 0.1461\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1433 - val_loss: 0.1449\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1425 - val_loss: 0.1449\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1417 - val_loss: 0.1433\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1409 - val_loss: 0.1434\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1401 - val_loss: 0.1427\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.1392 - val_loss: 0.1418\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1384 - val_loss: 0.1411\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1378 - val_loss: 0.1402\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1369 - val_loss: 0.1398\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1361 - val_loss: 0.1394\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1356 - val_loss: 0.1385\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1347 - val_loss: 0.1385\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1340 - val_loss: 0.1371\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1334 - val_loss: 0.1366\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1327 - val_loss: 0.1366\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.1320 - val_loss: 0.1354\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1313 - val_loss: 0.1352\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1307 - val_loss: 0.1348\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1300 - val_loss: 0.1336\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1294 - val_loss: 0.1334\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1286 - val_loss: 0.1328\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1281 - val_loss: 0.1324\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1274 - val_loss: 0.1317\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1269 - val_loss: 0.1314\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1264 - val_loss: 0.1308\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.1255 - val_loss: 0.1306\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1251 - val_loss: 0.1296\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1244 - val_loss: 0.1292\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1239 - val_loss: 0.1288\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.1234 - val_loss: 0.1285\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1228 - val_loss: 0.1276\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1221 - val_loss: 0.1275\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1216 - val_loss: 0.1267\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1211 - val_loss: 0.1266\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1205 - val_loss: 0.1256\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1200 - val_loss: 0.1257\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1195 - val_loss: 0.1251\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1189 - val_loss: 0.1250\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1184 - val_loss: 0.1238\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1178 - val_loss: 0.1233\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1173 - val_loss: 0.1234\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1168 - val_loss: 0.1226\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1162 - val_loss: 0.1232\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.1157 - val_loss: 0.1219\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1152 - val_loss: 0.1219\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1147 - val_loss: 0.1209\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1142 - val_loss: 0.1208\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1138 - val_loss: 0.1207\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1133 - val_loss: 0.1200\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1128 - val_loss: 0.1200\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1123 - val_loss: 0.1194\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1118 - val_loss: 0.1190\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1113 - val_loss: 0.1182\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1109 - val_loss: 0.1180\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1105 - val_loss: 0.1171\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.1099 - val_loss: 0.1173\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 0.1095 - val_loss: 0.1169\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: 0.1091 - val_loss: 0.1165 ETA: - ETA: \n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.1086 - val_loss: 0.1160\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.1082 - val_loss: 0.1155\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.1077 - val_loss: 0.1154\n",
      "Epoch 209/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.1073 - val_loss: 0.1148\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.1070 - val_loss: 0.1144\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.1065 - val_loss: 0.1143\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.1060 - val_loss: 0.1133\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.1056 - val_loss: 0.1141\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.1053 - val_loss: 0.1137\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.1049 - val_loss: 0.1130\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.1044 - val_loss: 0.1124\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.1040 - val_loss: 0.1120\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.1037 - val_loss: 0.1117\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.1032 - val_loss: 0.1112\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.1028 - val_loss: 0.1110\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.1024 - val_loss: 0.1106\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.1020 - val_loss: 0.1105\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.1017 - val_loss: 0.1102\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.1012 - val_loss: 0.1100\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.1009 - val_loss: 0.1095\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.1005 - val_loss: 0.1093\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.1001 - val_loss: 0.1090\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.0998 - val_loss: 0.1087\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0994 - val_loss: 0.1087\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0991 - val_loss: 0.1082\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.0986 - val_loss: 0.1082\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.0983 - val_loss: 0.1074\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.0979 - val_loss: 0.1067\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0976 - val_loss: 0.1068\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0973 - val_loss: 0.1066\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.0969 - val_loss: 0.1064\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 3s 274us/step - loss: 0.0966 - val_loss: 0.1055\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 0.0962 - val_loss: 0.1058\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0958 - val_loss: 0.1053\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0955 - val_loss: 0.1053\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0952 - val_loss: 0.1049\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.0949 - val_loss: 0.1048\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 3s 274us/step - loss: 0.0946 - val_loss: 0.1043\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.0943 - val_loss: 0.1039\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.0939 - val_loss: 0.1040\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0936 - val_loss: 0.1041\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0933 - val_loss: 0.1033\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 3s 281us/step - loss: 0.0930 - val_loss: 0.1032\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.0926 - val_loss: 0.1028\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.0924 - val_loss: 0.1030\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 3.3826 - val_loss: 0.7724\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.8510 - val_loss: 1.2420\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.6476 - val_loss: 0.3291\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: 0.5894 - val_loss: 0.3267\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.5445 - val_loss: 0.2704\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.5109 - val_loss: 0.8320\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.4702 - val_loss: 0.7598\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 0.4678 - val_loss: 0.3424\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.4365 - val_loss: 0.2830\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.4330 - val_loss: 0.5867\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4179 - val_loss: 0.8875\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.4155 - val_loss: 0.3273\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.4191 - val_loss: 0.5337\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.3791 - val_loss: 0.9088\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.3880 - val_loss: 0.2797\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.3961 - val_loss: 0.5153\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.3847 - val_loss: 0.2551\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.3689 - val_loss: 0.2978\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.3689 - val_loss: 0.2043\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.3715 - val_loss: 0.3867\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3579 - val_loss: 0.2164\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.3436 - val_loss: 0.2665\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.3634 - val_loss: 0.2401\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.3518 - val_loss: 0.2173\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.3511 - val_loss: 0.2976\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.3337 - val_loss: 0.2367\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.3428 - val_loss: 0.2032\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.3362 - val_loss: 0.3546\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.3285 - val_loss: 0.2311\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.3330 - val_loss: 0.1836\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.3256 - val_loss: 0.1739\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.3227 - val_loss: 0.2362\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.3201 - val_loss: 0.2008\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3278 - val_loss: 0.2659\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.3261 - val_loss: 0.2277\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.3207 - val_loss: 0.2147\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.3234 - val_loss: 0.2458\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3311 - val_loss: 0.4695\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.3001 - val_loss: 1.1830\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.3192 - val_loss: 1.1991\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.3146 - val_loss: 0.5303\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.3048 - val_loss: 0.1930\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.2974 - val_loss: 0.1980\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.3039 - val_loss: 0.3921\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.3053 - val_loss: 0.2620\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.3185 - val_loss: 0.1836\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2882 - val_loss: 0.1909\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 3s 278us/step - loss: 0.2901 - val_loss: 0.1701\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: 0.2954 - val_loss: 0.9027\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 3s 276us/step - loss: 0.3117 - val_loss: 0.2035\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.2925 - val_loss: 0.1987\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.2913 - val_loss: 0.1542\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.2848 - val_loss: 0.3606\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2945 - val_loss: 0.5109\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.2944 - val_loss: 0.1665\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.2902 - val_loss: 0.2863\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.2887 - val_loss: 0.1769\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.3024 - val_loss: 0.3346\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2930 - val_loss: 0.1758\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.2871 - val_loss: 0.1782\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2757 - val_loss: 1.5331\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2881 - val_loss: 0.1871\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2663 - val_loss: 0.5498\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2751 - val_loss: 0.6961\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2789 - val_loss: 0.1579\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2680 - val_loss: 0.4012\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2804 - val_loss: 0.6645\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - ETA: 0s - loss: 0.284 - 2s 173us/step - loss: 0.2833 - val_loss: 1.0575\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2892 - val_loss: 0.6765\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2754 - val_loss: 0.1804\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2875 - val_loss: 0.2189\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2697 - val_loss: 0.3449\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.2804 - val_loss: 0.6081\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2903 - val_loss: 0.2078\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.2566 - val_loss: 0.1559\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2759 - val_loss: 0.1886\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.2779 - val_loss: 0.1543\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.2685 - val_loss: 0.1805\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.2659 - val_loss: 0.2590\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2734 - val_loss: 0.1547\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.2612 - val_loss: 0.1401\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2689 - val_loss: 0.1944\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2628 - val_loss: 0.1774\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.2676 - val_loss: 0.3491\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2726 - val_loss: 0.7607\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2722 - val_loss: 0.4641\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2761 - val_loss: 0.2709\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2785 - val_loss: 0.1995\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2837 - val_loss: 0.3022\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2651 - val_loss: 0.2664\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.2893 - val_loss: 0.2126\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.2569 - val_loss: 0.4895\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2736 - val_loss: 0.2103\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2767 - val_loss: 0.2763\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2721 - val_loss: 0.2238\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2733 - val_loss: 0.6136\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2637 - val_loss: 0.2734\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2745 - val_loss: 0.1415\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.2823 - val_loss: 0.2660\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.2741 - val_loss: 0.4538\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2726 - val_loss: 0.1664\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2829 - val_loss: 0.4581\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2682 - val_loss: 0.4036\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.2730 - val_loss: 0.3134\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2740 - val_loss: 0.2918\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.2803 - val_loss: 0.1593\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2592 - val_loss: 0.4893\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2667 - val_loss: 0.1402\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.2647 - val_loss: 0.1727\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.2729 - val_loss: 1.3328\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2549 - val_loss: 0.9735\n",
      "Epoch 112/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.2698 - val_loss: 0.2361\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.2697 - val_loss: 0.2645\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.2668 - val_loss: 0.2666\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.2529 - val_loss: 0.1884\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.2499 - val_loss: 0.5544\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.2486 - val_loss: 0.1480\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.2614 - val_loss: 0.1898\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2673 - val_loss: 0.1598\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2526 - val_loss: 0.8266\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2630 - val_loss: 0.3580\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2682 - val_loss: 0.2205\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2626 - val_loss: 0.2647\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2500 - val_loss: 0.1532\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2620 - val_loss: 0.1871\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.2665 - val_loss: 0.3595\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2596 - val_loss: 0.3331\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2588 - val_loss: 0.1541\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.2540 - val_loss: 0.4420\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.2659 - val_loss: 0.1651\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2503 - val_loss: 0.3366\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2517 - val_loss: 0.5312\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2498 - val_loss: 0.2616\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2436 - val_loss: 0.1635\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2526 - val_loss: 0.1607\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2623 - val_loss: 0.2092\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2569 - val_loss: 0.3801\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2578 - val_loss: 0.6547\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2480 - val_loss: 0.5229\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2617 - val_loss: 0.1430\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2519 - val_loss: 0.1583\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2508 - val_loss: 0.2146\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.2492 - val_loss: 0.3264\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2517 - val_loss: 0.1558\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2657 - val_loss: 0.1666\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2406 - val_loss: 0.4646\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2430 - val_loss: 0.4851\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2300 - val_loss: 0.5474\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2344 - val_loss: 0.1815\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2533 - val_loss: 0.2013\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2451 - val_loss: 0.1339\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2553 - val_loss: 0.1707\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2489 - val_loss: 0.1962\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2554 - val_loss: 0.1431\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2468 - val_loss: 0.4188\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2507 - val_loss: 0.1996\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2442 - val_loss: 0.9036\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2378 - val_loss: 0.1241\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2385 - val_loss: 0.1973\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2418 - val_loss: 0.2183\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2285 - val_loss: 0.1896\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2368 - val_loss: 0.5666\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2501 - val_loss: 0.1999\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2382 - val_loss: 0.2306\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2398 - val_loss: 0.3179\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2431 - val_loss: 0.1325\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2324 - val_loss: 0.2690\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2342 - val_loss: 0.1801\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2311 - val_loss: 0.2397\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2304 - val_loss: 0.2652\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2271 - val_loss: 0.1138\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2390 - val_loss: 0.1483\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2400 - val_loss: 0.2871\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2391 - val_loss: 1.1291\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.2397 - val_loss: 0.2977\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.2344 - val_loss: 0.2276\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.2270 - val_loss: 0.1755\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2339 - val_loss: 0.2883\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2332 - val_loss: 0.6753\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2394 - val_loss: 0.1754\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2326 - val_loss: 0.1400\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2367 - val_loss: 0.1980\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2381 - val_loss: 0.1832\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.2364 - val_loss: 0.2272\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2362 - val_loss: 0.3225\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.2309 - val_loss: 0.1999\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.2334 - val_loss: 0.8961\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.2373 - val_loss: 0.2061\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.2365 - val_loss: 0.1719\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.2346 - val_loss: 0.2097\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2255 - val_loss: 0.3832\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2283 - val_loss: 0.1598\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.2472 - val_loss: 0.1304\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2200 - val_loss: 0.5453\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2348 - val_loss: 0.1372\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.2280 - val_loss: 0.2062\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.2151 - val_loss: 0.9981\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2226 - val_loss: 0.2920\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2370 - val_loss: 0.1668\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.2364 - val_loss: 0.1532\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.2318 - val_loss: 0.2044\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2382 - val_loss: 0.1413\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.2308 - val_loss: 0.2557\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2296 - val_loss: 0.7962\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.2316 - val_loss: 0.3672\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.2539 - val_loss: 0.1821\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.2198 - val_loss: 0.2628\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.2354 - val_loss: 0.1526\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.2253 - val_loss: 0.5456\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.2212 - val_loss: 0.1853\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.2350 - val_loss: 0.3585\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.2249 - val_loss: 0.1136\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.2280 - val_loss: 0.1276\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.2169 - val_loss: 1.1305\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.2255 - val_loss: 0.2930\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.2354 - val_loss: 0.6271\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2296 - val_loss: 0.2741\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.2110 - val_loss: 0.5267\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 3s 285us/step - loss: 0.2349 - val_loss: 0.1624\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.2219 - val_loss: 0.1456\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.2294 - val_loss: 0.2516\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.2363 - val_loss: 0.1946\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.2253 - val_loss: 0.1327\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.2256 - val_loss: 0.2339\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.2276 - val_loss: 0.1926\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.2273 - val_loss: 0.2017\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.2192 - val_loss: 0.1619\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.2334 - val_loss: 0.1372\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2067 - val_loss: 0.6990\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2237 - val_loss: 0.1155\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2124 - val_loss: 0.2056\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2235 - val_loss: 0.4524\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2279 - val_loss: 0.1791\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2222 - val_loss: 0.2768\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2308 - val_loss: 0.1581\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2206 - val_loss: 0.1783\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2237 - val_loss: 0.2704\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2124 - val_loss: 0.1540\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2084 - val_loss: 0.1843\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2215 - val_loss: 0.3544\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2205 - val_loss: 0.2223\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.2150 - val_loss: 0.1215\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2097 - val_loss: 0.3338\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2212 - val_loss: 0.4085\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.2131 - val_loss: 0.2025\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2083 - val_loss: 0.1543\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2254 - val_loss: 0.3336\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2142 - val_loss: 0.4231\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2085 - val_loss: 0.1341\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2084 - val_loss: 0.3499\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 3.6279 - val_loss: 0.2650\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.2088 - val_loss: 0.1994\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.1734 - val_loss: 0.1810\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.1611 - val_loss: 0.1715\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.1625 - val_loss: 0.2012\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.1686 - val_loss: 0.1738\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.1443 - val_loss: 0.1580\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1720 - val_loss: 0.1797\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1850 - val_loss: 0.1917\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1738 - val_loss: 0.2023\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.1950 - val_loss: 0.2188\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.1751 - val_loss: 0.1736\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.1936 - val_loss: 0.1803\n",
      "Epoch 14/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1625 - val_loss: 0.2531\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.1875 - val_loss: 0.2039\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1947 - val_loss: 0.1882\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.2051 - val_loss: 0.2298\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.2108 - val_loss: 0.2618\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2477 - val_loss: 0.2382\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2494 - val_loss: 0.3001\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.2515 - val_loss: 0.2446\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.2414 - val_loss: 0.2612\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.2161 - val_loss: 0.2450\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.2432 - val_loss: 0.2308\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.2125 - val_loss: 0.2296\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1889 - val_loss: 0.2073\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2202 - val_loss: 0.3285\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.2267 - val_loss: 0.2422\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 0.2136 - val_loss: 0.2232\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.2155 - val_loss: 0.2017\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.2159 - val_loss: 0.2183\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.2076 - val_loss: 0.2206\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.2102 - val_loss: 0.2745\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1880 - val_loss: 0.2595\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.1910 - val_loss: 0.1789\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1599 - val_loss: 0.1881\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 0.1737 - val_loss: 0.2516\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.2037 - val_loss: 0.2316\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1859 - val_loss: 0.1924\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1695 - val_loss: 0.1795\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1840 - val_loss: 0.1937\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1659 - val_loss: 0.2147\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.1935 - val_loss: 0.2058\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.2069 - val_loss: 0.2627\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.1852 - val_loss: 0.2430\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.2077 - val_loss: 0.2337\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1695 - val_loss: 0.2113\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.1898 - val_loss: 0.1929\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.2202 - val_loss: 0.2213\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.2126 - val_loss: 0.2686\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1750 - val_loss: 0.1716\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.1625 - val_loss: 0.1819\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.1596 - val_loss: 0.1869\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1643 - val_loss: 0.3103\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.1860 - val_loss: 0.1675\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.1670 - val_loss: 0.1662\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1892 - val_loss: 0.1701\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.1628 - val_loss: 0.1619\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.1808 - val_loss: 0.1787\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.1702 - val_loss: 0.1467\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.1470 - val_loss: 0.1906\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1525 - val_loss: 0.1583\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 240us/step - loss: 0.1520 - val_loss: 0.1625\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 0.1824 - val_loss: 0.2147\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.1564 - val_loss: 0.1596\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.1394 - val_loss: 0.1766\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.1386 - val_loss: 0.1662\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1447 - val_loss: 0.1478\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.1522 - val_loss: 0.1666\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.1682 - val_loss: 0.2469\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.1738 - val_loss: 0.1880\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1694 - val_loss: 0.2716\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1502 - val_loss: 0.1898\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.2153 - val_loss: 0.2570\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.2086 - val_loss: 0.2139\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.1867 - val_loss: 0.2163\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.1833 - val_loss: 0.1506\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1589 - val_loss: 0.1996\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1322 - val_loss: 0.1362\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1424 - val_loss: 0.1760\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.1710 - val_loss: 0.2075\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.1970 - val_loss: 0.2029\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.1612 - val_loss: 0.1825\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 0.1853 - val_loss: 0.2173\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.1705 - val_loss: 0.1870\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.1748 - val_loss: 0.1647\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.1422 - val_loss: 0.1605\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.1637 - val_loss: 0.1690\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 0.1523 - val_loss: 0.1721\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.1673 - val_loss: 0.2260\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.1561 - val_loss: 0.2264\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.1652 - val_loss: 0.1823\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.1668 - val_loss: 0.1587\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.1514 - val_loss: 0.1817\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1688 - val_loss: 0.2167\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1428 - val_loss: 0.1641\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.1536 - val_loss: 0.2474\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1670 - val_loss: 0.2170\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1640 - val_loss: 0.1798\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1689 - val_loss: 0.2013\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.1777 - val_loss: 0.1903\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1306 - val_loss: 0.1681\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1468 - val_loss: 0.2076\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.1514 - val_loss: 0.1646\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1433 - val_loss: 0.1878\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1555 - val_loss: 0.1527\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1501 - val_loss: 0.1494\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1492 - val_loss: 0.2779\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.1648 - val_loss: 0.1484\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1696 - val_loss: 0.1653\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.1864 - val_loss: 0.2025\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1824 - val_loss: 0.1906\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1803 - val_loss: 0.2222\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1728 - val_loss: 0.2066\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1773 - val_loss: 0.2305\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1458 - val_loss: 0.1560\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1504 - val_loss: 0.1829\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1398 - val_loss: 0.1501\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1542 - val_loss: 0.2163\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.1501 - val_loss: 0.1710\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.1177 - val_loss: 0.1263\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.1152 - val_loss: 0.1401\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1375 - val_loss: 0.1353\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1276 - val_loss: 0.1391\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1571 - val_loss: 0.1672\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1558 - val_loss: 0.2090\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.1417 - val_loss: 0.2831\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.1459 - val_loss: 0.2058\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.1386 - val_loss: 0.1583\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1260 - val_loss: 0.1459\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1335 - val_loss: 0.1391\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1241 - val_loss: 0.1534\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1397 - val_loss: 0.1554\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1368 - val_loss: 0.2068\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1557 - val_loss: 0.1654\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1385 - val_loss: 0.1518\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1595 - val_loss: 0.2087\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.1439 - val_loss: 0.1726\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.1597 - val_loss: 0.2572\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.1643 - val_loss: 0.1837\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1904 - val_loss: 0.2080\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1821 - val_loss: 0.3395\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1673 - val_loss: 0.1736\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1713 - val_loss: 0.2244\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.1723 - val_loss: 0.2360\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1679 - val_loss: 0.2022\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1732 - val_loss: 0.1783\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1691 - val_loss: 0.1839\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1637 - val_loss: 0.1721\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1662 - val_loss: 0.1616\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - ETA: 0s - loss: 0.169 - 2s 208us/step - loss: 0.1700 - val_loss: 0.2004\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.1443 - val_loss: 0.1376\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1411 - val_loss: 0.1531\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.1466 - val_loss: 0.1566\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1392 - val_loss: 0.1519\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1299 - val_loss: 0.1537\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1303 - val_loss: 0.1375\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.1402 - val_loss: 0.2403\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1535 - val_loss: 0.1785\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.1400 - val_loss: 0.1677\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1280 - val_loss: 0.1618\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1310 - val_loss: 0.1559\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1212 - val_loss: 0.1819\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1474 - val_loss: 0.1546\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1210 - val_loss: 0.1565\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1296 - val_loss: 0.1444\n",
      "Epoch 167/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1321 - val_loss: 0.1493\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1352 - val_loss: 0.1393\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1292 - val_loss: 0.1305\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1314 - val_loss: 0.1653\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1413 - val_loss: 0.1505\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1359 - val_loss: 0.1685\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1267 - val_loss: 0.2042\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1647 - val_loss: 0.1970\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1535 - val_loss: 0.1426\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1413 - val_loss: 0.1419\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1360 - val_loss: 0.1478\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1454 - val_loss: 0.1370\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1344 - val_loss: 0.1893\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1482 - val_loss: 0.1666\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1359 - val_loss: 0.2604\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1259 - val_loss: 0.1949\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1339 - val_loss: 0.2283\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.1414 - val_loss: 0.1783\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1215 - val_loss: 0.1858\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.1209 - val_loss: 0.1650\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1478 - val_loss: 0.1581\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1358 - val_loss: 0.1469\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1366 - val_loss: 0.1392\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1246 - val_loss: 0.1273\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1297 - val_loss: 0.1523\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1392 - val_loss: 0.1542\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1343 - val_loss: 0.1567\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1420 - val_loss: 0.1634\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1469 - val_loss: 0.1388\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1290 - val_loss: 0.1349\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1202 - val_loss: 0.2273\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.1257 - val_loss: 0.1670\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1377 - val_loss: 0.1260\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1357 - val_loss: 0.1479\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1365 - val_loss: 0.1386\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1337 - val_loss: 0.1235\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1406 - val_loss: 0.1325\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1148 - val_loss: 0.1225\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1293 - val_loss: 0.1126\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.1199 - val_loss: 0.1269\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1240 - val_loss: 0.1382\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1123 - val_loss: 0.1235\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1189 - val_loss: 0.1592\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1292 - val_loss: 0.1783\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.1640 - val_loss: 0.1812\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1370 - val_loss: 0.1588\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.1226 - val_loss: 0.1175\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1354 - val_loss: 0.1516\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.1374 - val_loss: 0.2002\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1202 - val_loss: 0.1693\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1264 - val_loss: 0.1672\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.1401 - val_loss: 0.1890\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1656 - val_loss: 0.1562\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1600 - val_loss: 0.1618\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1304 - val_loss: 0.1366\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1363 - val_loss: 0.2239\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1288 - val_loss: 0.1490\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.1449 - val_loss: 0.1366\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1543 - val_loss: 0.1484\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1423 - val_loss: 0.1711\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1500 - val_loss: 0.2707\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1688 - val_loss: 0.2042\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1508 - val_loss: 0.1610\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1348 - val_loss: 0.2232\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1320 - val_loss: 0.1542\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1300 - val_loss: 0.1624\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1257 - val_loss: 0.1613\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1255 - val_loss: 0.1560\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1509 - val_loss: 0.1646\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1362 - val_loss: 0.1422\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1219 - val_loss: 0.1600\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1315 - val_loss: 0.1764\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1170 - val_loss: 0.1227\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.1206 - val_loss: 0.1413\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.1236 - val_loss: 0.1466\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1595 - val_loss: 0.1661\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1353 - val_loss: 0.1477\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1260 - val_loss: 0.1581\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1448 - val_loss: 0.1927\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.1297 - val_loss: 0.1346\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1323 - val_loss: 0.1524\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.1289 - val_loss: 0.1299\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1187 - val_loss: 0.1385\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1257 - val_loss: 0.1357\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "moptimizer = Adagrad(lr=0.01)\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_ada_sig = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "moptimizer = Adadelta(lr=0.01)\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_adadel_sig = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "moptimizer = RMSprop(lr=0.01)\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_rms_sig= model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "moptimizer = Adam(lr=0.01)\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_adam_sig = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1584 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2,figsize=(16,22))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(history_ada_sig.history['val_loss'])\n",
    "plt.plot(history_ada_sig.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDE--OPTIMIZADOR ADAGRAD')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(history_adadel_sig.history['val_loss'])\n",
    "plt.plot(history_adadel_sig.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDE--OPTIMIZADOR ADADELTA')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(history_rms_sig.history['val_loss'])\n",
    "plt.plot(history_rms_sig.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDE--OPTIMIZADOR RMSPROP')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(history_adam_sig.history['val_loss'])\n",
    "plt.plot(history_adam_sig.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDE--OPTIMIZADOR ADAM')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify>En esta primera sección podemos observar que la rapidez en la que converge el optimizador <b><font color=red>ADAM</b></font> es bastante superior a todos los demas, mientras que el <b><font color=green>RMSprop</b></font> demostró ser el más lento de todos los optimizadores, así como el que tiene la mayor cantidad de error en la función de pérdida de la validación de la red neuronal, esto es muy interesante y se puede analizar de muchos sentidos, en el caso particular de este set de datos el optimizador <b><font color=blue>ADAGRAD</b></font> es el que tiene el mejor comportamiento de todos los modelos entrenados hasta el momento, con un tiempo de convergencia muy pequeño y sobre todo lo mas interesante es que los valores de las funciones de pérdida en ambos set de datos es la misma, esta ubicado muy cercano a cero.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 21.7325 - val_loss: 11.9543\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 6.6375 - val_loss: 7.0482\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 4.0506 - val_loss: 5.3121\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 2.8521 - val_loss: 4.1632\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 2.1783 - val_loss: 3.5836\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 1.8232 - val_loss: 3.0609\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 1.5271 - val_loss: 2.8148\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 1.3405 - val_loss: 2.5149\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 1.1948 - val_loss: 2.3889\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 1.0839 - val_loss: 2.2830\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.9789 - val_loss: 2.1559\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.9230 - val_loss: 2.0029\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.8639 - val_loss: 2.0186\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.8166 - val_loss: 1.9288\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.7725 - val_loss: 1.8543\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - ETA: 0s - loss: 0.745 - 2s 190us/step - loss: 0.7422 - val_loss: 1.7962\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.7028 - val_loss: 1.7393\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.6776 - val_loss: 1.7715\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.6528 - val_loss: 1.6640\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.6329 - val_loss: 1.6783\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.6098 - val_loss: 1.6308\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.5923 - val_loss: 1.6038\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.5775 - val_loss: 1.5684\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.5624 - val_loss: 1.5689\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.5466 - val_loss: 1.5644\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.5338 - val_loss: 1.5434\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.5210 - val_loss: 1.5053\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.5101 - val_loss: 1.5047\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.4991 - val_loss: 1.4724\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.4884 - val_loss: 1.4526\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.4780 - val_loss: 1.4505\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.4695 - val_loss: 1.4207\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.4604 - val_loss: 1.3850\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.4526 - val_loss: 1.3741\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.4435 - val_loss: 1.3800\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.4362 - val_loss: 1.3574\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.4297 - val_loss: 1.3572\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.4228 - val_loss: 1.3444\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.4141 - val_loss: 1.3190\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.4092 - val_loss: 1.3094\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.4033 - val_loss: 1.3149\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.3963 - val_loss: 1.2777\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 0.3904 - val_loss: 1.2757\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3845 - val_loss: 1.2722\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.3791 - val_loss: 1.2582\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.3729 - val_loss: 1.2566\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.3708 - val_loss: 1.2218\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.3651 - val_loss: 1.2147\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.3616 - val_loss: 1.2149\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.3552 - val_loss: 1.2626\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.3528 - val_loss: 1.2217\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.3477 - val_loss: 1.1975\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.3442 - val_loss: 1.1918\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.3400 - val_loss: 1.1920\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 0.3346 - val_loss: 1.1774\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.3319 - val_loss: 1.1830\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.3282 - val_loss: 1.1568\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.3254 - val_loss: 1.1551\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.3207 - val_loss: 1.1545\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 0.3178 - val_loss: 1.1265\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.3152 - val_loss: 1.1310\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.3113 - val_loss: 1.1274\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.3089 - val_loss: 1.1050\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.3059 - val_loss: 1.1230\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.3022 - val_loss: 1.1293\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.3004 - val_loss: 1.0900\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.2960 - val_loss: 1.0918\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.2949 - val_loss: 1.0759\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 193us/step - loss: 0.2916 - val_loss: 1.0633\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.2895 - val_loss: 1.0766\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.2865 - val_loss: 1.0517\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 0.2845 - val_loss: 1.0830\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 190us/step - loss: 0.2823 - val_loss: 1.0592\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2791 - val_loss: 1.0630\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2763 - val_loss: 1.0528\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 191us/step - loss: 0.2743 - val_loss: 1.0549\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.2718 - val_loss: 1.0492\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.2698 - val_loss: 1.0355\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2685 - val_loss: 1.0242\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2658 - val_loss: 1.0273\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.2629 - val_loss: 1.0370\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.2613 - val_loss: 1.0045\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.2597 - val_loss: 1.0122\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2579 - val_loss: 1.0024\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2563 - val_loss: 0.9913\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2542 - val_loss: 0.9922\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2518 - val_loss: 0.9853\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - ETA: 0s - loss: 0.250 - 2s 180us/step - loss: 0.2503 - val_loss: 0.9897\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.2477 - val_loss: 0.9967\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.2463 - val_loss: 0.9867\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2444 - val_loss: 0.9660\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2437 - val_loss: 0.9651\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.2416 - val_loss: 0.9621\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.2395 - val_loss: 0.9570\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.2384 - val_loss: 0.9759\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2363 - val_loss: 0.9609\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2347 - val_loss: 0.9393\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2332 - val_loss: 0.9530\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.2321 - val_loss: 0.9434\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.2303 - val_loss: 0.9534\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.2290 - val_loss: 0.9384\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2279 - val_loss: 0.9332\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2260 - val_loss: 0.9282\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2247 - val_loss: 0.9379\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.2233 - val_loss: 0.9221\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2221 - val_loss: 0.9161\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 0.2202 - val_loss: 0.9072\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2198 - val_loss: 0.9247\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 0.2184 - val_loss: 0.9171\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2172 - val_loss: 0.9120\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2150 - val_loss: 0.9113\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2143 - val_loss: 0.9049\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 190us/step - loss: 0.2128 - val_loss: 0.9016\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2120 - val_loss: 0.9022\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.2110 - val_loss: 0.8967\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2099 - val_loss: 0.8913\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 187us/step - loss: 0.2087 - val_loss: 0.9000\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.2071 - val_loss: 0.8794\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2066 - val_loss: 0.8860\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2047 - val_loss: 0.8987\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.2043 - val_loss: 0.8837\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.2030 - val_loss: 0.8691\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.2017 - val_loss: 0.8692\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2009 - val_loss: 0.8660\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2000 - val_loss: 0.8765\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.1987 - val_loss: 0.8619\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1979 - val_loss: 0.8595\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.1968 - val_loss: 0.8579\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1961 - val_loss: 0.8696\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1949 - val_loss: 0.8638\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1939 - val_loss: 0.8533\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1930 - val_loss: 0.8585\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1921 - val_loss: 0.8422\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1915 - val_loss: 0.8442\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1899 - val_loss: 0.8456\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.1892 - val_loss: 0.8487\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.1884 - val_loss: 0.8353\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1877 - val_loss: 0.8366\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.1864 - val_loss: 0.8285\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.1855 - val_loss: 0.8358\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.1848 - val_loss: 0.8337\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1839 - val_loss: 0.8323\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1830 - val_loss: 0.8296\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.1822 - val_loss: 0.8272\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.1816 - val_loss: 0.8132\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.1809 - val_loss: 0.8196\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1799 - val_loss: 0.8279\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.1792 - val_loss: 0.8200\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.1780 - val_loss: 0.8145\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.1775 - val_loss: 0.8163\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.1769 - val_loss: 0.8092\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.1755 - val_loss: 0.8006\n",
      "Epoch 153/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.1750 - val_loss: 0.8128\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.1738 - val_loss: 0.8197\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.1738 - val_loss: 0.7991\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 160us/step - loss: 0.1727 - val_loss: 0.8023\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1723 - val_loss: 0.8086\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.1708 - val_loss: 0.7934\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1706 - val_loss: 0.7914\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.1701 - val_loss: 0.7933\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 167us/step - loss: 0.1693 - val_loss: 0.7938\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 162us/step - loss: 0.1683 - val_loss: 0.7988\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1677 - val_loss: 0.7949\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.1672 - val_loss: 0.7826\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1664 - val_loss: 0.7941\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.1659 - val_loss: 0.7878\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.1653 - val_loss: 0.7831\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1646 - val_loss: 0.7869\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.1640 - val_loss: 0.7832\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.1631 - val_loss: 0.7809\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.1624 - val_loss: 0.7748\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.1615 - val_loss: 0.7725\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.1614 - val_loss: 0.7730\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.1612 - val_loss: 0.7791\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.1599 - val_loss: 0.7738\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.1596 - val_loss: 0.7672\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1588 - val_loss: 0.7658\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1584 - val_loss: 0.7617\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1578 - val_loss: 0.7574\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.1572 - val_loss: 0.7566\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1560 - val_loss: 0.7597\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1556 - val_loss: 0.7655\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1553 - val_loss: 0.7549\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1551 - val_loss: 0.7559\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.1544 - val_loss: 0.7569\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.1534 - val_loss: 0.7604\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1534 - val_loss: 0.7495\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.1526 - val_loss: 0.7501\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.1521 - val_loss: 0.7464\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.1516 - val_loss: 0.7449\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.1510 - val_loss: 0.7465\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1506 - val_loss: 0.7376\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.1498 - val_loss: 0.7524\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 166us/step - loss: 0.1495 - val_loss: 0.7499\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 168us/step - loss: 0.1489 - val_loss: 0.7393\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.1486 - val_loss: 0.7404\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1479 - val_loss: 0.7419\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 164us/step - loss: 0.1472 - val_loss: 0.7492\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 161us/step - loss: 0.1470 - val_loss: 0.7278\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.1465 - val_loss: 0.7288\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 165us/step - loss: 0.1461 - val_loss: 0.7321\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1457 - val_loss: 0.7283\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.1452 - val_loss: 0.7300\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.1444 - val_loss: 0.7264\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.1441 - val_loss: 0.7233\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.1436 - val_loss: 0.7236\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.1431 - val_loss: 0.7285\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1430 - val_loss: 0.7200\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1424 - val_loss: 0.7156\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.1418 - val_loss: 0.7242\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1416 - val_loss: 0.7231\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.1410 - val_loss: 0.7226\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1406 - val_loss: 0.7184\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.1403 - val_loss: 0.7181\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 0.1395 - val_loss: 0.7085\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.1390 - val_loss: 0.7190\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1388 - val_loss: 0.7124s \n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.1384 - val_loss: 0.7025\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 190us/step - loss: 0.1380 - val_loss: 0.7065\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.1377 - val_loss: 0.7035\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1369 - val_loss: 0.6986\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1369 - val_loss: 0.7065\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1366 - val_loss: 0.7126\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.1362 - val_loss: 0.7074\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.1358 - val_loss: 0.7034\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.1354 - val_loss: 0.6961\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.1348 - val_loss: 0.7031\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.1344 - val_loss: 0.6951\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.1341 - val_loss: 0.7032\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.1337 - val_loss: 0.6998\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.1332 - val_loss: 0.7004\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 192us/step - loss: 0.1328 - val_loss: 0.6901\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.1327 - val_loss: 0.6933\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.1318 - val_loss: 0.6896\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1317 - val_loss: 0.6957\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.1315 - val_loss: 0.6905\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1312 - val_loss: 0.6917\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.1308 - val_loss: 0.6909\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.1303 - val_loss: 0.6895\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1300 - val_loss: 0.6900\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.1295 - val_loss: 0.6790\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.1294 - val_loss: 0.6871\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 163us/step - loss: 0.1291 - val_loss: 0.6831\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1286 - val_loss: 0.6837\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1281 - val_loss: 0.6837\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 190us/step - loss: 0.1281 - val_loss: 0.6737\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.1275 - val_loss: 0.6848\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1273 - val_loss: 0.6720\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1270 - val_loss: 0.6849\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1265 - val_loss: 0.6726\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 3s 281us/step - loss: 129.2816 - val_loss: 143.0032\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 121.9164 - val_loss: 134.2349\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 114.4877 - val_loss: 125.5519\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 107.0391 - val_loss: 116.9957\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 99.6376 - val_loss: 108.6821\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 92.3252 - val_loss: 100.5737\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 85.1056 - val_loss: 92.7015\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 77.9875 - val_loss: 85.0624\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 71.0526 - val_loss: 77.7357\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 64.4027 - val_loss: 70.8162\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 58.1070 - val_loss: 64.3283\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 240us/step - loss: 52.2376 - val_loss: 58.3494\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 46.9246 - val_loss: 52.9473\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 42.1617 - val_loss: 48.0751\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 37.9334 - val_loss: 43.7211\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 34.2942 - val_loss: 39.9701\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 31.1589 - val_loss: 36.6274\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 28.4362 - val_loss: 33.7034\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 26.0631 - val_loss: 31.1067\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 23.9562 - val_loss: 28.7988\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 22.1164 - val_loss: 26.7727\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 20.4995 - val_loss: 25.0045\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 19.0909 - val_loss: 23.4442\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 17.8268 - val_loss: 22.0436\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 16.7149 - val_loss: 20.8042\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 15.7423 - val_loss: 19.7412\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 14.8892 - val_loss: 18.7863\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 14.1351 - val_loss: 17.9509\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 13.4629 - val_loss: 17.2072\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 12.8744 - val_loss: 16.5511\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 12.3520 - val_loss: 15.9686\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 11.8852 - val_loss: 15.4505\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 11.4871 - val_loss: 15.0047\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 11.1322 - val_loss: 14.6055\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 10.8181 - val_loss: 14.2530\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 10.5306 - val_loss: 13.9171\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 10.2760 - val_loss: 13.6317\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 10.0527 - val_loss: 13.3833\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 9.8553 - val_loss: 13.1551\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 9.6694 - val_loss: 12.9365\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 9.4891 - val_loss: 12.7326\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 240us/step - loss: 9.3266 - val_loss: 12.5365\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 9.1663 - val_loss: 12.3444\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 9.0166 - val_loss: 12.1693\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 8.8735 - val_loss: 11.9985\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 8.7388 - val_loss: 11.8481\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 8.6125 - val_loss: 11.6977\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 8.4929 - val_loss: 11.5545\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 8.3687 - val_loss: 11.4182\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 8.2530 - val_loss: 11.2853\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 8.1384 - val_loss: 11.1428\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 8.0277 - val_loss: 11.0102\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 7.9100 - val_loss: 10.8649\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 7.7983 - val_loss: 10.7369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 7.6951 - val_loss: 10.6172\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 7.5954 - val_loss: 10.4991\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 7.4895 - val_loss: 10.3772\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 7.3915 - val_loss: 10.2592\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 7.2943 - val_loss: 10.1396\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 7.1964 - val_loss: 10.0247\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 7.0993 - val_loss: 9.9101\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 7.0076 - val_loss: 9.8038\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 6.9201 - val_loss: 9.6933\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 6.8278 - val_loss: 9.5874\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 6.7408 - val_loss: 9.4849\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 6.6496 - val_loss: 9.3830\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 6.5651 - val_loss: 9.2764\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 6.4818 - val_loss: 9.1744\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 6.3957 - val_loss: 9.0697\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 6.3081 - val_loss: 8.9676\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 6.2231 - val_loss: 8.8664\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 6.1468 - val_loss: 8.7719\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 6.0662 - val_loss: 8.6747\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 5.9850 - val_loss: 8.5764\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 5.9052 - val_loss: 8.4867\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 5.8313 - val_loss: 8.3996\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 5.7570 - val_loss: 8.3084\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 5.6836 - val_loss: 8.2196\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 5.6096 - val_loss: 8.1264\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 5.5380 - val_loss: 8.0452\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 5.4677 - val_loss: 7.9579\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 5.3988 - val_loss: 7.8709\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 5.3261 - val_loss: 7.7873\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 5.2593 - val_loss: 7.7118\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 5.1998 - val_loss: 7.6302\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 5.1321 - val_loss: 7.5553\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 5.0699 - val_loss: 7.4787\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 5.0098 - val_loss: 7.4021\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 4.9429 - val_loss: 7.3282\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 4.8857 - val_loss: 7.2662\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 4.8290 - val_loss: 7.1953\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 4.7693 - val_loss: 7.1225\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 4.7106 - val_loss: 7.0533\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 4.6545 - val_loss: 6.9865\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 4.6067 - val_loss: 6.9260\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 4.5453 - val_loss: 6.8569\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 4.4896 - val_loss: 6.7882\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 4.4363 - val_loss: 6.7251\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 4.3862 - val_loss: 6.6666\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 4.3377 - val_loss: 6.6123\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 4.2926 - val_loss: 6.5542\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 4.2425 - val_loss: 6.4974\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 4.1949 - val_loss: 6.4434\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 4.1554 - val_loss: 6.3971\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 4.1115 - val_loss: 6.3424\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 4.0663 - val_loss: 6.2944\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 4.0249 - val_loss: 6.2444\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.9871 - val_loss: 6.1948\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.9418 - val_loss: 6.1459\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.9026 - val_loss: 6.0935\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.8618 - val_loss: 6.0436\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.8213 - val_loss: 5.9956\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.7835 - val_loss: 5.9472\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.7476 - val_loss: 5.9011\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.7108 - val_loss: 5.8611\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.6722 - val_loss: 5.8204\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.6396 - val_loss: 5.7743\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.6050 - val_loss: 5.7343\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.5712 - val_loss: 5.6989\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.5383 - val_loss: 5.6566\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 3.5084 - val_loss: 5.6210\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 3.4801 - val_loss: 5.5799\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.4479 - val_loss: 5.5457\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 3.4188 - val_loss: 5.5101\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 3.3905 - val_loss: 5.4748\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.3649 - val_loss: 5.4443\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 3.3374 - val_loss: 5.4132\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.3083 - val_loss: 5.3736\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 3.2819 - val_loss: 5.3414\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.2557 - val_loss: 5.3074\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.2286 - val_loss: 5.2767\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 3.2014 - val_loss: 5.2499\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.1792 - val_loss: 5.2180\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.1545 - val_loss: 5.1872\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.1292 - val_loss: 5.1563\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 3.1078 - val_loss: 5.1259\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.0831 - val_loss: 5.0933\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.0592 - val_loss: 5.0677\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 3.0382 - val_loss: 5.0382\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.0169 - val_loss: 5.0128\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 2.9961 - val_loss: 4.9805\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.9740 - val_loss: 4.9520\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.9532 - val_loss: 4.9265\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.9306 - val_loss: 4.9040\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.9152 - val_loss: 4.8811\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 2.8941 - val_loss: 4.8562\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.8752 - val_loss: 4.8301\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.8550 - val_loss: 4.8069\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.8362 - val_loss: 4.7924\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.8230 - val_loss: 4.7658\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.8042 - val_loss: 4.7523\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 2.7913 - val_loss: 4.7254\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.7699 - val_loss: 4.7031\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 2.7559 - val_loss: 4.6798\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 2.7357 - val_loss: 4.6568\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 2.7205 - val_loss: 4.6347\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.7040 - val_loss: 4.6127\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.6879 - val_loss: 4.5944\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.6705 - val_loss: 4.5706\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.6542 - val_loss: 4.5482\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.6385 - val_loss: 4.5276\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.6230 - val_loss: 4.5035\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.6070 - val_loss: 4.4770\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.5894 - val_loss: 4.4602\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.5750 - val_loss: 4.4434\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.5624 - val_loss: 4.4265\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.5500 - val_loss: 4.4088\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 2.5354 - val_loss: 4.3905\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.5218 - val_loss: 4.3745\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.5049 - val_loss: 4.3536\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 2.4937 - val_loss: 4.3400\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 2.4801 - val_loss: 4.3169\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 2.4639 - val_loss: 4.3047\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.4531 - val_loss: 4.2881\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.4413 - val_loss: 4.2707\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.4267 - val_loss: 4.2515\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.4125 - val_loss: 4.2372\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 2.4012 - val_loss: 4.2172\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 2.3886 - val_loss: 4.1999\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.3755 - val_loss: 4.1835\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.3614 - val_loss: 4.1655\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.3505 - val_loss: 4.1471\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 2.3370 - val_loss: 4.1345\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.3261 - val_loss: 4.1181\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 2.3240 - val_loss: 4.1157\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.3081 - val_loss: 4.1000\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 2.2996 - val_loss: 4.0840\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 2.2818 - val_loss: 4.0679\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.2761 - val_loss: 4.0497\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.2566 - val_loss: 4.0341\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.2473 - val_loss: 4.0245\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.2352 - val_loss: 4.0022\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 2.2246 - val_loss: 3.9887\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.2117 - val_loss: 3.9777\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.2040 - val_loss: 3.9653\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.1931 - val_loss: 3.9506\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.1862 - val_loss: 3.9425\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 2.1757 - val_loss: 3.9246\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 2.1664 - val_loss: 3.9079\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 2.1533 - val_loss: 3.8934\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.1416 - val_loss: 3.8751\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.1331 - val_loss: 3.8637\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.1211 - val_loss: 3.8502\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.1105 - val_loss: 3.8304\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 2.1006 - val_loss: 3.8156\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.0889 - val_loss: 3.8015\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.0805 - val_loss: 3.7911\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.0715 - val_loss: 3.7783\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 2.0600 - val_loss: 3.7638\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 2.0538 - val_loss: 3.7539\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 2.0422 - val_loss: 3.7415\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 2.0337 - val_loss: 3.7274\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.0255 - val_loss: 3.7124\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.0141 - val_loss: 3.6981\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.0025 - val_loss: 3.6841\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.9948 - val_loss: 3.6743\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 1.9841 - val_loss: 3.6646\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.9763 - val_loss: 3.6520\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.9699 - val_loss: 3.6392\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.9620 - val_loss: 3.6287\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.9512 - val_loss: 3.6170\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.9422 - val_loss: 3.6059\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.9322 - val_loss: 3.5997\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.9345 - val_loss: 3.5958\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 1.9213 - val_loss: 3.5772\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.9103 - val_loss: 3.5639\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.9022 - val_loss: 3.5515\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.8957 - val_loss: 3.5431\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.8858 - val_loss: 3.5288\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.8803 - val_loss: 3.5218\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.8692 - val_loss: 3.5134\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 1.8642 - val_loss: 3.4953\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.8561 - val_loss: 3.4927\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.8480 - val_loss: 3.4773\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 1.8413 - val_loss: 3.4685\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.8336 - val_loss: 3.4580\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.8234 - val_loss: 3.4471\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 1.8235 - val_loss: 3.4375\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.8127 - val_loss: 3.4251\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.8024 - val_loss: 3.4127\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.8008 - val_loss: 3.4143\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 1.7918 - val_loss: 3.3996\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.7831 - val_loss: 3.3885\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 1.7751 - val_loss: 3.3771\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.7695 - val_loss: 3.3671\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.7602 - val_loss: 3.3564\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 1.7533 - val_loss: 3.3467\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.7466 - val_loss: 3.3344\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.7386 - val_loss: 3.3248\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 1.7312 - val_loss: 3.3144\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 7.7512 - val_loss: 4.8742\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 2.7588 - val_loss: 8.8610\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 2.2944 - val_loss: 1.7538\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 1.4631 - val_loss: 3.5925\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 1.4099 - val_loss: 2.0302\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 1.2614 - val_loss: 1.3479\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 1.0693 - val_loss: 1.4987\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.9148 - val_loss: 1.2735\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.8872 - val_loss: 2.2705\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.8340 - val_loss: 1.2411\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.7131 - val_loss: 1.1894\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.7491 - val_loss: 1.1745\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.6564 - val_loss: 1.4884\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.6871 - val_loss: 1.1308\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.7077 - val_loss: 1.0482\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.6332 - val_loss: 0.8566\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.6585 - val_loss: 0.9737\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.5921 - val_loss: 1.3191\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.5043 - val_loss: 0.9479\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.5173 - val_loss: 0.8917\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.6174 - val_loss: 0.9668\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.4883 - val_loss: 2.1422\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.5005 - val_loss: 2.5042\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.4969 - val_loss: 1.0458\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.4493 - val_loss: 0.9794\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.4310 - val_loss: 1.6410\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.4544 - val_loss: 1.1175\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.4052 - val_loss: 0.8489\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.4012 - val_loss: 1.2029\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.3952 - val_loss: 1.2359\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.4007 - val_loss: 0.8490\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.3504 - val_loss: 1.0395\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.4009 - val_loss: 1.6202\n",
      "Epoch 34/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.3859 - val_loss: 1.1935\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.3648 - val_loss: 1.2480\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.3852 - val_loss: 0.9573\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.3876 - val_loss: 1.1452\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.3409 - val_loss: 1.0205\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.3519 - val_loss: 1.0490\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.3042 - val_loss: 1.1505\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.3339 - val_loss: 1.2293\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.3291 - val_loss: 1.4122\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.3178 - val_loss: 0.9103\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2841 - val_loss: 0.8952\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.3009 - val_loss: 2.3933\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.3208 - val_loss: 0.8858\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.2963 - val_loss: 0.8083\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2844 - val_loss: 1.0192\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2714 - val_loss: 0.8921\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2971 - val_loss: 0.9172\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.2793 - val_loss: 1.0820\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.2596 - val_loss: 1.0063\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2934 - val_loss: 1.3368\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2464 - val_loss: 1.1469\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2568 - val_loss: 0.9614\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2682 - val_loss: 0.9341\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2521 - val_loss: 1.3265\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2394 - val_loss: 1.7648\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.2708 - val_loss: 1.0474\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2484 - val_loss: 1.1336\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2531 - val_loss: 0.9662\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2604 - val_loss: 1.4046\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2232 - val_loss: 1.3805\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2329 - val_loss: 1.7739\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2258 - val_loss: 1.0810\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2595 - val_loss: 1.3864\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2170 - val_loss: 1.0049\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2282 - val_loss: 1.0575\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2589 - val_loss: 1.6420\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2904 - val_loss: 1.3426\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2149 - val_loss: 0.9792\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2165 - val_loss: 0.9352\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2089 - val_loss: 0.9110\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2175 - val_loss: 0.9911\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2606 - val_loss: 1.2486\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2504 - val_loss: 0.7411\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2153 - val_loss: 1.7312\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2245 - val_loss: 1.5129\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2114 - val_loss: 0.8993\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1971 - val_loss: 2.1631\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2283 - val_loss: 1.2588\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2010 - val_loss: 1.2613\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1850 - val_loss: 1.3608\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2025 - val_loss: 1.1768\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2174 - val_loss: 1.0004\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2036 - val_loss: 1.2392\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1840 - val_loss: 1.0917\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1863 - val_loss: 1.5120\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1668 - val_loss: 1.0939\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.2377 - val_loss: 1.4332\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2584 - val_loss: 0.9791\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2211 - val_loss: 1.9894\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1826 - val_loss: 1.3144\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.1976 - val_loss: 0.8921\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 189us/step - loss: 0.1885 - val_loss: 1.4064\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1968 - val_loss: 1.2052\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1948 - val_loss: 1.3216\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2152 - val_loss: 1.5207\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.2075 - val_loss: 1.3978\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1715 - val_loss: 1.1201\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2147 - val_loss: 0.9884\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1946 - val_loss: 1.3804\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2248 - val_loss: 0.9865\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2357 - val_loss: 1.2057\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1848 - val_loss: 1.3023\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.2050 - val_loss: 0.9929\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1713 - val_loss: 0.9829\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1832 - val_loss: 1.0271\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1815 - val_loss: 1.2794\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2119 - val_loss: 2.4080\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1781 - val_loss: 2.3584\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1692 - val_loss: 1.2433\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1654 - val_loss: 1.5117\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2129 - val_loss: 1.2028\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2222 - val_loss: 1.1121\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.1803 - val_loss: 0.9691\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1690 - val_loss: 0.8950\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1728 - val_loss: 1.0164\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2231 - val_loss: 1.2164\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1919 - val_loss: 1.5551\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1755 - val_loss: 1.3281\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1547 - val_loss: 0.9619\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 188us/step - loss: 0.1753 - val_loss: 1.1412\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1823 - val_loss: 1.1351\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1810 - val_loss: 1.2158\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1880 - val_loss: 1.2829\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1710 - val_loss: 1.2724\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 0.1693 - val_loss: 1.4207\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1648 - val_loss: 1.2444\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1871 - val_loss: 1.7917\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1653 - val_loss: 1.0270\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1709 - val_loss: 1.3257\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1487 - val_loss: 1.7021\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1409 - val_loss: 1.3469\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1810 - val_loss: 1.4619\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1433 - val_loss: 1.1236\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1686 - val_loss: 1.2098\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1509 - val_loss: 1.1521\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.2117 - val_loss: 1.7598\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1954 - val_loss: 0.9429\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1712 - val_loss: 1.0754\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2429 - val_loss: 1.4190\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1557 - val_loss: 1.4630\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1476 - val_loss: 1.2527\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2271 - val_loss: 1.7064\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2285 - val_loss: 1.6138\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1841 - val_loss: 1.8708\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1799 - val_loss: 1.1491\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1371 - val_loss: 2.0402\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1590 - val_loss: 1.3228\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1496 - val_loss: 1.3154\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1424 - val_loss: 1.7794\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1634 - val_loss: 1.0413\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1233 - val_loss: 1.1882\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1688 - val_loss: 1.3400\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1667 - val_loss: 1.7332\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.1631 - val_loss: 1.0681\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1493 - val_loss: 1.2096\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1497 - val_loss: 2.3419\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1753 - val_loss: 0.9370\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1751 - val_loss: 1.1490\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1460 - val_loss: 1.0135\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1496 - val_loss: 0.9874\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1514 - val_loss: 1.1112\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1452 - val_loss: 1.5812\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1476 - val_loss: 1.3680\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1292 - val_loss: 1.4502\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1428 - val_loss: 1.0857\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.1562 - val_loss: 1.3902\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1603 - val_loss: 1.2589\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1361 - val_loss: 1.2482\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1256 - val_loss: 0.6182\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1288 - val_loss: 1.4467\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.1736 - val_loss: 1.1721\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1374 - val_loss: 1.4061\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1615 - val_loss: 1.4870\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1674 - val_loss: 2.0649\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1678 - val_loss: 1.3126\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1354 - val_loss: 0.9708\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1528 - val_loss: 1.3917\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1526 - val_loss: 0.9892\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1460 - val_loss: 1.5174\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1438 - val_loss: 1.6831\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1477 - val_loss: 2.4104\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1317 - val_loss: 1.7536\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1326 - val_loss: 1.5054\n",
      "Epoch 187/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1295 - val_loss: 1.7746\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1701 - val_loss: 1.4096\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1775 - val_loss: 1.0262\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1614 - val_loss: 1.6549\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1320 - val_loss: 1.3549\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1465 - val_loss: 1.3815\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1392 - val_loss: 1.5566\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.1325 - val_loss: 1.1002\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1755 - val_loss: 1.8433\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1517 - val_loss: 1.1975\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1840 - val_loss: 1.6194\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1352 - val_loss: 1.5039\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1187 - val_loss: 0.8349\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1308 - val_loss: 1.0760\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.1186 - val_loss: 1.1971\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1239 - val_loss: 1.3030\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1381 - val_loss: 1.0975\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1487 - val_loss: 1.9554\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1354 - val_loss: 1.7453\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1338 - val_loss: 1.5813\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1439 - val_loss: 2.5232\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1394 - val_loss: 1.2953\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1288 - val_loss: 1.9462\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1202 - val_loss: 1.1978\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1134 - val_loss: 1.3503\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1492 - val_loss: 1.6810\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1322 - val_loss: 2.0986\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 186us/step - loss: 0.1459 - val_loss: 1.3020\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.1672 - val_loss: 1.5967\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1074 - val_loss: 1.2875\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.3092 - val_loss: 1.1919\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1560 - val_loss: 1.4952\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1517 - val_loss: 1.0549\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.1407 - val_loss: 2.2136\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1407 - val_loss: 1.3353\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1563 - val_loss: 1.4747\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1272 - val_loss: 1.6308\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1403 - val_loss: 1.3566\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.1556 - val_loss: 2.2056\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1488 - val_loss: 1.3913\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1637 - val_loss: 1.4079\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1340 - val_loss: 1.4538\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1165 - val_loss: 1.9125\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1238 - val_loss: 0.9205\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1160 - val_loss: 1.6072\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1399 - val_loss: 1.8888\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1058 - val_loss: 1.4062\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1423 - val_loss: 1.5144\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1095 - val_loss: 0.9866\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1103 - val_loss: 1.1032\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1330 - val_loss: 1.1891\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1123 - val_loss: 1.5797\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1077 - val_loss: 1.5830\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1904 - val_loss: 1.8041\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1083 - val_loss: 1.6394\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1223 - val_loss: 1.2080\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1202 - val_loss: 1.1926\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1271 - val_loss: 1.6498\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1409 - val_loss: 1.2260\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1073 - val_loss: 1.7933\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1677 - val_loss: 2.2713\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1072 - val_loss: 1.7535\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1190 - val_loss: 1.4785\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1917 - val_loss: 1.9352\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 11.4038 - val_loss: 4.2319\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 1.5892 - val_loss: 1.7832\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.6478 - val_loss: 1.3146\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.4890 - val_loss: 1.0233\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.3906 - val_loss: 0.8956\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.3519 - val_loss: 0.7099\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.3311 - val_loss: 0.7967\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.3293 - val_loss: 0.6428\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.5776 - val_loss: 1.6982\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.4167 - val_loss: 0.6445\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.2109 - val_loss: 0.6021\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.3415 - val_loss: 0.9727\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.2496 - val_loss: 0.4812\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.1422 - val_loss: 0.6466\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.2582 - val_loss: 0.5872\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.2541 - val_loss: 0.3873\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1583 - val_loss: 0.4651\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1941 - val_loss: 0.5719\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.2769 - val_loss: 0.5912\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1358 - val_loss: 0.4914\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1441 - val_loss: 1.4306\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.5362 - val_loss: 1.1008\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1820 - val_loss: 0.4883\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.3569 - val_loss: 0.4521\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.1139 - val_loss: 0.5576\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.1599 - val_loss: 0.5751\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.1263 - val_loss: 0.5384\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1262 - val_loss: 0.6317\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.3586 - val_loss: 0.9780\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.1147 - val_loss: 0.5332\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.0811 - val_loss: 0.4941\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1119 - val_loss: 0.4724\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1258 - val_loss: 0.6571\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1063 - val_loss: 0.5432\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1219 - val_loss: 1.0589\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.2523 - val_loss: 0.5046\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1141 - val_loss: 0.7287\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.1326 - val_loss: 0.4997\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1123 - val_loss: 0.5272\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1543 - val_loss: 0.7947\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.1813 - val_loss: 0.5402\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0864 - val_loss: 0.4717\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1096 - val_loss: 0.5188\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1325 - val_loss: 1.3211\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.2587 - val_loss: 0.7130\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.1029 - val_loss: 0.5075\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0734 - val_loss: 0.5381\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0718 - val_loss: 0.5027\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.0928 - val_loss: 0.4501\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0801 - val_loss: 0.5523\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1143 - val_loss: 0.4605\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1046 - val_loss: 0.4584\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.0716 - val_loss: 0.9266\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1676 - val_loss: 0.5533\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0771 - val_loss: 0.4824\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0689 - val_loss: 0.6915\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1386 - val_loss: 0.5289\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.0655 - val_loss: 0.4813\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.1096 - val_loss: 0.4939\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.2538 - val_loss: 0.6852\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0746 - val_loss: 0.6121\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0769 - val_loss: 0.5216\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0808 - val_loss: 0.5008\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0883 - val_loss: 0.5584\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0946 - val_loss: 0.5858\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0681 - val_loss: 0.4981\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0768 - val_loss: 0.5217\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0740 - val_loss: 0.5133\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0677 - val_loss: 0.6501\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0816 - val_loss: 0.4998\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.0969 - val_loss: 0.5961\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1192 - val_loss: 0.5597\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0957 - val_loss: 0.5204\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0794 - val_loss: 0.6355\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.0758 - val_loss: 0.5342\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0634 - val_loss: 0.5601\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0517 - val_loss: 0.7550\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.0993 - val_loss: 0.6651\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0748 - val_loss: 0.5393\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.0742 - val_loss: 0.5174\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.0585 - val_loss: 0.5326\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.0487 - val_loss: 0.4837\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0743 - val_loss: 0.6020\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1116 - val_loss: 0.5834\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.0907 - val_loss: 0.6178\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1173 - val_loss: 0.7260\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.0918 - val_loss: 0.6506\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.0597 - val_loss: 0.5929\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.0581 - val_loss: 0.6000\n",
      "Epoch 90/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0694 - val_loss: 0.7210\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1063 - val_loss: 0.5485\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.0439 - val_loss: 0.5564\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.0444 - val_loss: 0.5697\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.0649 - val_loss: 0.5382\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0633 - val_loss: 0.5702\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 0.0694 - val_loss: 0.5999\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1139 - val_loss: 0.6229\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1061 - val_loss: 0.8358\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0926 - val_loss: 0.6103\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.0565 - val_loss: 0.7567\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.1081 - val_loss: 0.5478\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0947 - val_loss: 0.5946\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0487 - val_loss: 0.5682\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0427 - val_loss: 0.5652\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0562 - val_loss: 0.5860\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0483 - val_loss: 0.5709\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.0609 - val_loss: 0.5706\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0504 - val_loss: 0.5781\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.0773 - val_loss: 0.5930\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.0871 - val_loss: 0.5441\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 0.0585 - val_loss: 0.5303\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0544 - val_loss: 0.4896\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.0510 - val_loss: 0.6230\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.0495 - val_loss: 0.6063\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.0429 - val_loss: 0.5759\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0389 - val_loss: 0.6174\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.0476 - val_loss: 0.6716\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.0767 - val_loss: 0.6627\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0573 - val_loss: 0.6668\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0630 - val_loss: 0.6281\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 0.0726 - val_loss: 0.6654\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.0761 - val_loss: 0.5821\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.0381 - val_loss: 0.5635\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0404 - val_loss: 0.6354\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.0693 - val_loss: 0.6093\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 240us/step - loss: 0.1972 - val_loss: 0.5751\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.0492 - val_loss: 0.6195\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 0.0427 - val_loss: 0.5605\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.0520 - val_loss: 0.6118\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.0477 - val_loss: 0.7107\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.0632 - val_loss: 0.5925\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.0509 - val_loss: 0.5684\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 0.0447 - val_loss: 0.5889\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.0510 - val_loss: 0.5775\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.0478 - val_loss: 0.6017\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0338 - val_loss: 0.5940\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.0462 - val_loss: 0.6812\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0493 - val_loss: 0.5365\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0413 - val_loss: 0.5990\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.0695 - val_loss: 0.5488\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.0587 - val_loss: 0.6376\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.0406 - val_loss: 0.6512\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.0502 - val_loss: 0.5746\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.0397 - val_loss: 0.6369\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.3672 - val_loss: 0.6405\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0599 - val_loss: 0.6642\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.0414 - val_loss: 0.6563\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0354 - val_loss: 0.6006\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.0343 - val_loss: 0.6472\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0319 - val_loss: 0.6566\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.0343 - val_loss: 0.6512\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0404 - val_loss: 0.6150\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0340 - val_loss: 0.7000\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.0350 - val_loss: 0.6123\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0399 - val_loss: 0.5973\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.0474 - val_loss: 0.5803\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.0499 - val_loss: 0.6162\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0616 - val_loss: 0.6096\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0604 - val_loss: 0.5807\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0307 - val_loss: 0.5793\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.0350 - val_loss: 0.5998\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0348 - val_loss: 0.7005\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0451 - val_loss: 0.5817\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0465 - val_loss: 0.5284\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.0528 - val_loss: 0.5904\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0600 - val_loss: 0.6723\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0456 - val_loss: 0.5881\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.0340 - val_loss: 0.6545\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.0386 - val_loss: 0.6270\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.0424 - val_loss: 0.6843\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.0460 - val_loss: 0.6340\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.0530 - val_loss: 0.6331\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 0.0379 - val_loss: 0.5725\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 0.0364 - val_loss: 0.5955\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.0339 - val_loss: 0.6515\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.0465 - val_loss: 0.6496\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.0349 - val_loss: 0.6891\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0326 - val_loss: 0.6514\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.0359 - val_loss: 0.6428\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.0496 - val_loss: 0.7183\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.0488 - val_loss: 0.6476\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.0407 - val_loss: 0.6132\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0373 - val_loss: 0.7517\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.0406 - val_loss: 0.7186\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.0322 - val_loss: 0.6511\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.0270 - val_loss: 0.6460\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.0286 - val_loss: 0.5997\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.0645 - val_loss: 0.6088\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.0556 - val_loss: 0.7292\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0500 - val_loss: 0.6469\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.0324 - val_loss: 0.6771\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.0292 - val_loss: 0.6098\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.0293 - val_loss: 0.6664\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.0254 - val_loss: 0.6196\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.0302 - val_loss: 0.6329\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.0380 - val_loss: 0.6119\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0336 - val_loss: 0.5850\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 0.0381 - val_loss: 0.6638\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0263 - val_loss: 0.6711\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0999 - val_loss: 1.1213\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.0638 - val_loss: 0.7404\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.0339 - val_loss: 0.6163\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.0314 - val_loss: 0.6357\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0374 - val_loss: 0.6712\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.0283 - val_loss: 0.6969\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 0.0342 - val_loss: 0.7352\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.0323 - val_loss: 0.7079\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0436 - val_loss: 0.6531\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0253 - val_loss: 0.6454\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.0273 - val_loss: 0.7530\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 240us/step - loss: 0.0504 - val_loss: 0.6673\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.0348 - val_loss: 0.7269\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.0435 - val_loss: 0.6550\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.0302 - val_loss: 0.5890\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.0407 - val_loss: 0.7757\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.0498 - val_loss: 0.6209\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 0.0355 - val_loss: 0.6912\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 3s 309us/step - loss: 0.0425 - val_loss: 0.7081\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 3s 272us/step - loss: 0.0410 - val_loss: 0.5944\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.0357 - val_loss: 0.6294\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.0360 - val_loss: 0.6951\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.0295 - val_loss: 0.6800\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.0331 - val_loss: 0.6604\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.0324 - val_loss: 0.6427\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 0.0427 - val_loss: 0.6763\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.0281 - val_loss: 0.6917\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.0257 - val_loss: 0.6202\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 0.0500 - val_loss: 0.7375\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.0337 - val_loss: 0.6704\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.0351 - val_loss: 0.6539\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 0.0298 - val_loss: 0.6652\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.0248 - val_loss: 0.6502\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0463 - val_loss: 0.6568\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 0.0342 - val_loss: 0.6321\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 0.0211 - val_loss: 0.6876\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.0215 - val_loss: 0.6042\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.0389 - val_loss: 0.6243\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0577 - val_loss: 0.6545\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.1100 - val_loss: 0.6439\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.0341 - val_loss: 0.6815\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.0230 - val_loss: 0.6474\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.0310 - val_loss: 0.6415\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 3s 272us/step - loss: 0.0219 - val_loss: 0.6056\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.0328 - val_loss: 0.6389\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.0309 - val_loss: 0.6626\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.0235 - val_loss: 0.6281\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.0341 - val_loss: 0.6469\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.0503 - val_loss: 0.6224\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.0367 - val_loss: 0.6917\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 0.0531 - val_loss: 0.6061\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "moptimizer = Adagrad(lr=0.001)\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_ada_rel = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "moptimizer = Adadelta(lr=0.001)\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_adadel_rel = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "moptimizer = RMSprop(lr=0.001)\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_rms_rel= model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"relu\"))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "moptimizer = Adam(lr=0.001)\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_adam_rel = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1584 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify> Lo interesante de este análisis es que nos mantenemos en que la función de activación <b>ReLU</b> en particular para esta aplicación no tiene un buen rendimiento, comparado con su contraparte <b><font color=ORGANGE>SIGMOIDE</font></b> , pero en el caso de analizar datos, encontramos que al igual que en el punto anterior el modelo con el optimizador que converge mas rápido en su función de pérdida es <b><font color=RED> ADAM</font></b> pero no con la misma exactitud tenemos en el modelo <b><font color=green> ADAGRAD </B></FONT>. Aunque esta información es bastante relevante e interesante, no quiere decir que aunque en el set de validación los valores de la función sean tan dispersos, es muy claro anotar que estos resultados son solo orientados a este dataframe, puede que en otro tipo de datos este optimizador en conjunto con esta función de activación sea una mejor herramienta </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify><b>h) Entrene los modelos obtenidos en b) y c) utilizando regularizadores $l_1$ y $l_2$ (*weight decay*). Compare los desempeños de prueba obtenidos antes y después de regularizar. Experimente con distintos valores del parámetro de regularización y comente. Además evalúe el efecto de regularizar solo la primera capa *vs* la segunda, comente.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=1275, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: 10.7442 - val_loss: 2.6123\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 1.5728 - val_loss: 0.9905\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.8965 - val_loss: 0.8798\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.7306 - val_loss: 0.6105\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.6406 - val_loss: 0.5557\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.5886 - val_loss: 0.5209\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.5522 - val_loss: 0.5417\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.5248 - val_loss: 0.4704\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.5217 - val_loss: 0.4960\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5046 - val_loss: 0.4913\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4916 - val_loss: 0.4639\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.4918 - val_loss: 0.4493\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.4826 - val_loss: 0.4349\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.4782 - val_loss: 0.4557\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4723 - val_loss: 0.4794\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.4724 - val_loss: 0.4413\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4714 - val_loss: 0.4606\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4684 - val_loss: 0.4685\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.4655 - val_loss: 0.4278\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.4635 - val_loss: 0.4214\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.4599 - val_loss: 0.4190\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.4534 - val_loss: 0.4448\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4531 - val_loss: 0.4287\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.4532 - val_loss: 0.4252\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4528 - val_loss: 0.4224\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.4526 - val_loss: 0.4160\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4480 - val_loss: 0.4220\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.4449 - val_loss: 0.4270\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4443 - val_loss: 0.4138\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4423 - val_loss: 0.4094\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.4396 - val_loss: 0.4265\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4370 - val_loss: 0.4067\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.4366 - val_loss: 0.4071\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4346 - val_loss: 0.4075\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.4330 - val_loss: 0.4068\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4323 - val_loss: 0.4101\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.4332 - val_loss: 0.4063\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.4313 - val_loss: 0.4049\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4303 - val_loss: 0.4208\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.4291 - val_loss: 0.3986\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4253 - val_loss: 0.4058\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.4253 - val_loss: 0.3971\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.4245 - val_loss: 0.3969\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4197 - val_loss: 0.3915\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.4210 - val_loss: 0.3953\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4167 - val_loss: 0.3981\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.4154 - val_loss: 0.4012\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4159 - val_loss: 0.3958\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4126 - val_loss: 0.3853\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.4122 - val_loss: 0.3903\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4098 - val_loss: 0.3853\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.4078 - val_loss: 0.3831\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4079 - val_loss: 0.3836\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.4055 - val_loss: 0.3835\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4059 - val_loss: 0.3913\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4039 - val_loss: 0.3792\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.4010 - val_loss: 0.3997\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3995 - val_loss: 0.3785\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.3999 - val_loss: 0.3797\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3977 - val_loss: 0.3703\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.3953 - val_loss: 0.3744\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3968 - val_loss: 0.3769\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3932 - val_loss: 0.3810\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.3910 - val_loss: 0.3682\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3885 - val_loss: 0.4121\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.3910 - val_loss: 0.3659\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3880 - val_loss: 0.3768\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3873 - val_loss: 0.3733\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3831 - val_loss: 0.3621\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.3836 - val_loss: 0.3667\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3849 - val_loss: 0.3662\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.3817 - val_loss: 0.3638\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.3799 - val_loss: 0.3644\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3794 - val_loss: 0.3626\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3780 - val_loss: 0.3547\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3763 - val_loss: 0.3609\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.3752 - val_loss: 0.3572\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3751 - val_loss: 0.3576\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.3731 - val_loss: 0.3641\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.3734 - val_loss: 0.3581\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.3713 - val_loss: 0.3520\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.3689 - val_loss: 0.3591\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3674 - val_loss: 0.3757\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.3670 - val_loss: 0.3595\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.3661 - val_loss: 0.3456\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3645 - val_loss: 0.3446\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.3638 - val_loss: 0.3452\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3639 - val_loss: 0.3667\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.3604 - val_loss: 0.3453\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3614 - val_loss: 0.3547\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 0.3597 - val_loss: 0.3419\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.3570 - val_loss: 0.3504\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3580 - val_loss: 0.3377\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.3547 - val_loss: 0.3519\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3547 - val_loss: 0.3357\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.3537 - val_loss: 0.3419\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3513 - val_loss: 0.3397\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.3518 - val_loss: 0.3329\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3491 - val_loss: 0.3421\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.3489 - val_loss: 0.3328\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3478 - val_loss: 0.3362\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3469 - val_loss: 0.3312\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.3463 - val_loss: 0.3344\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3440 - val_loss: 0.3373\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3429 - val_loss: 0.3343\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.3430 - val_loss: 0.3416\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.3403 - val_loss: 0.3237\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.3405 - val_loss: 0.3267\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3396 - val_loss: 0.3252\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.3377 - val_loss: 0.3326\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3363 - val_loss: 0.3543\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.3369 - val_loss: 0.3303\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.3352 - val_loss: 0.3242\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3357 - val_loss: 0.3221\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 0.3347 - val_loss: 0.3466\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3323 - val_loss: 0.3329\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.3334 - val_loss: 0.3186\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3316 - val_loss: 0.3333\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.3299 - val_loss: 0.3191\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3293 - val_loss: 0.3172\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.3272 - val_loss: 0.3230\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.3284 - val_loss: 0.3191\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3265 - val_loss: 0.3169\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.3262 - val_loss: 0.3165\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3256 - val_loss: 0.3167\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.3238 - val_loss: 0.3110\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.3224 - val_loss: 0.3298\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3225 - val_loss: 0.3108\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.3199 - val_loss: 0.3082\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3194 - val_loss: 0.3183\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.3184 - val_loss: 0.3115\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3190 - val_loss: 0.3087\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.3188 - val_loss: 0.3119\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.3172 - val_loss: 0.3454\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.3172 - val_loss: 0.3062\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.3142 - val_loss: 0.3058\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3148 - val_loss: 0.3071\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.3135 - val_loss: 0.3083\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.3131 - val_loss: 0.3041\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.3122 - val_loss: 0.3076\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3107 - val_loss: 0.3024\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3095 - val_loss: 0.3085\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3101 - val_loss: 0.3072\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3085 - val_loss: 0.3174\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.3061 - val_loss: 0.2998\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.3064 - val_loss: 0.3076\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.3035 - val_loss: 0.3048\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3051 - val_loss: 0.3089\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3038 - val_loss: 0.2989\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3027 - val_loss: 0.2936\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3014 - val_loss: 0.2945\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.3020 - val_loss: 0.3136\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.2995 - val_loss: 0.3011\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.3012 - val_loss: 0.2992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.2993 - val_loss: 0.2918\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2989 - val_loss: 0.2914\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.2983 - val_loss: 0.2911\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.2973 - val_loss: 0.3061\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2961 - val_loss: 0.2990\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.2962 - val_loss: 0.2882\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.2933 - val_loss: 0.2861\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.2944 - val_loss: 0.2878\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.2931 - val_loss: 0.3420\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 0.2925 - val_loss: 0.2862\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2923 - val_loss: 0.2865\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.2912 - val_loss: 0.2836\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2890 - val_loss: 0.2896\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.2896 - val_loss: 0.2837\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.2882 - val_loss: 0.2826\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2880 - val_loss: 0.2845\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.2885 - val_loss: 0.2824\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.2863 - val_loss: 0.2817\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2873 - val_loss: 0.2793\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2850 - val_loss: 0.2889\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2826 - val_loss: 0.2891\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.2834 - val_loss: 0.2787\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.2825 - val_loss: 0.2870\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.2836 - val_loss: 0.2811\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2832 - val_loss: 0.2758\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.2816 - val_loss: 0.2856\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2807 - val_loss: 0.2878\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2809 - val_loss: 0.2777\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.2801 - val_loss: 0.2770\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.2787 - val_loss: 0.2807\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2778 - val_loss: 0.2760\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.2774 - val_loss: 0.2753\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.2782 - val_loss: 0.2779\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2754 - val_loss: 0.2715\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.2753 - val_loss: 0.2856\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.2738 - val_loss: 0.2735\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2736 - val_loss: 0.2701\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.2734 - val_loss: 0.2705\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.2724 - val_loss: 0.2886\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.2722 - val_loss: 0.2690\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2701 - val_loss: 0.2729\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.2708 - val_loss: 0.2740\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.2714 - val_loss: 0.2731\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2715 - val_loss: 0.2680\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.2698 - val_loss: 0.2751\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.2677 - val_loss: 0.2791\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.2679 - val_loss: 0.2633\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.2657 - val_loss: 0.2840\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.2673 - val_loss: 0.2639\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.2666 - val_loss: 0.2614\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2664 - val_loss: 0.2677\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.2647 - val_loss: 0.2649\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.2639 - val_loss: 0.2678\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2638 - val_loss: 0.2646\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.2639 - val_loss: 0.2644\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.2624 - val_loss: 0.2612\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.2627 - val_loss: 0.2584\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.2608 - val_loss: 0.2628\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.2614 - val_loss: 0.2586\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2616 - val_loss: 0.2584\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2604 - val_loss: 0.2583\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.2594 - val_loss: 0.2578\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2637 - val_loss: 0.2610\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.2580 - val_loss: 0.2581\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.2569 - val_loss: 0.2587\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2565 - val_loss: 0.2611\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2575 - val_loss: 0.2614\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.2568 - val_loss: 0.2554\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.2549 - val_loss: 0.2551\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.2564 - val_loss: 0.2580\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.2546 - val_loss: 0.2561\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2538 - val_loss: 0.2528\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.2538 - val_loss: 0.2539\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.2548 - val_loss: 0.2539\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2521 - val_loss: 0.2586\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.2524 - val_loss: 0.2518\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.2510 - val_loss: 0.2584\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.2511 - val_loss: 0.2634\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.2508 - val_loss: 0.2581\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.2502 - val_loss: 0.2483\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.2504 - val_loss: 0.2560\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.2514 - val_loss: 0.2555\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 0.2499 - val_loss: 0.2943\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.2482 - val_loss: 0.2529\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.2477 - val_loss: 0.2625\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.2475 - val_loss: 0.2507\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.2480 - val_loss: 0.2460\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.2463 - val_loss: 0.2463\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.2478 - val_loss: 0.2471\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 0.2444 - val_loss: 0.2471\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2457 - val_loss: 0.2456\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.2450 - val_loss: 0.2449\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.2426 - val_loss: 0.2474\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.2447 - val_loss: 0.2438\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2467 - val_loss: 0.2804\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.2434 - val_loss: 0.2460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=1275, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 23.4915 - val_loss: 13.3718\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 8.5414 - val_loss: 9.4643\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 6.4614 - val_loss: 7.8406\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 5.5020 - val_loss: 6.8379\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 4.9177 - val_loss: 6.4764\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 4.5140 - val_loss: 5.9966\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 4.2716 - val_loss: 5.6868\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 4.0849 - val_loss: 5.4471\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 3.9224 - val_loss: 5.2494\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 3.7968 - val_loss: 5.1097\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 3.6884 - val_loss: 4.9898\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 3.5862 - val_loss: 4.8512\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 3.5103 - val_loss: 4.7879\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 3.4428 - val_loss: 4.6586\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 3.3801 - val_loss: 4.6246\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.3212 - val_loss: 4.5822\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 3.2688 - val_loss: 4.4693\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 3.2182 - val_loss: 4.4504\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 3.1737 - val_loss: 4.3852\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 3.1334 - val_loss: 4.3445\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 3.0917 - val_loss: 4.3132\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 3.0519 - val_loss: 4.2590\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 3.0184 - val_loss: 4.2128\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.9835 - val_loss: 4.1716\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 2.9516 - val_loss: 4.1505\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 2.9243 - val_loss: 4.0922\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 2.8935 - val_loss: 4.0905\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 2.8654 - val_loss: 4.0498\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 2.8359 - val_loss: 3.9966\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 2.8109 - val_loss: 3.9494\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.7863 - val_loss: 3.9524\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 2.7628 - val_loss: 3.8911\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.7400 - val_loss: 3.8900\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 2.7172 - val_loss: 3.8627\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 2.6940 - val_loss: 3.8497\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.6739 - val_loss: 3.7922\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 2.6515 - val_loss: 3.7770\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 2.6323 - val_loss: 3.7685\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 2.6117 - val_loss: 3.7320\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 2.5932 - val_loss: 3.7286\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 2.5738 - val_loss: 3.6963\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 2.5579 - val_loss: 3.6548\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.5400 - val_loss: 3.6409\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.5223 - val_loss: 3.6409\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.5045 - val_loss: 3.5882\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 2.4899 - val_loss: 3.6036\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 2.4684 - val_loss: 3.5411\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 2.4571 - val_loss: 3.5490\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 2.4408 - val_loss: 3.5304\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 2.4263 - val_loss: 3.4984\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 2.4115 - val_loss: 3.5079\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 2.3965 - val_loss: 3.4532\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 2.3821 - val_loss: 3.4501\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 2.3684 - val_loss: 3.4537\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 2.3557 - val_loss: 3.4153\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 2.3408 - val_loss: 3.3953\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 2.3262 - val_loss: 3.3889\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 2.3145 - val_loss: 3.3721\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 2.3005 - val_loss: 3.3664\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 2.2890 - val_loss: 3.3542\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 2.2759 - val_loss: 3.3567\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 2.2639 - val_loss: 3.3214\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.2513 - val_loss: 3.3139\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 2.2401 - val_loss: 3.2968\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.2280 - val_loss: 3.2510\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.2166 - val_loss: 3.2719\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 2.2054 - val_loss: 3.2553\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 2.1933 - val_loss: 3.2454\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.1828 - val_loss: 3.2179\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 2.1729 - val_loss: 3.2100\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 2.1629 - val_loss: 3.2008\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 2.1514 - val_loss: 3.1585\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 2.1410 - val_loss: 3.1544\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 2.1303 - val_loss: 3.1559\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 2.1207 - val_loss: 3.1512\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 2.1104 - val_loss: 3.1274\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 2.1005 - val_loss: 3.1348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.0912 - val_loss: 3.1049\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 2.0820 - val_loss: 3.0943\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 2.0720 - val_loss: 3.0925\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 2.0628 - val_loss: 3.0881\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 2.0535 - val_loss: 3.0762\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 2.0452 - val_loss: 3.0568\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 2.0353 - val_loss: 3.0391\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 2.0266 - val_loss: 3.0367\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 2.0179 - val_loss: 2.9981\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 2.0092 - val_loss: 3.0068\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 2.0012 - val_loss: 2.9930\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 1.9919 - val_loss: 2.9864\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 1.9835 - val_loss: 2.9878\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 195us/step - loss: 1.9755 - val_loss: 2.9736\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.9668 - val_loss: 2.9527\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 1.9597 - val_loss: 2.9373\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 1.9503 - val_loss: 2.9569\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 1.9432 - val_loss: 2.9260\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 194us/step - loss: 1.9347 - val_loss: 2.9128\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.9268 - val_loss: 2.9013\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 1.9194 - val_loss: 2.8716\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 1.9118 - val_loss: 2.8905\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 1.9046 - val_loss: 2.8820\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.8974 - val_loss: 2.8653\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 1.8899 - val_loss: 2.8420\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 1.8822 - val_loss: 2.8596\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.8759 - val_loss: 2.8360\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.8680 - val_loss: 2.8381\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.8608 - val_loss: 2.8159\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 1.8546 - val_loss: 2.8219\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 1.8473 - val_loss: 2.7986\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.8404 - val_loss: 2.7939\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 1.8329 - val_loss: 2.7937\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.8265 - val_loss: 2.7838\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 1.8192 - val_loss: 2.7747\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.8134 - val_loss: 2.7815\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 1.8069 - val_loss: 2.7569\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.7996 - val_loss: 2.7265\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 1.7947 - val_loss: 2.7345\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 1.7872 - val_loss: 2.7311\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 1.7802 - val_loss: 2.7126\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 1.7750 - val_loss: 2.7138\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.7686 - val_loss: 2.7137\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 1.7620 - val_loss: 2.6955\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.7565 - val_loss: 2.6949\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 1.7500 - val_loss: 2.6908\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 1.7442 - val_loss: 2.6939\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.7387 - val_loss: 2.6688\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 1.7324 - val_loss: 2.6609\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.7264 - val_loss: 2.6571\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 1.7205 - val_loss: 2.6372\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 1.7143 - val_loss: 2.6245\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 1.7090 - val_loss: 2.6389\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.7033 - val_loss: 2.6197\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.6980 - val_loss: 2.6243\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 1.6923 - val_loss: 2.6120\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.6865 - val_loss: 2.5997\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.6805 - val_loss: 2.6002\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.6748 - val_loss: 2.5965\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 1.6703 - val_loss: 2.5942\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 1.6643 - val_loss: 2.5729\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.6597 - val_loss: 2.5616\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 1.6541 - val_loss: 2.5595\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.6490 - val_loss: 2.5560\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.6439 - val_loss: 2.5365\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 1.6388 - val_loss: 2.5520\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.6335 - val_loss: 2.5375\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 1.6286 - val_loss: 2.5415\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.6235 - val_loss: 2.5328\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 1.6178 - val_loss: 2.5131\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.6135 - val_loss: 2.5020\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.6084 - val_loss: 2.5090\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 1.6031 - val_loss: 2.4936\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.5987 - val_loss: 2.4929\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.5936 - val_loss: 2.4910\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.5890 - val_loss: 2.4929\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.5842 - val_loss: 2.4851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 1.5793 - val_loss: 2.4700\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 1.5746 - val_loss: 2.4460\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 196us/step - loss: 1.5703 - val_loss: 2.4626\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.5656 - val_loss: 2.4424\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 1.5603 - val_loss: 2.4452\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.5556 - val_loss: 2.4526\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 1.5513 - val_loss: 2.4398\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 198us/step - loss: 1.5475 - val_loss: 2.4344\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.5428 - val_loss: 2.4140\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 197us/step - loss: 1.5384 - val_loss: 2.4211\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.5335 - val_loss: 2.4174\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.5289 - val_loss: 2.4039\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.5250 - val_loss: 2.3991\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.5205 - val_loss: 2.4054\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 1.5163 - val_loss: 2.3953\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.5123 - val_loss: 2.3811\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 3s 281us/step - loss: 1.5077 - val_loss: 2.4022\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 1.5037 - val_loss: 2.3801\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 1.4998 - val_loss: 2.3833\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.4945 - val_loss: 2.3631\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 1.4909 - val_loss: 2.3605\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 1.4867 - val_loss: 2.3659\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.4824 - val_loss: 2.3625\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.4785 - val_loss: 2.3562\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 1.4740 - val_loss: 2.3430\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 1.4706 - val_loss: 2.3314\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.4664 - val_loss: 2.3222\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 1.4628 - val_loss: 2.3367\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 240us/step - loss: 1.4584 - val_loss: 2.3129\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.4546 - val_loss: 2.3105\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.4503 - val_loss: 2.3148\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.4466 - val_loss: 2.2914\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 1.4427 - val_loss: 2.2925\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 1.4390 - val_loss: 2.3025\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.4351 - val_loss: 2.2912\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.4312 - val_loss: 2.2922\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.4280 - val_loss: 2.2756\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.4236 - val_loss: 2.2866\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.4204 - val_loss: 2.2715\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 1.4159 - val_loss: 2.2662\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 1.4130 - val_loss: 2.2590\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.4085 - val_loss: 2.2547\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.4052 - val_loss: 2.2436\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 1.4019 - val_loss: 2.2531\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 1.3981 - val_loss: 2.2456\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 1.3947 - val_loss: 2.2407\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.3911 - val_loss: 2.2376\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 1.3876 - val_loss: 2.2281\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.3837 - val_loss: 2.2179\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.3803 - val_loss: 2.2165\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 1.3765 - val_loss: 2.2162\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.3733 - val_loss: 2.2114\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 1.3699 - val_loss: 2.2021\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 1.3662 - val_loss: 2.2007\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.3628 - val_loss: 2.2109\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 1.3594 - val_loss: 2.1952\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 1.3560 - val_loss: 2.1822\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 1.3523 - val_loss: 2.1980\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 1.3497 - val_loss: 2.1778\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 1.3461 - val_loss: 2.1702\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 1.3424 - val_loss: 2.1738\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.3394 - val_loss: 2.1748\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 1.3362 - val_loss: 2.1728\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.3330 - val_loss: 2.1621\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 1.3295 - val_loss: 2.1558\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 1.3267 - val_loss: 2.1492\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 1.3234 - val_loss: 2.1483\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 1.3202 - val_loss: 2.1426\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 1.3171 - val_loss: 2.1577\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.3139 - val_loss: 2.1391\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 1.3109 - val_loss: 2.1395\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 1.3077 - val_loss: 2.1286\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 1.3045 - val_loss: 2.1289\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.3011 - val_loss: 2.1206\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.2984 - val_loss: 2.1222\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 1.2949 - val_loss: 2.1095\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 1.2922 - val_loss: 2.1087\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 1.2890 - val_loss: 2.1118\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 1.2863 - val_loss: 2.0951\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 1.2829 - val_loss: 2.0977\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 1.2801 - val_loss: 2.0896\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 1.2771 - val_loss: 2.0952\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 1.2740 - val_loss: 2.0901\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 1.2711 - val_loss: 2.0965\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 1.2682 - val_loss: 2.0803\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.2649 - val_loss: 2.0882\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 1.2622 - val_loss: 2.0771\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 1.2595 - val_loss: 2.0680\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 1.2565 - val_loss: 2.0779\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 1.2537 - val_loss: 2.0656\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 1.2509 - val_loss: 2.0625\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.2477 - val_loss: 2.0657\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 1.2450 - val_loss: 2.0638\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 1.2421 - val_loss: 2.0356\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 1.2393 - val_loss: 2.0443\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 1.2366 - val_loss: 2.0480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=1275, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 9.9792 - val_loss: 2.4663\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 1.4250 - val_loss: 1.0146\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.8931 - val_loss: 0.7154\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.7192 - val_loss: 0.6388\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 240us/step - loss: 0.6443 - val_loss: 0.5627\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.6036 - val_loss: 0.6489\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.5797 - val_loss: 0.5313\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.5577 - val_loss: 0.5074\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.5386 - val_loss: 0.5105\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.5277 - val_loss: 0.5050\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.5250 - val_loss: 0.4787\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.5183 - val_loss: 0.4788\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5186 - val_loss: 0.4662\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.5110 - val_loss: 0.4701\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.5078 - val_loss: 0.4734\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.5047 - val_loss: 0.4719\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 0.5004 - val_loss: 0.4797\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.4989 - val_loss: 0.4660\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.4979 - val_loss: 0.4636\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4953 - val_loss: 0.4602\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4938 - val_loss: 0.5353\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4915 - val_loss: 0.4575\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4880 - val_loss: 0.4549\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.4865 - val_loss: 0.4503\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4883 - val_loss: 0.4567\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.4882 - val_loss: 0.4519\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4867 - val_loss: 0.4494\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4821 - val_loss: 0.4571\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4802 - val_loss: 0.4561\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.4788 - val_loss: 0.4505\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.4810 - val_loss: 0.4951\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4795 - val_loss: 0.4507\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4769 - val_loss: 0.4464\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4763 - val_loss: 0.4524\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4722 - val_loss: 0.4419\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.4735 - val_loss: 0.4487\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4713 - val_loss: 0.4408\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4707 - val_loss: 0.4386\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4708 - val_loss: 0.4334\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4659 - val_loss: 0.4344\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.4653 - val_loss: 0.4337\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4634 - val_loss: 0.4405\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4619 - val_loss: 0.4369\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.4602 - val_loss: 0.4289\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.4592 - val_loss: 0.4377\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4610 - val_loss: 0.4307\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4578 - val_loss: 0.4279\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.4563 - val_loss: 0.4313\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4546 - val_loss: 0.4291\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.4533 - val_loss: 0.4230\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4529 - val_loss: 0.4274\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4505 - val_loss: 0.4325\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4484 - val_loss: 0.4218\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4511 - val_loss: 0.4235\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.4457 - val_loss: 0.4261\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4474 - val_loss: 0.4238\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4422 - val_loss: 0.4189\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4472 - val_loss: 0.4370\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4417 - val_loss: 0.4237\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4402 - val_loss: 0.4163\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.4404 - val_loss: 0.4315\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4385 - val_loss: 0.4170\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4381 - val_loss: 0.4288\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4362 - val_loss: 0.4184\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.4375 - val_loss: 0.4099\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4353 - val_loss: 0.4123\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4341 - val_loss: 0.4501\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.4309 - val_loss: 0.4068\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.4312 - val_loss: 0.4196\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4313 - val_loss: 0.4100\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.4298 - val_loss: 0.4119\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.4266 - val_loss: 0.4056\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4280 - val_loss: 0.4032\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.4257 - val_loss: 0.3992\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4244 - val_loss: 0.4191\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4226 - val_loss: 0.4105\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.4235 - val_loss: 0.3990\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4208 - val_loss: 0.4038\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4206 - val_loss: 0.4179\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.4182 - val_loss: 0.4179\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4195 - val_loss: 0.4174\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.4160 - val_loss: 0.3956\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.4172 - val_loss: 0.4019\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4161 - val_loss: 0.3940\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.4131 - val_loss: 0.3970\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4136 - val_loss: 0.3931\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.4116 - val_loss: 0.3922\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4109 - val_loss: 0.3999\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.4098 - val_loss: 0.3924\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.4082 - val_loss: 0.3926\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4090 - val_loss: 0.3908\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.4066 - val_loss: 0.3852\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4060 - val_loss: 0.3930\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4052 - val_loss: 0.3862\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.4041 - val_loss: 0.3878\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.4044 - val_loss: 0.3862\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.4026 - val_loss: 0.3818\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.4019 - val_loss: 0.3806\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.3997 - val_loss: 0.3887\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3994 - val_loss: 0.3925\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.3992 - val_loss: 0.3862\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3965 - val_loss: 0.3783\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.3955 - val_loss: 0.3826\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3960 - val_loss: 0.3785\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3950 - val_loss: 0.3825\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3936 - val_loss: 0.3779\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.3939 - val_loss: 0.3779\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3919 - val_loss: 0.3743\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.3900 - val_loss: 0.3880\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3891 - val_loss: 0.3758\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3896 - val_loss: 0.3759\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3887 - val_loss: 0.3760\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.3864 - val_loss: 0.3731\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3860 - val_loss: 0.3751\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3855 - val_loss: 0.3681\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3863 - val_loss: 0.3742\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3865 - val_loss: 0.3668\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3826 - val_loss: 0.3872\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3835 - val_loss: 0.3765\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3828 - val_loss: 0.3694\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3806 - val_loss: 0.3680\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.3814 - val_loss: 0.3707\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.3788 - val_loss: 0.3847\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.3779 - val_loss: 0.3675\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3783 - val_loss: 0.3693\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3780 - val_loss: 0.3676\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3756 - val_loss: 0.3663\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3771 - val_loss: 0.3616\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3768 - val_loss: 0.3620\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3751 - val_loss: 0.3749\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3750 - val_loss: 0.3635\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3733 - val_loss: 0.3592\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3715 - val_loss: 0.3657\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3699 - val_loss: 0.3612\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3720 - val_loss: 0.3654\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 0.3706 - val_loss: 0.3565\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.3693 - val_loss: 0.3574\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3684 - val_loss: 0.3562\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.3678 - val_loss: 0.3593\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3672 - val_loss: 0.3587\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3680 - val_loss: 0.3630\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.3649 - val_loss: 0.3558\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.3658 - val_loss: 0.3579\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.3656 - val_loss: 0.3794\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3681 - val_loss: 0.3533\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3627 - val_loss: 0.3540\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3635 - val_loss: 0.3508\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3624 - val_loss: 0.3526\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3608 - val_loss: 0.3681\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3614 - val_loss: 0.3525\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.3589 - val_loss: 0.3550\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3587 - val_loss: 0.3586\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.3593 - val_loss: 0.3648\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.3593 - val_loss: 0.3527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.3569 - val_loss: 0.3471\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.3583 - val_loss: 0.3486\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.3553 - val_loss: 0.4348\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3569 - val_loss: 0.3956\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3561 - val_loss: 0.3462\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3549 - val_loss: 0.3515\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.3547 - val_loss: 0.3442\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3538 - val_loss: 0.3571\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.3525 - val_loss: 0.3652\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3534 - val_loss: 0.3750\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3518 - val_loss: 0.3431\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3510 - val_loss: 0.3421\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.3511 - val_loss: 0.3526\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.3498 - val_loss: 0.3471\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.3491 - val_loss: 0.3446\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.3492 - val_loss: 0.3419\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3481 - val_loss: 0.3549\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.3471 - val_loss: 0.3401\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3470 - val_loss: 0.3432\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3462 - val_loss: 0.3439\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3473 - val_loss: 0.3394\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3448 - val_loss: 0.3375\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3439 - val_loss: 0.3366\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3446 - val_loss: 0.3366\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.3419 - val_loss: 0.3400\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3428 - val_loss: 0.3366\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3411 - val_loss: 0.3398\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3408 - val_loss: 0.3457\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3413 - val_loss: 0.3349\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3401 - val_loss: 0.3825\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.3411 - val_loss: 0.3352\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.3389 - val_loss: 0.3305\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3381 - val_loss: 0.3331\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3385 - val_loss: 0.3328\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3371 - val_loss: 0.3353\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3376 - val_loss: 0.3375\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.3373 - val_loss: 0.3462\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.3353 - val_loss: 0.3378\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3356 - val_loss: 0.3316\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3351 - val_loss: 0.3285\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3341 - val_loss: 0.3442\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3334 - val_loss: 0.3266\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.3338 - val_loss: 0.3400\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3333 - val_loss: 0.3310\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.3331 - val_loss: 0.3253\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.3319 - val_loss: 0.3450\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3332 - val_loss: 0.3271\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.3303 - val_loss: 0.3294\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3307 - val_loss: 0.3367\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3295 - val_loss: 0.3292\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3302 - val_loss: 0.3283\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.3288 - val_loss: 0.3292\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3292 - val_loss: 0.3322\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3297 - val_loss: 0.3223\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.3271 - val_loss: 0.3228\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3274 - val_loss: 0.3287\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 0.3270 - val_loss: 0.3208\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.3263 - val_loss: 0.3216\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3253 - val_loss: 0.3237\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.3254 - val_loss: 0.3330\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3252 - val_loss: 0.3277\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3228 - val_loss: 0.3230\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 0.3245 - val_loss: 0.3181\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3253 - val_loss: 0.3190\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.3236 - val_loss: 0.3203\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.3232 - val_loss: 0.3182\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3225 - val_loss: 0.3236\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.3216 - val_loss: 0.3953\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.3220 - val_loss: 0.3256\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3212 - val_loss: 0.3173\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.3200 - val_loss: 0.3153\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3206 - val_loss: 0.3299\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.3200 - val_loss: 0.3148\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.3189 - val_loss: 0.3150\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 0.3192 - val_loss: 0.3203\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3176 - val_loss: 0.3152\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.3187 - val_loss: 0.3176\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.3176 - val_loss: 0.3163\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3176 - val_loss: 0.3173\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 0.3187 - val_loss: 0.3187\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.3155 - val_loss: 0.3158\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3160 - val_loss: 0.3187\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3155 - val_loss: 0.3218\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3153 - val_loss: 0.3150\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3158 - val_loss: 0.3153\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3152 - val_loss: 0.3154\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.3150 - val_loss: 0.3123\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3147 - val_loss: 0.3168\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.3141 - val_loss: 0.3098\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3142 - val_loss: 0.3105\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3122 - val_loss: 0.3089\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3117 - val_loss: 0.3142\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.3122 - val_loss: 0.3094\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.3120 - val_loss: 0.3087\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3118 - val_loss: 0.3188\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.3110 - val_loss: 0.3106\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=1275, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 24.1071 - val_loss: 13.6260\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 8.8864 - val_loss: 9.5876\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 6.6222 - val_loss: 8.0696\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 5.5868 - val_loss: 7.0441\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 5.0130 - val_loss: 6.6796\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 4.6722 - val_loss: 6.1403\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 4.4052 - val_loss: 5.8868\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 4.2230 - val_loss: 5.6459\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 4.0484 - val_loss: 5.4915\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 3.9141 - val_loss: 5.3490\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 3.8115 - val_loss: 5.2171\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 3.7246 - val_loss: 5.0714\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 3.6388 - val_loss: 5.0354\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.5687 - val_loss: 4.9313\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 3.5050 - val_loss: 4.8052\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 3.4444 - val_loss: 4.7455\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 3.3886 - val_loss: 4.7177\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 3.3443 - val_loss: 4.6555\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 3.3016 - val_loss: 4.5864\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 3.2592 - val_loss: 4.5605\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 3.2175 - val_loss: 4.5052\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 3.1844 - val_loss: 4.4397\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 3.1470 - val_loss: 4.3664\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 3.1122 - val_loss: 4.3913\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 3.0837 - val_loss: 4.3035\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.0532 - val_loss: 4.2638\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 3.0242 - val_loss: 4.2738\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.9981 - val_loss: 4.2140\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.9684 - val_loss: 4.1884\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 2.9468 - val_loss: 4.1600\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.9194 - val_loss: 4.1448\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 2.8980 - val_loss: 4.0941\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.8733 - val_loss: 4.0729\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 2.8528 - val_loss: 4.0444\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.8308 - val_loss: 3.9790\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.8081 - val_loss: 4.0090\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.7906 - val_loss: 3.9507\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 2.7685 - val_loss: 3.9304\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 2.7500 - val_loss: 3.9214\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 2.7283 - val_loss: 3.8793\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 2.7116 - val_loss: 3.8595\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.6957 - val_loss: 3.8195\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 2.6780 - val_loss: 3.8218\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.6597 - val_loss: 3.7744\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.6445 - val_loss: 3.7746\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.6255 - val_loss: 3.7409\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 230us/step - loss: 2.6117 - val_loss: 3.7425\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 2.5951 - val_loss: 3.7364\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 2.5809 - val_loss: 3.6813\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 2.5640 - val_loss: 3.6422\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 2.5502 - val_loss: 3.6611\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 2.5368 - val_loss: 3.6253\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 2.5226 - val_loss: 3.6236\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 2.5075 - val_loss: 3.6306\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 2.4951 - val_loss: 3.5761\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 2.4809 - val_loss: 3.5502\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.4671 - val_loss: 3.5457\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.4554 - val_loss: 3.5308\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.4421 - val_loss: 3.5079\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.4286 - val_loss: 3.4973\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.4178 - val_loss: 3.4882\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.4052 - val_loss: 3.4962\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.3939 - val_loss: 3.4948\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 2.3822 - val_loss: 3.4376\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 2.3696 - val_loss: 3.4327\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 2.3585 - val_loss: 3.4039\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.3471 - val_loss: 3.4114\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.3364 - val_loss: 3.3717\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 2.3241 - val_loss: 3.3927\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.3146 - val_loss: 3.3729\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 2.3038 - val_loss: 3.3508\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 2.2934 - val_loss: 3.3355\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.2847 - val_loss: 3.3157\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 2.2734 - val_loss: 3.2996\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.2638 - val_loss: 3.2853\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 2.2535 - val_loss: 3.2928\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.2430 - val_loss: 3.3009\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.2324 - val_loss: 3.2711\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.2243 - val_loss: 3.2613\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 2.2151 - val_loss: 3.2482\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.2062 - val_loss: 3.2251\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.1971 - val_loss: 3.2107\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.1876 - val_loss: 3.1930\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.1789 - val_loss: 3.1918\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 2.1692 - val_loss: 3.1846\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 2.1618 - val_loss: 3.1699\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.1520 - val_loss: 3.1581\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.1431 - val_loss: 3.1373\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.1362 - val_loss: 3.1438\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 2.1271 - val_loss: 3.1266\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.1194 - val_loss: 3.1158\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 2.1116 - val_loss: 3.1111\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.1029 - val_loss: 3.1019\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.0938 - val_loss: 3.0906\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.0867 - val_loss: 3.0897\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.0793 - val_loss: 3.0783\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.0715 - val_loss: 3.0730\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.0638 - val_loss: 3.0532\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.0556 - val_loss: 3.0607\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.0493 - val_loss: 3.0652\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.0416 - val_loss: 3.0277\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.0337 - val_loss: 3.0098\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 2.0270 - val_loss: 3.0186\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.0200 - val_loss: 3.0132\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.0120 - val_loss: 2.9935\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 2.0039 - val_loss: 2.9947\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.9975 - val_loss: 2.9702\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.9914 - val_loss: 2.9780\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.9844 - val_loss: 2.9590\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.9774 - val_loss: 2.9594\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.9708 - val_loss: 2.9411\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.9635 - val_loss: 2.9263\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.9568 - val_loss: 2.9329\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.9509 - val_loss: 2.9190\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.9443 - val_loss: 2.9254\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.9376 - val_loss: 2.9120\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.9313 - val_loss: 2.9005\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.9256 - val_loss: 2.8810\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.9188 - val_loss: 2.8832\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.9126 - val_loss: 2.8678\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.9068 - val_loss: 2.8560\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.9004 - val_loss: 2.8529\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.8924 - val_loss: 2.8282\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.8883 - val_loss: 2.8514\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.8821 - val_loss: 2.8407\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.8761 - val_loss: 2.8216\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.8696 - val_loss: 2.8189\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.8641 - val_loss: 2.8165\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.8584 - val_loss: 2.8100\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.8527 - val_loss: 2.8079\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.8467 - val_loss: 2.7837\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.8416 - val_loss: 2.7781\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.8355 - val_loss: 2.7887\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.8301 - val_loss: 2.7694\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.8243 - val_loss: 2.7636\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.8189 - val_loss: 2.7564\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.8132 - val_loss: 2.7677\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 1.8078 - val_loss: 2.7668\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.8028 - val_loss: 2.7301\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 1.7976 - val_loss: 2.7343\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.7926 - val_loss: 2.7228\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.7871 - val_loss: 2.7092\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.7814 - val_loss: 2.6993\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 1.7769 - val_loss: 2.7027\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 1.7713 - val_loss: 2.7121\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.7664 - val_loss: 2.6905\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.7609 - val_loss: 2.6925\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.7561 - val_loss: 2.6832\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.7513 - val_loss: 2.6857\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.7462 - val_loss: 2.6853\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.7413 - val_loss: 2.6685\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.7365 - val_loss: 2.6589\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.7313 - val_loss: 2.6547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.7263 - val_loss: 2.6443\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.7223 - val_loss: 2.6443\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.7172 - val_loss: 2.6400\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.7121 - val_loss: 2.6489\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.7075 - val_loss: 2.6356\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.7024 - val_loss: 2.6199\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.6978 - val_loss: 2.6143\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.6933 - val_loss: 2.5878\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.6888 - val_loss: 2.6119\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.6845 - val_loss: 2.5954\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.6794 - val_loss: 2.5872\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.6754 - val_loss: 2.5825\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.6705 - val_loss: 2.5670\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.6669 - val_loss: 2.5721\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.6618 - val_loss: 2.5654\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.6579 - val_loss: 2.5591\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.6537 - val_loss: 2.5593\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.6493 - val_loss: 2.5426\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 1.6453 - val_loss: 2.5447\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.6402 - val_loss: 2.5313\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.6361 - val_loss: 2.5340\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.6319 - val_loss: 2.5323\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.6279 - val_loss: 2.5351\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.6234 - val_loss: 2.5149\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.6195 - val_loss: 2.5087\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.6150 - val_loss: 2.5197\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.6114 - val_loss: 2.5046\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.6067 - val_loss: 2.5100\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.6028 - val_loss: 2.4792\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.5989 - val_loss: 2.4852\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.5950 - val_loss: 2.4955\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.5909 - val_loss: 2.4854\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.5867 - val_loss: 2.4808\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.5828 - val_loss: 2.4714\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.5788 - val_loss: 2.4572\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.5749 - val_loss: 2.4519\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.5711 - val_loss: 2.4615\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.5672 - val_loss: 2.4480\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.5637 - val_loss: 2.4388\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.5601 - val_loss: 2.4379\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.5559 - val_loss: 2.4316\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.5518 - val_loss: 2.4346\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.5487 - val_loss: 2.4247\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.5451 - val_loss: 2.4171\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.5412 - val_loss: 2.4219\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.5374 - val_loss: 2.4009\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.5337 - val_loss: 2.4037\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.5295 - val_loss: 2.4001\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.5265 - val_loss: 2.3955\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 1.5230 - val_loss: 2.3998\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 1.5191 - val_loss: 2.3848\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.5156 - val_loss: 2.3975\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.5117 - val_loss: 2.3894\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.5084 - val_loss: 2.3889\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.5050 - val_loss: 2.3750\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.5006 - val_loss: 2.3531\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.4978 - val_loss: 2.3700\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.4944 - val_loss: 2.3527\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.4909 - val_loss: 2.3575\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.4875 - val_loss: 2.3564\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.4837 - val_loss: 2.3494\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.4807 - val_loss: 2.3319\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.4770 - val_loss: 2.3407\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.4737 - val_loss: 2.3304\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.4707 - val_loss: 2.3322\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.4672 - val_loss: 2.3313\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.4639 - val_loss: 2.3169\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.4611 - val_loss: 2.3196\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.4575 - val_loss: 2.3106\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.4540 - val_loss: 2.3115\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.4505 - val_loss: 2.3121\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.4472 - val_loss: 2.2972\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.4444 - val_loss: 2.2930\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.4405 - val_loss: 2.2878\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 1.4380 - val_loss: 2.2954\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.4348 - val_loss: 2.2868\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.4313 - val_loss: 2.2807\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.4286 - val_loss: 2.2846\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.4253 - val_loss: 2.2745\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.4219 - val_loss: 2.2794\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.4190 - val_loss: 2.2676\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.4155 - val_loss: 2.2567\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.4129 - val_loss: 2.2600\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.4094 - val_loss: 2.2542\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 1.4066 - val_loss: 2.2520\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.4033 - val_loss: 2.2407\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.4007 - val_loss: 2.2389\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.3974 - val_loss: 2.2405\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.3941 - val_loss: 2.2428\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.3917 - val_loss: 2.2211\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.3890 - val_loss: 2.2287\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.3855 - val_loss: 2.2119\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.3828 - val_loss: 2.2263\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.3802 - val_loss: 2.2127\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.3763 - val_loss: 2.2205\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.3736 - val_loss: 2.2208\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.3714 - val_loss: 2.2078\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "moptimizer = Adagrad(lr=0.01)\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1, kernel_initializer='uniform'))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_wd_sig__onelayer = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "moptimizer = Adagrad(lr=0.001)\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform'))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_wd_rel_onelayer  = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "moptimizer = Adagrad(lr=0.01)\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1, kernel_initializer='uniform',W_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_wd_sig_twolayers = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "moptimizer = Adagrad(lr=0.001)\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform',W_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_wd_rel_twolayers = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1584 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2,figsize=(16,22))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(history_wd_sig__onelayer.history['val_loss'])\n",
    "plt.plot(history_wd_sig__onelayer.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDE --WD EN UNA CAPA')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(history_wd_rel_onelayer.history['val_loss'])\n",
    "plt.plot(history_wd_rel_onelayer.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO RELU --WD EN UNA CAPA')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(history_wd_sig_twolayers.history['val_loss'])\n",
    "plt.plot(history_wd_sig_twolayers.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDE --WD EN AMBAS  CAPA')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(history_wd_rel_twolayers.history['val_loss'])\n",
    "plt.plot(history_wd_rel_twolayers.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO RELU --WD EN AMBAS CAPAS')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify>Como en las otras pruebas de sensibilidad en la primera fila se evalua el rendimiento de los modelos con el decaimiento de los pesos en una sola capa, y en la segunda fila aplicando el mismo criterio en las dos capas, es interesante encontrar que el comportamiento de ambos modelos se mantiene, con un error alto el modelo que utiliza <b>ReLU</b> como función de activación, sin encontrrar muchas diferencias en ambos gráficos en el caso del modelo Sigmoide, pero si con un aumento del error en  <b>ReLU</b>  con el decaimiento de los pesos en ambas capas, esto puede deberse a que la función introduce cierto nivel de Sparcidad que da como consecuencia problemas en el algoritmo de aprendizaje. Es muy resaltable los resultados obtenidos por el modelo <b>SIGMOIDE</b> con un error muy cercano a 0, y con una velocidad muy rapida de convergencia a su punto mínimo.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=1275, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 9.5370 - val_loss: 1.0684\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.0818 - val_loss: 0.8742\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.9037 - val_loss: 0.7195\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.8826 - val_loss: 0.8142\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.8536 - val_loss: 0.7219\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.8099 - val_loss: 0.7834\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.8313 - val_loss: 0.7274\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.8110 - val_loss: 0.7399\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.7998 - val_loss: 0.6773\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.8013 - val_loss: 0.6847\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.7909 - val_loss: 0.9126\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.7939 - val_loss: 0.7014\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.7836 - val_loss: 0.6766\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.7758 - val_loss: 0.6754\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.7723 - val_loss: 0.6978\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.7644 - val_loss: 0.6669\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.7586 - val_loss: 0.6605\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.7576 - val_loss: 0.6482\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.7557 - val_loss: 0.7079\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.7475 - val_loss: 0.6445\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.7469 - val_loss: 0.6465\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.7363 - val_loss: 0.6411\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.7459 - val_loss: 0.6376\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.7339 - val_loss: 0.6560\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.7302 - val_loss: 0.6444\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.7303 - val_loss: 0.6435\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.7253 - val_loss: 0.6318\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.7194 - val_loss: 0.6564\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.7184 - val_loss: 0.6160\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.7178 - val_loss: 0.6135\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.7139 - val_loss: 0.6301\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.7054 - val_loss: 0.6100\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.7071 - val_loss: 0.6037\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.7047 - val_loss: 0.6036\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.6976 - val_loss: 0.6091\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.7004 - val_loss: 0.6128\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.6945 - val_loss: 0.6460\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.6893 - val_loss: 0.5879\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.6860 - val_loss: 0.5927\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.6851 - val_loss: 0.6219\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.6866 - val_loss: 0.5905\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.6761 - val_loss: 0.5930\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.6732 - val_loss: 0.5797\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.6693 - val_loss: 0.6082\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.6710 - val_loss: 0.6005\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 0.6738 - val_loss: 0.5851\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.6681 - val_loss: 0.5720\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.6591 - val_loss: 0.6407\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.6616 - val_loss: 0.5771\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.6564 - val_loss: 0.5733\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.6539 - val_loss: 0.5967\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.6495 - val_loss: 0.5647\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.6500 - val_loss: 0.5673\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.6455 - val_loss: 0.6034\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.6457 - val_loss: 0.5789\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.6376 - val_loss: 0.5490\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.6388 - val_loss: 0.5755\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.6318 - val_loss: 0.5794\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.6384 - val_loss: 0.5769\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.6298 - val_loss: 0.5653\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.6269 - val_loss: 0.5578\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.6268 - val_loss: 0.5439\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 224us/step - loss: 0.6241 - val_loss: 0.5493\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.6196 - val_loss: 0.5311\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.6224 - val_loss: 0.5319\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.6149 - val_loss: 0.5398\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.6134 - val_loss: 0.5968\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.6122 - val_loss: 0.5437\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.6086 - val_loss: 0.5332\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.6037 - val_loss: 0.5207\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.6039 - val_loss: 0.5565\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.5994 - val_loss: 0.5192\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.5991 - val_loss: 0.5360\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.5999 - val_loss: 0.6048\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.5961 - val_loss: 0.5502\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.5921 - val_loss: 0.5281\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.5884 - val_loss: 0.5375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.5867 - val_loss: 0.5076\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.5824 - val_loss: 0.5189\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.5857 - val_loss: 0.5219\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.5786 - val_loss: 0.5045\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.5763 - val_loss: 0.5206\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.5787 - val_loss: 0.5085\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.5726 - val_loss: 0.5274\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.5715 - val_loss: 0.5043\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5682 - val_loss: 0.4928\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.5702 - val_loss: 0.4904\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5673 - val_loss: 0.4913\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.5638 - val_loss: 0.4883\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5634 - val_loss: 0.4932\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.5614 - val_loss: 0.5058\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.5570 - val_loss: 0.5064\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.5550 - val_loss: 0.4913\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.5529 - val_loss: 0.4857\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.5501 - val_loss: 0.4866\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.5504 - val_loss: 0.4901\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.5465 - val_loss: 0.4938\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.5456 - val_loss: 0.4767\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.5432 - val_loss: 0.4953\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5472 - val_loss: 0.5068\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.5370 - val_loss: 0.4778\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.5360 - val_loss: 0.4709\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.5349 - val_loss: 0.4688\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.5401 - val_loss: 0.4719\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5309 - val_loss: 0.4756\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.5315 - val_loss: 0.4871\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5315 - val_loss: 0.4666\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.5294 - val_loss: 0.4684\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.5252 - val_loss: 0.4628\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5258 - val_loss: 0.4620\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.5196 - val_loss: 0.4573\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.5190 - val_loss: 0.4596\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.5203 - val_loss: 0.4562\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.5173 - val_loss: 0.4515\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.5164 - val_loss: 0.4595\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.5161 - val_loss: 0.4859\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.5132 - val_loss: 0.4556\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.5099 - val_loss: 0.4629\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.5074 - val_loss: 0.4700\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5082 - val_loss: 0.4560\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.5064 - val_loss: 0.4505\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5056 - val_loss: 0.4534\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.5019 - val_loss: 0.4419\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5021 - val_loss: 0.4430\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.5023 - val_loss: 0.4480\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.5003 - val_loss: 0.4395\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4957 - val_loss: 0.4515\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4970 - val_loss: 0.4616\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4978 - val_loss: 0.4754\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 0.4940 - val_loss: 0.4387\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4909 - val_loss: 0.4345\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4899 - val_loss: 0.4426\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4882 - val_loss: 0.4287\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4852 - val_loss: 0.4410\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4851 - val_loss: 0.4502\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4806 - val_loss: 0.4691\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4842 - val_loss: 0.4314\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4786 - val_loss: 0.4254\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4822 - val_loss: 0.4359\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4798 - val_loss: 0.4332\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4792 - val_loss: 0.4460\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4757 - val_loss: 0.4283\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4748 - val_loss: 0.4332\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4740 - val_loss: 0.4223\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.4703 - val_loss: 0.4307\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4717 - val_loss: 0.4259\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.4681 - val_loss: 0.4244\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4641 - val_loss: 0.4449\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4661 - val_loss: 0.4167\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4670 - val_loss: 0.4118\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4644 - val_loss: 0.4103\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4620 - val_loss: 0.4377\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4603 - val_loss: 0.4467\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4587 - val_loss: 0.4189\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4574 - val_loss: 0.4046\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.4579 - val_loss: 0.4319\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4549 - val_loss: 0.4172\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4530 - val_loss: 0.4183\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.4492 - val_loss: 0.4119\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4490 - val_loss: 0.4175\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.4526 - val_loss: 0.4335\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4490 - val_loss: 0.4308\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4511 - val_loss: 0.4252\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4473 - val_loss: 0.4013\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4448 - val_loss: 0.3999\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.4440 - val_loss: 0.4176\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4460 - val_loss: 0.4012\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4428 - val_loss: 0.4161\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4419 - val_loss: 0.4063\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.4395 - val_loss: 0.4025\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.4396 - val_loss: 0.4092\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.4404 - val_loss: 0.4069\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4378 - val_loss: 0.3954\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4340 - val_loss: 0.4427\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4364 - val_loss: 0.3922\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4368 - val_loss: 0.3903\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.4379 - val_loss: 0.4204\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4333 - val_loss: 0.3887\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4312 - val_loss: 0.3865\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4279 - val_loss: 0.3918\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4275 - val_loss: 0.3911\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4291 - val_loss: 0.3846\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4297 - val_loss: 0.3904\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4261 - val_loss: 0.3884\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4233 - val_loss: 0.3893\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4245 - val_loss: 0.4095\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4221 - val_loss: 0.3962\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4247 - val_loss: 0.4221\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.4197 - val_loss: 0.3823\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4194 - val_loss: 0.3968\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4175 - val_loss: 0.3730\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4181 - val_loss: 0.3772\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4166 - val_loss: 0.3827\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4169 - val_loss: 0.3713\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.4134 - val_loss: 0.3805\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4139 - val_loss: 0.3678\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4119 - val_loss: 0.3697\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4106 - val_loss: 0.3761\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4105 - val_loss: 0.3763\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.4075 - val_loss: 0.3770\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4090 - val_loss: 0.3662\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4076 - val_loss: 0.3712\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4080 - val_loss: 0.3686\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4045 - val_loss: 0.3690\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4010 - val_loss: 0.3640\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4072 - val_loss: 0.3949\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4038 - val_loss: 0.4230\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4035 - val_loss: 0.3833\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4011 - val_loss: 0.3672\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3969 - val_loss: 0.3620\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4002 - val_loss: 0.3615\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3981 - val_loss: 0.3629\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3990 - val_loss: 0.3638\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3968 - val_loss: 0.3665\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.3963 - val_loss: 0.3578\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3957 - val_loss: 0.3646\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3936 - val_loss: 0.3569\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3917 - val_loss: 0.3551\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3912 - val_loss: 0.3585\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3938 - val_loss: 0.3772\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3876 - val_loss: 0.3719\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3846 - val_loss: 0.3579\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.3912 - val_loss: 0.3679\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3878 - val_loss: 0.3600\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3870 - val_loss: 0.3510\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3890 - val_loss: 0.3564\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3865 - val_loss: 0.3579\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3849 - val_loss: 0.3491\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3849 - val_loss: 0.3450\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3823 - val_loss: 0.3709\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3852 - val_loss: 0.3494\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3817 - val_loss: 0.3554\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3824 - val_loss: 0.3514\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.3779 - val_loss: 0.3497\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3777 - val_loss: 0.3460\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.3794 - val_loss: 0.3547\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3756 - val_loss: 0.3612\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3754 - val_loss: 0.3462\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 0.3765 - val_loss: 0.3401\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3760 - val_loss: 0.3384\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.3742 - val_loss: 0.3413\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3728 - val_loss: 0.3394\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.3722 - val_loss: 0.3363\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3703 - val_loss: 0.3423\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.3694 - val_loss: 0.3391\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.3703 - val_loss: 0.3888\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.3681 - val_loss: 0.3407\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.3666 - val_loss: 0.3441\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.3674 - val_loss: 0.3547\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.3688 - val_loss: 0.3333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=1275, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 35.3036 - val_loss: 24.8727\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 19.2924 - val_loss: 20.1134\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 16.5405 - val_loss: 17.7455\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 14.9724 - val_loss: 16.1421\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 13.8785 - val_loss: 15.2110\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 13.0258 - val_loss: 14.4242\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 201us/step - loss: 12.4048 - val_loss: 13.8043\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 11.8469 - val_loss: 13.2045\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 11.4141 - val_loss: 12.6860\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 10.9969 - val_loss: 12.3086\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 10.6466 - val_loss: 11.8525\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 10.3219 - val_loss: 11.5760\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 10.0302 - val_loss: 11.2449\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 9.7596 - val_loss: 10.9721\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 9.5045 - val_loss: 10.7343\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 9.2772 - val_loss: 10.4882\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 9.0566 - val_loss: 10.3314\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 8.8599 - val_loss: 10.0796\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 8.6771 - val_loss: 9.8532\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 8.4953 - val_loss: 9.7032\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 8.3182 - val_loss: 9.5237\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 8.1593 - val_loss: 9.3548\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 8.0039 - val_loss: 9.2194\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 7.8592 - val_loss: 9.0896\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 7.7174 - val_loss: 8.9139\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 7.5844 - val_loss: 8.7686\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 7.4524 - val_loss: 8.6154\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 7.3262 - val_loss: 8.5086\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 7.2049 - val_loss: 8.3419\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 7.0889 - val_loss: 8.2224\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 6.9808 - val_loss: 8.1724\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 6.8727 - val_loss: 8.0101\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 6.7653 - val_loss: 7.9247\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 6.6654 - val_loss: 7.8148\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 6.5680 - val_loss: 7.7440\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 6.4713 - val_loss: 7.6185\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 6.3805 - val_loss: 7.5385\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 6.2941 - val_loss: 7.4193\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 6.2053 - val_loss: 7.3386\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 6.1213 - val_loss: 7.2241\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 6.0363 - val_loss: 7.1776\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 5.9554 - val_loss: 7.1329\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 5.8820 - val_loss: 6.9850\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 5.8047 - val_loss: 6.9337\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 5.7314 - val_loss: 6.8335\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 5.6594 - val_loss: 6.7684\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 5.5877 - val_loss: 6.6656\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 5.5208 - val_loss: 6.6272\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 5.4540 - val_loss: 6.5217\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 5.3892 - val_loss: 6.4592\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 5.3258 - val_loss: 6.4134\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 5.2633 - val_loss: 6.3172\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 5.2002 - val_loss: 6.2612\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 5.1412 - val_loss: 6.2052\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 5.0848 - val_loss: 6.1429\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 5.0265 - val_loss: 6.0824\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 4.9709 - val_loss: 6.0269\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 4.9161 - val_loss: 5.9782\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 4.8627 - val_loss: 5.9312\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 4.8088 - val_loss: 5.8616\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 4.7605 - val_loss: 5.8003\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 4.7101 - val_loss: 5.7646\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 4.6598 - val_loss: 5.6916\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 4.6123 - val_loss: 5.6536\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 4.5640 - val_loss: 5.5999\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 4.5171 - val_loss: 5.5494\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 4.4694 - val_loss: 5.4970\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 4.4289 - val_loss: 5.4529\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 4.3789 - val_loss: 5.4316\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 4.3401 - val_loss: 5.3657\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 4.2973 - val_loss: 5.2928\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 4.2551 - val_loss: 5.2691\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 4.2135 - val_loss: 5.2282\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 4.1746 - val_loss: 5.1823\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 4.1338 - val_loss: 5.1131\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 4.0949 - val_loss: 5.0797\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 4.0570 - val_loss: 5.0521\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 4.0208 - val_loss: 5.0028\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 3.9838 - val_loss: 4.9570\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 3.9469 - val_loss: 4.9072\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 3.9107 - val_loss: 4.8919\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 3.8754 - val_loss: 4.8516\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 3.8419 - val_loss: 4.8211\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 3.8055 - val_loss: 4.7702\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 3.7741 - val_loss: 4.7685\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 3.7398 - val_loss: 4.6948\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 3.7093 - val_loss: 4.6828\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 3.6762 - val_loss: 4.6303\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 3.6447 - val_loss: 4.6177\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 3.6134 - val_loss: 4.5848\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 3.5833 - val_loss: 4.5366\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 3.5540 - val_loss: 4.5292\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 3.5226 - val_loss: 4.4869\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 3.4947 - val_loss: 4.4728\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 3.4664 - val_loss: 4.4239\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 3.4380 - val_loss: 4.3921\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 3.4094 - val_loss: 4.3693\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 3.3844 - val_loss: 4.3223\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 3.3562 - val_loss: 4.3009\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 3.3284 - val_loss: 4.2591\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 3.3010 - val_loss: 4.2510\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 3.2760 - val_loss: 4.2047\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 3.2501 - val_loss: 4.1854\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 3.2251 - val_loss: 4.1545\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 3.2003 - val_loss: 4.1513\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 3.1755 - val_loss: 4.1057\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 3.1516 - val_loss: 4.0982\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 3.1272 - val_loss: 4.0429\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 3.1048 - val_loss: 4.0289\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 3.0800 - val_loss: 4.0040\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 3.0561 - val_loss: 3.9720\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 3.0350 - val_loss: 3.9502\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 3.0139 - val_loss: 3.9366\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.9910 - val_loss: 3.9179\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 2.9683 - val_loss: 3.8819\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 2.9461 - val_loss: 3.8801\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.9259 - val_loss: 3.8354\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.9052 - val_loss: 3.8186\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.8841 - val_loss: 3.8144\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 2.8647 - val_loss: 3.7892\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.8438 - val_loss: 3.7719\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.8232 - val_loss: 3.7472\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.8048 - val_loss: 3.7089\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.7865 - val_loss: 3.6887\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.7654 - val_loss: 3.6978\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.7469 - val_loss: 3.6534\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 2.7285 - val_loss: 3.6167\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.7095 - val_loss: 3.6223\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 2.6911 - val_loss: 3.5868\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.6721 - val_loss: 3.5704\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.6551 - val_loss: 3.5571\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.6373 - val_loss: 3.5244\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.6196 - val_loss: 3.5198\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 2.6030 - val_loss: 3.4874\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.5855 - val_loss: 3.4648\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.5679 - val_loss: 3.4589\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.5520 - val_loss: 3.4422\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.5346 - val_loss: 3.4220\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.5195 - val_loss: 3.3948\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 2.5027 - val_loss: 3.3610\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.4870 - val_loss: 3.3517\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.4709 - val_loss: 3.3462\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.4563 - val_loss: 3.3413\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.4388 - val_loss: 3.3275\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 2.4255 - val_loss: 3.2785\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.4091 - val_loss: 3.2688\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 2.3955 - val_loss: 3.2453\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 2.3805 - val_loss: 3.2655\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.3658 - val_loss: 3.2334\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 2.3521 - val_loss: 3.2189\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.3369 - val_loss: 3.2060\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.3226 - val_loss: 3.1867\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.3092 - val_loss: 3.1626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.2937 - val_loss: 3.1510\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.2817 - val_loss: 3.1382\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.2683 - val_loss: 3.1198\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.2539 - val_loss: 3.1140\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.2411 - val_loss: 3.0853\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 2.2276 - val_loss: 3.0817\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.2143 - val_loss: 3.0606\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 2.2025 - val_loss: 3.0527\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.1889 - val_loss: 3.0415\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.1771 - val_loss: 3.0128\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.1631 - val_loss: 3.0294\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.1528 - val_loss: 2.9944\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 2.1393 - val_loss: 2.9778\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.1286 - val_loss: 2.9511\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 2.1156 - val_loss: 2.9697\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 2.1039 - val_loss: 2.9349\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 2.0919 - val_loss: 2.9109\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 2.0798 - val_loss: 2.8970\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 2.0686 - val_loss: 2.8934\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 2.0587 - val_loss: 2.8839\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 2.0456 - val_loss: 2.9121\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 2.0358 - val_loss: 2.8646\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 2.0248 - val_loss: 2.8500\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 2.0125 - val_loss: 2.8435\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 2.0024 - val_loss: 2.8474\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.9918 - val_loss: 2.8208\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.9807 - val_loss: 2.8061\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.9703 - val_loss: 2.8150\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 1.9599 - val_loss: 2.7711\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.9483 - val_loss: 2.7717\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.9396 - val_loss: 2.7591\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 1.9285 - val_loss: 2.7463\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.9193 - val_loss: 2.7332\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.9092 - val_loss: 2.7298\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.8996 - val_loss: 2.7186\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.8901 - val_loss: 2.7088\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.8798 - val_loss: 2.6789\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.8710 - val_loss: 2.6830\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.8611 - val_loss: 2.6583\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.8517 - val_loss: 2.6658\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.8419 - val_loss: 2.6497\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.8334 - val_loss: 2.6400\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.8235 - val_loss: 2.6240\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.8145 - val_loss: 2.5980\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.8066 - val_loss: 2.6138\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.7976 - val_loss: 2.5944\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.7879 - val_loss: 2.5959\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.7791 - val_loss: 2.5840\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.7703 - val_loss: 2.5697\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.7614 - val_loss: 2.5548\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.7536 - val_loss: 2.5463\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.7450 - val_loss: 2.5254\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.7373 - val_loss: 2.5359\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.7287 - val_loss: 2.5168\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.7197 - val_loss: 2.5228\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.7113 - val_loss: 2.5207\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 1.7031 - val_loss: 2.4801\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.6970 - val_loss: 2.4843\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.6878 - val_loss: 2.4802\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.6793 - val_loss: 2.4777\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.6721 - val_loss: 2.4345\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.6653 - val_loss: 2.4696\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.6569 - val_loss: 2.4331\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 1.6501 - val_loss: 2.4367\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.6406 - val_loss: 2.4247\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.6345 - val_loss: 2.4307\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.6277 - val_loss: 2.4001\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.6200 - val_loss: 2.3889\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.6131 - val_loss: 2.3773\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.6052 - val_loss: 2.3784\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.5983 - val_loss: 2.3657\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.5910 - val_loss: 2.3582\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.5837 - val_loss: 2.3628\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 1.5776 - val_loss: 2.3542\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.5695 - val_loss: 2.3366\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 1.5623 - val_loss: 2.3198\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.5567 - val_loss: 2.3352\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.5491 - val_loss: 2.3313\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.5420 - val_loss: 2.3001\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.5362 - val_loss: 2.2973\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 1.5290 - val_loss: 2.3038\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.5220 - val_loss: 2.2794\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.5145 - val_loss: 2.2904\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.5102 - val_loss: 2.2761\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.5046 - val_loss: 2.2647\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 1.4977 - val_loss: 2.2600\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.4897 - val_loss: 2.2371\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 1.4837 - val_loss: 2.2531\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.4793 - val_loss: 2.2508\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 1.4718 - val_loss: 2.2369\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 1.4657 - val_loss: 2.2164\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.4606 - val_loss: 2.2047\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 1.4543 - val_loss: 2.2211\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 1.4477 - val_loss: 2.2200\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 200us/step - loss: 1.4424 - val_loss: 2.1970\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 1.4365 - val_loss: 2.1903\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.4304 - val_loss: 2.1808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=1275, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 9.5316 - val_loss: 1.8863\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 1.1003 - val_loss: 0.9206\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.9618 - val_loss: 0.7570\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.8960 - val_loss: 0.7385\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.8834 - val_loss: 0.8243\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.8664 - val_loss: 0.8053\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.8497 - val_loss: 0.7216\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.8452 - val_loss: 0.7159\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 221us/step - loss: 0.8402 - val_loss: 0.7239\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.8357 - val_loss: 0.7582\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.8262 - val_loss: 0.7460\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.8147 - val_loss: 0.7359\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.8140 - val_loss: 0.7049\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.8084 - val_loss: 0.7264\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.8079 - val_loss: 0.7654\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.8124 - val_loss: 0.6936\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.7980 - val_loss: 0.7403\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.7963 - val_loss: 0.7305\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.7898 - val_loss: 0.6836\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.7866 - val_loss: 0.6873\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.7812 - val_loss: 0.6775\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.7881 - val_loss: 0.6873\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.7841 - val_loss: 0.6884\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.7781 - val_loss: 0.6996\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.7713 - val_loss: 0.7148\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.7814 - val_loss: 0.6744\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.7736 - val_loss: 0.6722\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.7698 - val_loss: 0.6882\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.7701 - val_loss: 0.6704\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.7669 - val_loss: 0.6639\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.7654 - val_loss: 0.7208\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.7587 - val_loss: 0.6852\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.7588 - val_loss: 0.6643\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.7569 - val_loss: 0.6909\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.7572 - val_loss: 0.6604\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.7502 - val_loss: 0.6900\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.7531 - val_loss: 0.6821\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.7457 - val_loss: 0.6641\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.7488 - val_loss: 0.6623\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.7464 - val_loss: 0.6765\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.7406 - val_loss: 0.6520\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.7377 - val_loss: 0.6469\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.7370 - val_loss: 0.6474\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.7347 - val_loss: 0.6502\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.7380 - val_loss: 0.6363\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.7321 - val_loss: 0.6419\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.7280 - val_loss: 0.6458\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.7284 - val_loss: 0.6418\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.7269 - val_loss: 0.6407\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.7282 - val_loss: 0.6397\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.7220 - val_loss: 0.6460\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.7159 - val_loss: 0.6353\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.7158 - val_loss: 0.6488\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.7159 - val_loss: 0.6243\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.7130 - val_loss: 0.6291\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.7106 - val_loss: 0.6814\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.7131 - val_loss: 0.6249\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.7089 - val_loss: 0.6416\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.7076 - val_loss: 0.6288\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.7034 - val_loss: 0.6200\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 217us/step - loss: 0.7038 - val_loss: 0.6296\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 0.7043 - val_loss: 0.6300\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 225us/step - loss: 0.7024 - val_loss: 0.6784\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.6972 - val_loss: 0.6278\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.6974 - val_loss: 0.6961\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.6995 - val_loss: 0.6146\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.6930 - val_loss: 0.6154\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.6896 - val_loss: 0.6280\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.6912 - val_loss: 0.6846\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.6920 - val_loss: 0.6171\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.6872 - val_loss: 0.6089\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.6859 - val_loss: 0.6037\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.6833 - val_loss: 0.6026\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.6801 - val_loss: 0.6107\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.6794 - val_loss: 0.6044\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.6804 - val_loss: 0.5984\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.6766 - val_loss: 0.6039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.6741 - val_loss: 0.6061\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.6723 - val_loss: 0.6037\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.6680 - val_loss: 0.6562\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.6703 - val_loss: 0.5979\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.6680 - val_loss: 0.5925\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.6648 - val_loss: 0.5913\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.6620 - val_loss: 0.5854\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.6618 - val_loss: 0.5948\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.6567 - val_loss: 0.5908\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.6547 - val_loss: 0.5836\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.6578 - val_loss: 0.5873\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.6539 - val_loss: 0.5995\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.6543 - val_loss: 0.6025\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.6508 - val_loss: 0.5771\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.6461 - val_loss: 0.5815\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.6469 - val_loss: 0.5748\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.6446 - val_loss: 0.5829\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.6413 - val_loss: 0.5801\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.6431 - val_loss: 0.5742\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.6406 - val_loss: 0.5788\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.6357 - val_loss: 0.5625\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.6340 - val_loss: 0.5687\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.6330 - val_loss: 0.5565\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.6312 - val_loss: 0.5621\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.6279 - val_loss: 0.5773\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.6251 - val_loss: 0.5935\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.6218 - val_loss: 0.5547\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 203us/step - loss: 0.6217 - val_loss: 0.5632\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.6222 - val_loss: 0.5551\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.6211 - val_loss: 0.5525\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.6189 - val_loss: 0.5521\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.6147 - val_loss: 0.5588\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.6138 - val_loss: 0.5525\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.6125 - val_loss: 0.5433\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.6150 - val_loss: 0.5448\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.6095 - val_loss: 0.5551\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.6065 - val_loss: 0.5369\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.6060 - val_loss: 0.5494\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.6044 - val_loss: 0.5352\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.6051 - val_loss: 0.5353\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.6015 - val_loss: 0.5344\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5988 - val_loss: 0.5354\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.5989 - val_loss: 0.5340\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 219us/step - loss: 0.5987 - val_loss: 0.5496\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.5970 - val_loss: 0.5598\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.5923 - val_loss: 0.5330\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5921 - val_loss: 0.5558\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 202us/step - loss: 0.5888 - val_loss: 0.5248\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.5893 - val_loss: 0.5242\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.5880 - val_loss: 0.5267\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5843 - val_loss: 0.5256\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 222us/step - loss: 0.5859 - val_loss: 0.5295\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.5819 - val_loss: 0.5226\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.5807 - val_loss: 0.5199\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.5794 - val_loss: 0.5178\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.5787 - val_loss: 0.5102\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 3s 299us/step - loss: 0.5784 - val_loss: 0.5142\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 3s 277us/step - loss: 0.5764 - val_loss: 0.5247\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.5733 - val_loss: 0.5413\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.5715 - val_loss: 0.5058\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.5719 - val_loss: 0.5120\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 240us/step - loss: 0.5720 - val_loss: 0.5107\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.5716 - val_loss: 0.5210\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.5685 - val_loss: 0.5133\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.5645 - val_loss: 0.5120\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.5668 - val_loss: 0.5152\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.5642 - val_loss: 0.5003\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 0.5611 - val_loss: 0.5013\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.5622 - val_loss: 0.5679\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.5590 - val_loss: 0.5346\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.5614 - val_loss: 0.4987\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.5590 - val_loss: 0.4974\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.5534 - val_loss: 0.5148\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.5551 - val_loss: 0.5078\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 3s 285us/step - loss: 0.5531 - val_loss: 0.5010\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 3s 321us/step - loss: 0.5519 - val_loss: 0.4986\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 3s 286us/step - loss: 0.5494 - val_loss: 0.5014\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 3s 305us/step - loss: 0.5525 - val_loss: 0.5091\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.5513 - val_loss: 0.4898\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.5467 - val_loss: 0.4909\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.5472 - val_loss: 0.4919\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5440 - val_loss: 0.5036\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.5453 - val_loss: 0.4895\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.5412 - val_loss: 0.4914\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.5419 - val_loss: 0.5067\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.5420 - val_loss: 0.4926\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.5390 - val_loss: 0.4829\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.5365 - val_loss: 0.5409\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.5356 - val_loss: 0.4880\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5309 - val_loss: 0.4809\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.5360 - val_loss: 0.4819\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.5337 - val_loss: 0.4856\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.5343 - val_loss: 0.5136\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5339 - val_loss: 0.4868\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5288 - val_loss: 0.4811\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.5304 - val_loss: 0.4833\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.5322 - val_loss: 0.4796\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.5253 - val_loss: 0.4798\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5239 - val_loss: 0.5032\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.5261 - val_loss: 0.4755\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.5232 - val_loss: 0.4774\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.5238 - val_loss: 0.4754\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.5210 - val_loss: 0.4767\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5203 - val_loss: 0.4791\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.5199 - val_loss: 0.4721\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.5207 - val_loss: 0.4661\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.5189 - val_loss: 0.4758\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.5167 - val_loss: 0.4709\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5143 - val_loss: 0.4677\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.5155 - val_loss: 0.4938\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.5139 - val_loss: 0.4749\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.5095 - val_loss: 0.4716\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.5140 - val_loss: 0.4625\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.5095 - val_loss: 0.4604\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.5105 - val_loss: 0.4871\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.5111 - val_loss: 0.4775\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.5054 - val_loss: 0.4691\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.5057 - val_loss: 0.4927\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5068 - val_loss: 0.4590\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.5064 - val_loss: 0.4634\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.5055 - val_loss: 0.4626\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.5033 - val_loss: 0.4562\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.5036 - val_loss: 0.4644\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.5027 - val_loss: 0.4922\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4991 - val_loss: 0.4660\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4966 - val_loss: 0.4550\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4973 - val_loss: 0.4521\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4953 - val_loss: 0.4620\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4990 - val_loss: 0.4560\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4956 - val_loss: 0.4556\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4944 - val_loss: 0.4523\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4936 - val_loss: 0.4783\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4924 - val_loss: 0.4535\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4890 - val_loss: 0.4469\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4921 - val_loss: 0.4485\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 214us/step - loss: 0.4900 - val_loss: 0.4441\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.4868 - val_loss: 0.4537\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.4868 - val_loss: 0.4498\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4852 - val_loss: 0.4485\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.4866 - val_loss: 0.4593\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4817 - val_loss: 0.4457\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.4831 - val_loss: 0.4475\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4818 - val_loss: 0.4423\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4797 - val_loss: 0.4414\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4794 - val_loss: 0.4422\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4784 - val_loss: 0.4385\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 215us/step - loss: 0.4765 - val_loss: 0.4384\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 0.4783 - val_loss: 0.4380\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4767 - val_loss: 0.4381\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4753 - val_loss: 0.4342\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4746 - val_loss: 0.4381\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4754 - val_loss: 0.4336\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.4741 - val_loss: 0.4307\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4720 - val_loss: 0.4411\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4699 - val_loss: 0.4403\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4699 - val_loss: 0.4346\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 207us/step - loss: 0.4685 - val_loss: 0.4347\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4692 - val_loss: 0.4267\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4683 - val_loss: 0.4325\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 0.4647 - val_loss: 0.4430\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 211us/step - loss: 0.4616 - val_loss: 0.4269\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4637 - val_loss: 0.4482\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4651 - val_loss: 0.4284\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4636 - val_loss: 0.4333\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4605 - val_loss: 0.4317\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 209us/step - loss: 0.4600 - val_loss: 0.4266\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 205us/step - loss: 0.4585 - val_loss: 0.4413\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 212us/step - loss: 0.4594 - val_loss: 0.4290\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 204us/step - loss: 0.4565 - val_loss: 0.4232\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 210us/step - loss: 0.4564 - val_loss: 0.4209\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4573 - val_loss: 0.4228\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 206us/step - loss: 0.4579 - val_loss: 0.4219\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 208us/step - loss: 0.4560 - val_loss: 0.4537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=1275, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 2s 213us/step - loss: 18.0627 - val_loss: 10.2438\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 5.3309 - val_loss: 6.6956\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 3.4932 - val_loss: 5.1249\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 2.5713 - val_loss: 4.1289\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 2.0525 - val_loss: 3.5048\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 1.6839 - val_loss: 3.2481\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 1.4795 - val_loss: 2.8086\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 1.2795 - val_loss: 2.6050\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 1.1457 - val_loss: 2.4203\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 1.0368 - val_loss: 2.3273\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.9504 - val_loss: 2.1175\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 170us/step - loss: 0.8954 - val_loss: 2.1092\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.8192 - val_loss: 2.0354\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.7870 - val_loss: 1.9017\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.7446 - val_loss: 1.8653\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.7140 - val_loss: 1.8237\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.6784 - val_loss: 1.7643\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.6529 - val_loss: 1.7728\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.6324 - val_loss: 1.7407\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.6107 - val_loss: 1.6551\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.5888 - val_loss: 1.6424\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.5734 - val_loss: 1.6278\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.5550 - val_loss: 1.5812\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.5405 - val_loss: 1.5757\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.5275 - val_loss: 1.5617\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.5154 - val_loss: 1.5256\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.5008 - val_loss: 1.4768\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.4917 - val_loss: 1.4868\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.4797 - val_loss: 1.4573\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.4672 - val_loss: 1.4015\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.4606 - val_loss: 1.4082\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.4487 - val_loss: 1.4064\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.4419 - val_loss: 1.3946\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.4320 - val_loss: 1.3688\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.4224 - val_loss: 1.3655\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.4160 - val_loss: 1.3512\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.4091 - val_loss: 1.3350\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.4011 - val_loss: 1.3010\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.3961 - val_loss: 1.3203\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.3888 - val_loss: 1.2892\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.3820 - val_loss: 1.2857\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.3773 - val_loss: 1.2649\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.3716 - val_loss: 1.2867\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.3654 - val_loss: 1.2643\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.3599 - val_loss: 1.2158\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.3560 - val_loss: 1.2285\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.3491 - val_loss: 1.2220\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.3455 - val_loss: 1.2144\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.3400 - val_loss: 1.1960\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.3354 - val_loss: 1.1918\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.3322 - val_loss: 1.1791\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.3270 - val_loss: 1.1503\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.3233 - val_loss: 1.1664\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.3194 - val_loss: 1.1451\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.3153 - val_loss: 1.1364\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.3110 - val_loss: 1.1175\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.3076 - val_loss: 1.1035\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.3045 - val_loss: 1.1002\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.2997 - val_loss: 1.1347\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2970 - val_loss: 1.0884\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.2931 - val_loss: 1.0933\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2908 - val_loss: 1.0758\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.2879 - val_loss: 1.0790\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2842 - val_loss: 1.0726\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.2803 - val_loss: 1.0874\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.2790 - val_loss: 1.0675\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.2749 - val_loss: 1.0486\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2734 - val_loss: 1.0531\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.2700 - val_loss: 1.0426\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2675 - val_loss: 1.0374\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2645 - val_loss: 1.0368\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.2617 - val_loss: 1.0274\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2585 - val_loss: 1.0339\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2573 - val_loss: 1.0246\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2545 - val_loss: 1.0257\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.2519 - val_loss: 1.0118\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.2501 - val_loss: 0.9979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.2480 - val_loss: 0.9892\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.2454 - val_loss: 0.9816\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2432 - val_loss: 0.9790\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2414 - val_loss: 0.9840\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2396 - val_loss: 0.9782\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 169us/step - loss: 0.2371 - val_loss: 0.9692\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2354 - val_loss: 0.9655\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2337 - val_loss: 0.9640\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2315 - val_loss: 0.9570\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.2303 - val_loss: 0.9535\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.2278 - val_loss: 0.9451\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2266 - val_loss: 0.9452\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2244 - val_loss: 0.9395\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2219 - val_loss: 0.9473\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.2210 - val_loss: 0.9427\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2195 - val_loss: 0.9393\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2176 - val_loss: 0.9165\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2162 - val_loss: 0.9212\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.2129 - val_loss: 0.9314\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.2127 - val_loss: 0.9249\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2109 - val_loss: 0.9217\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.2093 - val_loss: 0.8954\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2079 - val_loss: 0.9059\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2065 - val_loss: 0.9106\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.2049 - val_loss: 0.8944\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.2034 - val_loss: 0.9080\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.2022 - val_loss: 0.9034\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.2005 - val_loss: 0.8930\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1996 - val_loss: 0.8873\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1985 - val_loss: 0.8840\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1966 - val_loss: 0.8790\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1955 - val_loss: 0.8803\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1942 - val_loss: 0.8614\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1933 - val_loss: 0.8656\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1919 - val_loss: 0.8600\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1902 - val_loss: 0.8609\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1891 - val_loss: 0.8498\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1879 - val_loss: 0.8675\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1871 - val_loss: 0.8479\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1857 - val_loss: 0.8574\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1849 - val_loss: 0.8451\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1833 - val_loss: 0.8536\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1825 - val_loss: 0.8349\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1816 - val_loss: 0.8415\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1805 - val_loss: 0.8341\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1798 - val_loss: 0.8237\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1786 - val_loss: 0.8380\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1772 - val_loss: 0.8291\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1761 - val_loss: 0.8479\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1752 - val_loss: 0.8262\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1744 - val_loss: 0.8279\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1730 - val_loss: 0.8067\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1726 - val_loss: 0.8109\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1717 - val_loss: 0.8214\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1709 - val_loss: 0.8104\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1699 - val_loss: 0.8086\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1688 - val_loss: 0.8136\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1682 - val_loss: 0.8143\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1670 - val_loss: 0.7969\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1663 - val_loss: 0.8093\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1655 - val_loss: 0.8038\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1646 - val_loss: 0.7950\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1634 - val_loss: 0.7999\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1634 - val_loss: 0.8018\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1621 - val_loss: 0.7873\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1616 - val_loss: 0.7932\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1607 - val_loss: 0.7851\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1599 - val_loss: 0.7958\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1593 - val_loss: 0.7794\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1583 - val_loss: 0.7945\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1575 - val_loss: 0.7786\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1571 - val_loss: 0.7878\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1562 - val_loss: 0.7826\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1553 - val_loss: 0.7710\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1550 - val_loss: 0.7793\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1541 - val_loss: 0.7810\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.1533 - val_loss: 0.7817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1532 - val_loss: 0.7681\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1519 - val_loss: 0.7724\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1514 - val_loss: 0.7624\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1509 - val_loss: 0.7672\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1503 - val_loss: 0.7609\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1494 - val_loss: 0.7694\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 171us/step - loss: 0.1490 - val_loss: 0.7633\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1482 - val_loss: 0.7573\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1474 - val_loss: 0.7473\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1471 - val_loss: 0.7607\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1464 - val_loss: 0.7617\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.1458 - val_loss: 0.7526\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1451 - val_loss: 0.7569\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1446 - val_loss: 0.7444\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1442 - val_loss: 0.7482\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1435 - val_loss: 0.7500\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1430 - val_loss: 0.7537\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1426 - val_loss: 0.7482\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1419 - val_loss: 0.7480\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1410 - val_loss: 0.7517\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1407 - val_loss: 0.7423\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1398 - val_loss: 0.7447\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.1392 - val_loss: 0.7347\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1392 - val_loss: 0.7289\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1389 - val_loss: 0.7330\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1382 - val_loss: 0.7332\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1374 - val_loss: 0.7357\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1371 - val_loss: 0.7312\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1364 - val_loss: 0.7357\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1362 - val_loss: 0.7300\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1358 - val_loss: 0.7262\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1351 - val_loss: 0.7299\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1348 - val_loss: 0.7291\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1339 - val_loss: 0.7338\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.1338 - val_loss: 0.7186\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 172us/step - loss: 0.1334 - val_loss: 0.7255\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1329 - val_loss: 0.7195\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1323 - val_loss: 0.7241\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1318 - val_loss: 0.7151\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1315 - val_loss: 0.7177\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1309 - val_loss: 0.7128\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 173us/step - loss: 0.1305 - val_loss: 0.7104\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1300 - val_loss: 0.7131\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1296 - val_loss: 0.7157\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1292 - val_loss: 0.7128\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1291 - val_loss: 0.7110\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1285 - val_loss: 0.7140\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1282 - val_loss: 0.7136\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1274 - val_loss: 0.7091\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1270 - val_loss: 0.7045\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1269 - val_loss: 0.7095\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1263 - val_loss: 0.6996\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1264 - val_loss: 0.6997\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1257 - val_loss: 0.7067\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1252 - val_loss: 0.7031\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1250 - val_loss: 0.6992\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1246 - val_loss: 0.6991\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 183us/step - loss: 0.1243 - val_loss: 0.7021\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1240 - val_loss: 0.6953\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1236 - val_loss: 0.7003\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1232 - val_loss: 0.6991\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1226 - val_loss: 0.7006\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1223 - val_loss: 0.6990\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1218 - val_loss: 0.6934\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1216 - val_loss: 0.6972\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.1214 - val_loss: 0.6919\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1211 - val_loss: 0.6880\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1206 - val_loss: 0.6942\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 174us/step - loss: 0.1203 - val_loss: 0.6913\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.1199 - val_loss: 0.6838\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.1196 - val_loss: 0.6860\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.1195 - val_loss: 0.6990\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 185us/step - loss: 0.1188 - val_loss: 0.6755\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1188 - val_loss: 0.6891\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1181 - val_loss: 0.6866\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1176 - val_loss: 0.6857\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1175 - val_loss: 0.6800\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 175us/step - loss: 0.1175 - val_loss: 0.6827\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1170 - val_loss: 0.6861\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1167 - val_loss: 0.6813\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 199us/step - loss: 0.1163 - val_loss: 0.6867\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1161 - val_loss: 0.6725\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1158 - val_loss: 0.6826\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1155 - val_loss: 0.6812\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 181us/step - loss: 0.1151 - val_loss: 0.6824\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 177us/step - loss: 0.1150 - val_loss: 0.6766\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1147 - val_loss: 0.6790\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1144 - val_loss: 0.6727\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 180us/step - loss: 0.1140 - val_loss: 0.6813\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1136 - val_loss: 0.6719\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 184us/step - loss: 0.1135 - val_loss: 0.6733\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1133 - val_loss: 0.6791\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 178us/step - loss: 0.1129 - val_loss: 0.6739\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 179us/step - loss: 0.1127 - val_loss: 0.6781\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 176us/step - loss: 0.1122 - val_loss: 0.6728\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 182us/step - loss: 0.1120 - val_loss: 0.6754\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "moptimizer = Adagrad(lr=0.01)\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l2(0.05)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1, kernel_initializer='uniform'))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history1_wd_sig__onelayer = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "moptimizer = Adagrad(lr=0.001)\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l2(0.05)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform'))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history1_wd_rel_onelayer  = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "moptimizer = Adagrad(lr=0.01)\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l2(0.05)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1, kernel_initializer='uniform',W_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history1_wd_sig_twolayers = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "moptimizer = Adagrad(lr=0.001)\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l2(0.05)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform',W_regularizer=regularizers.l2(0.01)))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history1_wd_rel_twolayers = model.fit(X_train_scaled,y_train,batch_size=50,epochs=250,validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1584 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2,figsize=(16,22))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(history1_wd_sig__onelayer.history['val_loss'])\n",
    "plt.plot(history1_wd_sig__onelayer.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDE --WD EN UNA CAPA (HIGH REGULARIZADOR)')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(history1_wd_rel_onelayer.history['val_loss'])\n",
    "plt.plot(history1_wd_rel_onelayer.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO RELU --WD EN UNA CAPA(HIGH REGULARIZADOR)')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(history1_wd_sig_twolayers.history['val_loss'])\n",
    "plt.plot(history1_wd_sig_twolayers.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDE --WD EN AMBAS  CAPA(HIGH REGULARIZADOR)')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(history1_wd_rel_twolayers.history['val_loss'])\n",
    "plt.plot(history1_wd_rel_twolayers.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO RELU --WD EN AMBAS CAPAS(HIGH REGULARIZADOR)')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=justify>La regularización tiene un efecto muy interesante, comparando con los modelos anteriores tanto en ReLu como en <b>SIGMOIDE</b> que es como los diferenciamos y es en la eliminación de los rizados en las salidas ademas que en el caso de <b>ReLU</b> que en todos los demas modelos tenia un error muy elevado en este caso con el WD en ambas capas y con un nivel alto se llegan a resultados parecidos utilizando la función de activación <b>SIGMOIDE</b>; mientras que la red que tiene esta función de activación tiene un resultado muy bueno, de lejos es el mejor obtenido actualmente por la velocidad en la que ambas funciones alcanzaro la convergencia, asi como tiene en magnitud el valor más bajo que se ha analizado hasta el momento.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=1275, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/100\n",
      "9745/9745 [==============================] - 3s 331us/step - loss: 15.7186 - val_loss: 3.3686\n",
      "Epoch 2/100\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 3.7052 - val_loss: 3.7717\n",
      "Epoch 3/100\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 3.4797 - val_loss: 3.0334\n",
      "Epoch 4/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 3.3328 - val_loss: 3.3597\n",
      "Epoch 5/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 3.2186 - val_loss: 2.9703\n",
      "Epoch 6/100\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 3.1084 - val_loss: 3.2027\n",
      "Epoch 7/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 3.0046 - val_loss: 3.0888\n",
      "Epoch 8/100\n",
      "9745/9745 [==============================] - 3s 278us/step - loss: 2.9226 - val_loss: 2.7248\n",
      "Epoch 9/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 2.8418 - val_loss: 2.6400\n",
      "Epoch 10/100\n",
      "9745/9745 [==============================] - 3s 296us/step - loss: 2.7824 - val_loss: 2.5188\n",
      "Epoch 11/100\n",
      "9745/9745 [==============================] - 3s 306us/step - loss: 2.7281 - val_loss: 2.5434\n",
      "Epoch 12/100\n",
      "9745/9745 [==============================] - 3s 274us/step - loss: 2.6710 - val_loss: 2.4819\n",
      "Epoch 13/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 2.6259 - val_loss: 2.5586\n",
      "Epoch 14/100\n",
      "9745/9745 [==============================] - 3s 281us/step - loss: 2.5642 - val_loss: 2.3493\n",
      "Epoch 15/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 2.5230 - val_loss: 2.3422\n",
      "Epoch 16/100\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 2.4818 - val_loss: 2.2479\n",
      "Epoch 17/100\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 2.4526 - val_loss: 2.2229\n",
      "Epoch 18/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 2.3894 - val_loss: 2.6022\n",
      "Epoch 19/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 2.3608 - val_loss: 2.2702\n",
      "Epoch 20/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 2.3098 - val_loss: 2.1682\n",
      "Epoch 21/100\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 2.3005 - val_loss: 2.1929\n",
      "Epoch 22/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 2.2610 - val_loss: 2.0969\n",
      "Epoch 23/100\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 2.2330 - val_loss: 2.1778\n",
      "Epoch 24/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 2.2032 - val_loss: 2.0971\n",
      "Epoch 25/100\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 2.1688 - val_loss: 1.9798\n",
      "Epoch 26/100\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 2.1313 - val_loss: 2.0916\n",
      "Epoch 27/100\n",
      "9745/9745 [==============================] - 3s 271us/step - loss: 2.1403 - val_loss: 1.9434\n",
      "Epoch 28/100\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 2.1022 - val_loss: 2.1199\n",
      "Epoch 29/100\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: 2.0758 - val_loss: 2.1128\n",
      "Epoch 30/100\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 2.0576 - val_loss: 1.8665\n",
      "Epoch 31/100\n",
      "9745/9745 [==============================] - 3s 275us/step - loss: 2.0250 - val_loss: 2.1301\n",
      "Epoch 32/100\n",
      "9745/9745 [==============================] - 3s 283us/step - loss: 1.9995 - val_loss: 1.8885\n",
      "Epoch 33/100\n",
      "9745/9745 [==============================] - 3s 286us/step - loss: 2.0016 - val_loss: 1.8980\n",
      "Epoch 34/100\n",
      "9745/9745 [==============================] - 3s 289us/step - loss: 1.9762 - val_loss: 1.7935\n",
      "Epoch 35/100\n",
      "9745/9745 [==============================] - 3s 280us/step - loss: 1.9369 - val_loss: 1.9375\n",
      "Epoch 36/100\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 1.9467 - val_loss: 1.7728\n",
      "Epoch 37/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 1.9381 - val_loss: 1.8097\n",
      "Epoch 38/100\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 1.9158 - val_loss: 1.7568\n",
      "Epoch 39/100\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 1.9163 - val_loss: 1.8953\n",
      "Epoch 40/100\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 1.8928 - val_loss: 1.9431\n",
      "Epoch 41/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 1.8682 - val_loss: 1.6937\n",
      "Epoch 42/100\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 1.8473 - val_loss: 1.7116\n",
      "Epoch 43/100\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 1.8225 - val_loss: 1.7423\n",
      "Epoch 44/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 1.8168 - val_loss: 1.7148\n",
      "Epoch 45/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 1.8194 - val_loss: 2.1756\n",
      "Epoch 46/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 1.7747 - val_loss: 1.6917\n",
      "Epoch 47/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 1.7747 - val_loss: 1.6156\n",
      "Epoch 48/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 1.7939 - val_loss: 1.6402\n",
      "Epoch 49/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 1.7481 - val_loss: 1.6047\n",
      "Epoch 50/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 1.7355 - val_loss: 1.6237\n",
      "Epoch 51/100\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 1.7398 - val_loss: 2.0511\n",
      "Epoch 52/100\n",
      "9745/9745 [==============================] - 3s 274us/step - loss: 1.7176 - val_loss: 1.7019\n",
      "Epoch 53/100\n",
      "9745/9745 [==============================] - 3s 277us/step - loss: 1.7117 - val_loss: 1.5852\n",
      "Epoch 54/100\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: 1.7051 - val_loss: 1.5772\n",
      "Epoch 55/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 1.6844 - val_loss: 1.5795\n",
      "Epoch 56/100\n",
      "9745/9745 [==============================] - 3s 277us/step - loss: 1.6887 - val_loss: 1.6376\n",
      "Epoch 57/100\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: 1.6664 - val_loss: 1.6023\n",
      "Epoch 58/100\n",
      "9745/9745 [==============================] - 3s 280us/step - loss: 1.6926 - val_loss: 1.5977\n",
      "Epoch 59/100\n",
      "9745/9745 [==============================] - 3s 279us/step - loss: 1.6565 - val_loss: 1.5845\n",
      "Epoch 60/100\n",
      "9745/9745 [==============================] - 3s 276us/step - loss: 1.6835 - val_loss: 1.6216\n",
      "Epoch 61/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 1.6342 - val_loss: 1.5060\n",
      "Epoch 62/100\n",
      "9745/9745 [==============================] - 3s 279us/step - loss: 1.6237 - val_loss: 1.5556\n",
      "Epoch 63/100\n",
      "9745/9745 [==============================] - 3s 284us/step - loss: 1.6280 - val_loss: 1.4823\n",
      "Epoch 64/100\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: 1.6014 - val_loss: 1.4775\n",
      "Epoch 65/100\n",
      "9745/9745 [==============================] - 3s 284us/step - loss: 1.6110 - val_loss: 1.6792\n",
      "Epoch 66/100\n",
      "9745/9745 [==============================] - 3s 275us/step - loss: 1.6075 - val_loss: 1.5519\n",
      "Epoch 67/100\n",
      "9745/9745 [==============================] - 3s 271us/step - loss: 1.5749 - val_loss: 1.4829\n",
      "Epoch 68/100\n",
      "9745/9745 [==============================] - 3s 282us/step - loss: 1.5683 - val_loss: 1.4275\n",
      "Epoch 69/100\n",
      "9745/9745 [==============================] - 3s 285us/step - loss: 1.5774 - val_loss: 1.4163\n",
      "Epoch 70/100\n",
      "9745/9745 [==============================] - 3s 284us/step - loss: 1.5506 - val_loss: 1.5141\n",
      "Epoch 71/100\n",
      "9745/9745 [==============================] - 3s 272us/step - loss: 1.5410 - val_loss: 1.6537\n",
      "Epoch 72/100\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 1.5362 - val_loss: 1.7402\n",
      "Epoch 73/100\n",
      "9745/9745 [==============================] - 3s 284us/step - loss: 1.5491 - val_loss: 1.3848\n",
      "Epoch 74/100\n",
      "9745/9745 [==============================] - 3s 286us/step - loss: 1.5236 - val_loss: 1.3883\n",
      "Epoch 75/100\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: 1.5157 - val_loss: 1.3976\n",
      "Epoch 76/100\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: 1.5110 - val_loss: 1.5050\n",
      "Epoch 77/100\n",
      "9745/9745 [==============================] - 3s 272us/step - loss: 1.4932 - val_loss: 1.3756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 1.4982 - val_loss: 1.3969\n",
      "Epoch 79/100\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 1.5019 - val_loss: 1.4084\n",
      "Epoch 80/100\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 1.4755 - val_loss: 1.4318\n",
      "Epoch 81/100\n",
      "9745/9745 [==============================] - 3s 276us/step - loss: 1.4908 - val_loss: 1.4114\n",
      "Epoch 82/100\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 1.4828 - val_loss: 1.4044\n",
      "Epoch 83/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 1.4883 - val_loss: 1.8607\n",
      "Epoch 84/100\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 1.4624 - val_loss: 1.3304\n",
      "Epoch 85/100\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 1.5001 - val_loss: 1.3349\n",
      "Epoch 86/100\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 1.4727 - val_loss: 1.3707\n",
      "Epoch 87/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 1.4444 - val_loss: 1.3961\n",
      "Epoch 88/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 1.4332 - val_loss: 1.3447\n",
      "Epoch 89/100\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 1.4496 - val_loss: 1.3630\n",
      "Epoch 90/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 1.4354 - val_loss: 1.3427\n",
      "Epoch 91/100\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 1.4197 - val_loss: 1.3343\n",
      "Epoch 92/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 1.4261 - val_loss: 1.2929\n",
      "Epoch 93/100\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 1.4207 - val_loss: 1.2854\n",
      "Epoch 94/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 1.4129 - val_loss: 1.3843\n",
      "Epoch 95/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 1.4237 - val_loss: 1.2810\n",
      "Epoch 96/100\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 1.3937 - val_loss: 1.3314\n",
      "Epoch 97/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 1.4011 - val_loss: 1.2643\n",
      "Epoch 98/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 1.4076 - val_loss: 1.2722\n",
      "Epoch 99/100\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 1.3797 - val_loss: 1.2835\n",
      "Epoch 100/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 1.3821 - val_loss: 1.2893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:13: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=1275, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/100\n",
      "9745/9745 [==============================] - 3s 312us/step - loss: 92.3194 - val_loss: 78.2685\n",
      "Epoch 2/100\n",
      "9745/9745 [==============================] - 3s 276us/step - loss: 69.3892 - val_loss: 67.3158\n",
      "Epoch 3/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 61.1734 - val_loss: 60.4017\n",
      "Epoch 4/100\n",
      "9745/9745 [==============================] - 3s 279us/step - loss: 55.5191 - val_loss: 55.6106\n",
      "Epoch 5/100\n",
      "9745/9745 [==============================] - 3s 278us/step - loss: 51.3461 - val_loss: 51.4298\n",
      "Epoch 6/100\n",
      "9745/9745 [==============================] - 3s 281us/step - loss: 47.9636 - val_loss: 48.3564\n",
      "Epoch 7/100\n",
      "9745/9745 [==============================] - 3s 276us/step - loss: 45.1881 - val_loss: 45.6663\n",
      "Epoch 8/100\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 42.8233 - val_loss: 43.4273\n",
      "Epoch 9/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 40.7905 - val_loss: 41.5025\n",
      "Epoch 10/100\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 38.9617 - val_loss: 39.7369\n",
      "Epoch 11/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 37.3335 - val_loss: 38.0361\n",
      "Epoch 12/100\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 35.8325 - val_loss: 36.6011\n",
      "Epoch 13/100\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 34.4710 - val_loss: 35.2331\n",
      "Epoch 14/100\n",
      "9745/9745 [==============================] - 3s 282us/step - loss: 33.2332 - val_loss: 34.0574\n",
      "Epoch 15/100\n",
      "9745/9745 [==============================] - 3s 277us/step - loss: 32.0780 - val_loss: 33.0059\n",
      "Epoch 16/100\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 31.0079 - val_loss: 31.8455\n",
      "Epoch 17/100\n",
      "9745/9745 [==============================] - 3s 276us/step - loss: 30.0243 - val_loss: 30.8436\n",
      "Epoch 18/100\n",
      "9745/9745 [==============================] - 3s 278us/step - loss: 29.0875 - val_loss: 29.9395\n",
      "Epoch 19/100\n",
      "9745/9745 [==============================] - 3s 290us/step - loss: 28.2197 - val_loss: 29.0156\n",
      "Epoch 20/100\n",
      "9745/9745 [==============================] - 3s 282us/step - loss: 27.3954 - val_loss: 28.1791\n",
      "Epoch 21/100\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: 26.6026 - val_loss: 27.4932\n",
      "Epoch 22/100\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 25.8858 - val_loss: 26.6617\n",
      "Epoch 23/100\n",
      "9745/9745 [==============================] - 3s 275us/step - loss: 25.1852 - val_loss: 25.9956\n",
      "Epoch 24/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 24.5263 - val_loss: 25.3109\n",
      "Epoch 25/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 23.8918 - val_loss: 24.6630\n",
      "Epoch 26/100\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 23.2974 - val_loss: 24.0489\n",
      "Epoch 27/100\n",
      "9745/9745 [==============================] - 3s 281us/step - loss: 22.7187 - val_loss: 23.5007\n",
      "Epoch 28/100\n",
      "9745/9745 [==============================] - 3s 275us/step - loss: 22.1620 - val_loss: 22.9400\n",
      "Epoch 29/100\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 21.6611 - val_loss: 22.3836\n",
      "Epoch 30/100\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 21.1447 - val_loss: 21.8758\n",
      "Epoch 31/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 20.6742 - val_loss: 21.3813\n",
      "Epoch 32/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 20.2086 - val_loss: 20.9191\n",
      "Epoch 33/100\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 19.7620 - val_loss: 20.4463\n",
      "Epoch 34/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 19.3260 - val_loss: 19.9814\n",
      "Epoch 35/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 18.9161 - val_loss: 19.5778\n",
      "Epoch 36/100\n",
      "9745/9745 [==============================] - 3s 271us/step - loss: 18.5250 - val_loss: 19.1562\n",
      "Epoch 37/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 18.1370 - val_loss: 18.7821\n",
      "Epoch 38/100\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 17.7665 - val_loss: 18.3954\n",
      "Epoch 39/100\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 17.4053 - val_loss: 18.0387\n",
      "Epoch 40/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 17.0590 - val_loss: 17.6761\n",
      "Epoch 41/100\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 16.7280 - val_loss: 17.3392\n",
      "Epoch 42/100\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 16.4007 - val_loss: 17.0038\n",
      "Epoch 43/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 16.0881 - val_loss: 16.7244\n",
      "Epoch 44/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 15.7883 - val_loss: 16.3554\n",
      "Epoch 45/100\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 15.4954 - val_loss: 16.0690\n",
      "Epoch 46/100\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 15.2011 - val_loss: 15.9054\n",
      "Epoch 47/100\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 14.9323 - val_loss: 15.5028\n",
      "Epoch 48/100\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 14.6637 - val_loss: 15.2071\n",
      "Epoch 49/100\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 14.3987 - val_loss: 14.9484\n",
      "Epoch 50/100\n",
      "9745/9745 [==============================] - 3s 274us/step - loss: 14.1467 - val_loss: 14.6865\n",
      "Epoch 51/100\n",
      "9745/9745 [==============================] - 3s 275us/step - loss: 13.8980 - val_loss: 14.4138\n",
      "Epoch 52/100\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 13.6604 - val_loss: 14.1746\n",
      "Epoch 53/100\n",
      "9745/9745 [==============================] - 2s 257us/step - loss: 13.4284 - val_loss: 13.9491\n",
      "Epoch 54/100\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 13.1934 - val_loss: 13.7172\n",
      "Epoch 55/100\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 12.9789 - val_loss: 13.4570\n",
      "Epoch 56/100\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 12.7618 - val_loss: 13.2537\n",
      "Epoch 57/100\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 12.5558 - val_loss: 13.0389\n",
      "Epoch 58/100\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 12.3415 - val_loss: 12.8262\n",
      "Epoch 59/100\n",
      "9745/9745 [==============================] - 3s 278us/step - loss: 12.1491 - val_loss: 12.6289\n",
      "Epoch 60/100\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 11.9526 - val_loss: 12.4156\n",
      "Epoch 61/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 11.7696 - val_loss: 12.2266\n",
      "Epoch 62/100\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 11.5769 - val_loss: 12.0337\n",
      "Epoch 63/100\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 11.4059 - val_loss: 11.8646\n",
      "Epoch 64/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 11.2302 - val_loss: 11.6711\n",
      "Epoch 65/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 11.0625 - val_loss: 11.4955\n",
      "Epoch 66/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 10.8929 - val_loss: 11.3117\n",
      "Epoch 67/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 10.7298 - val_loss: 11.1366\n",
      "Epoch 68/100\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 10.5723 - val_loss: 10.9871\n",
      "Epoch 69/100\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 10.4220 - val_loss: 10.8271\n",
      "Epoch 70/100\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 10.2649 - val_loss: 10.6767\n",
      "Epoch 71/100\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: 10.1151 - val_loss: 10.6458\n",
      "Epoch 72/100\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 9.9830 - val_loss: 10.3693\n",
      "Epoch 73/100\n",
      "9745/9745 [==============================] - 3s 275us/step - loss: 9.8398 - val_loss: 10.2443\n",
      "Epoch 74/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 9.7005 - val_loss: 10.1627\n",
      "Epoch 75/100\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 9.5715 - val_loss: 9.9493\n",
      "Epoch 76/100\n",
      "9745/9745 [==============================] - 3s 278us/step - loss: 9.4411 - val_loss: 9.8201\n",
      "Epoch 77/100\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 9.3144 - val_loss: 9.6883\n",
      "Epoch 78/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 9.1938 - val_loss: 9.5409\n",
      "Epoch 79/100\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 9.0664 - val_loss: 9.4341\n",
      "Epoch 80/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 8.9478 - val_loss: 9.3078\n",
      "Epoch 81/100\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 8.8318 - val_loss: 9.1805\n",
      "Epoch 82/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 8.7146 - val_loss: 9.0611\n",
      "Epoch 83/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 8.6067 - val_loss: 8.9579\n",
      "Epoch 84/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 8.4959 - val_loss: 8.8311\n",
      "Epoch 85/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 8.3877 - val_loss: 8.7138\n",
      "Epoch 86/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 8.2851 - val_loss: 8.6134\n",
      "Epoch 87/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 8.1831 - val_loss: 8.5413\n",
      "Epoch 88/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 8.0872 - val_loss: 8.3912\n",
      "Epoch 89/100\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 7.9844 - val_loss: 8.3082\n",
      "Epoch 90/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 7.8901 - val_loss: 8.2016\n",
      "Epoch 91/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 7.7961 - val_loss: 8.0994\n",
      "Epoch 92/100\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 7.7050 - val_loss: 8.0086\n",
      "Epoch 93/100\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 7.6117 - val_loss: 7.9075\n",
      "Epoch 94/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 7.5227 - val_loss: 7.8150\n",
      "Epoch 95/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 7.4380 - val_loss: 7.7210\n",
      "Epoch 96/100\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 7.3539 - val_loss: 7.6329\n",
      "Epoch 97/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 7.2697 - val_loss: 7.5625\n",
      "Epoch 98/100\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 7.1903 - val_loss: 7.5381\n",
      "Epoch 99/100\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 7.1132 - val_loss: 7.3868\n",
      "Epoch 100/100\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: 7.0330 - val_loss: 7.3026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:22: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=1275, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:24: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/100\n",
      "9745/9745 [==============================] - 3s 315us/step - loss: 16.3924 - val_loss: 3.7437\n",
      "Epoch 2/100\n",
      "9745/9745 [==============================] - 3s 282us/step - loss: 3.9118 - val_loss: 3.8600\n",
      "Epoch 3/100\n",
      "9745/9745 [==============================] - 3s 281us/step - loss: 3.6382 - val_loss: 3.4456\n",
      "Epoch 4/100\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 3.5287 - val_loss: 3.3447\n",
      "Epoch 5/100\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 3.4290 - val_loss: 3.0948\n",
      "Epoch 6/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 3.2840 - val_loss: 2.9586\n",
      "Epoch 7/100\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 3.1929 - val_loss: 2.9817\n",
      "Epoch 8/100\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 3.1324 - val_loss: 2.9246\n",
      "Epoch 9/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 3.0582 - val_loss: 2.8038\n",
      "Epoch 10/100\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 2.9930 - val_loss: 2.7527\n",
      "Epoch 11/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 2.9109 - val_loss: 2.7254\n",
      "Epoch 12/100\n",
      "9745/9745 [==============================] - 3s 272us/step - loss: 2.8547 - val_loss: 2.9480\n",
      "Epoch 13/100\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 2.8103 - val_loss: 2.6074\n",
      "Epoch 14/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 2.7805 - val_loss: 3.0778\n",
      "Epoch 15/100\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 2.7098 - val_loss: 2.5672\n",
      "Epoch 16/100\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 2.6642 - val_loss: 2.4862\n",
      "Epoch 17/100\n",
      "9745/9745 [==============================] - 3s 272us/step - loss: 2.6312 - val_loss: 2.5927\n",
      "Epoch 18/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 2.5988 - val_loss: 2.5028\n",
      "Epoch 19/100\n",
      "9745/9745 [==============================] - 3s 276us/step - loss: 2.5515 - val_loss: 2.3416\n",
      "Epoch 20/100\n",
      "9745/9745 [==============================] - 3s 289us/step - loss: 2.5083 - val_loss: 2.3101\n",
      "Epoch 21/100\n",
      "9745/9745 [==============================] - 3s 279us/step - loss: 2.5011 - val_loss: 2.3192\n",
      "Epoch 22/100\n",
      "9745/9745 [==============================] - 3s 283us/step - loss: 2.4455 - val_loss: 2.3065\n",
      "Epoch 23/100\n",
      "9745/9745 [==============================] - 3s 279us/step - loss: 2.4192 - val_loss: 2.2466\n",
      "Epoch 24/100\n",
      "9745/9745 [==============================] - 3s 271us/step - loss: 2.3998 - val_loss: 2.2178\n",
      "Epoch 25/100\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 2.3835 - val_loss: 2.2291\n",
      "Epoch 26/100\n",
      "9745/9745 [==============================] - 3s 286us/step - loss: 2.3463 - val_loss: 2.2045\n",
      "Epoch 27/100\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: 2.3241 - val_loss: 2.1672\n",
      "Epoch 28/100\n",
      "9745/9745 [==============================] - 3s 277us/step - loss: 2.2974 - val_loss: 2.1614\n",
      "Epoch 29/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 2.2781 - val_loss: 2.1078\n",
      "Epoch 30/100\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: 2.2621 - val_loss: 2.1059\n",
      "Epoch 31/100\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: 2.2344 - val_loss: 2.1039\n",
      "Epoch 32/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 2.2184 - val_loss: 2.1006\n",
      "Epoch 33/100\n",
      "9745/9745 [==============================] - 3s 271us/step - loss: 2.2026 - val_loss: 2.1469\n",
      "Epoch 34/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 2.1994 - val_loss: 2.0221\n",
      "Epoch 35/100\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: 2.1780 - val_loss: 2.0151\n",
      "Epoch 36/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 2.1534 - val_loss: 2.0841\n",
      "Epoch 37/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 2.1425 - val_loss: 2.0711\n",
      "Epoch 38/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 2.1192 - val_loss: 2.0127\n",
      "Epoch 39/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 2.1046 - val_loss: 2.0238\n",
      "Epoch 40/100\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 2.0860 - val_loss: 1.9983\n",
      "Epoch 41/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 2.0722 - val_loss: 2.0648\n",
      "Epoch 42/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 2.0602 - val_loss: 1.9386\n",
      "Epoch 43/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 2.0585 - val_loss: 2.7178\n",
      "Epoch 44/100\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 2.0380 - val_loss: 1.9224\n",
      "Epoch 45/100\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 2.0333 - val_loss: 1.9079\n",
      "Epoch 46/100\n",
      "9745/9745 [==============================] - 3s 271us/step - loss: 2.0050 - val_loss: 2.1326\n",
      "Epoch 47/100\n",
      "9745/9745 [==============================] - 3s 279us/step - loss: 2.0045 - val_loss: 1.9159\n",
      "Epoch 48/100\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: 1.9971 - val_loss: 1.8593\n",
      "Epoch 49/100\n",
      "9745/9745 [==============================] - 3s 280us/step - loss: 1.9875 - val_loss: 1.8783\n",
      "Epoch 50/100\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 1.9604 - val_loss: 2.0079\n",
      "Epoch 51/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 1.9659 - val_loss: 1.8314\n",
      "Epoch 52/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 1.9464 - val_loss: 1.8258\n",
      "Epoch 53/100\n",
      "9745/9745 [==============================] - 3s 276us/step - loss: 1.9412 - val_loss: 1.8746\n",
      "Epoch 54/100\n",
      "9745/9745 [==============================] - 3s 274us/step - loss: 1.9249 - val_loss: 1.8416\n",
      "Epoch 55/100\n",
      "9745/9745 [==============================] - 3s 271us/step - loss: 1.9316 - val_loss: 1.8172\n",
      "Epoch 56/100\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 1.9161 - val_loss: 1.8085\n",
      "Epoch 57/100\n",
      "9745/9745 [==============================] - 3s 280us/step - loss: 1.9129 - val_loss: 1.8008\n",
      "Epoch 58/100\n",
      "9745/9745 [==============================] - 3s 282us/step - loss: 1.8948 - val_loss: 1.7897\n",
      "Epoch 59/100\n",
      "9745/9745 [==============================] - 3s 291us/step - loss: 1.8813 - val_loss: 1.7693\n",
      "Epoch 60/100\n",
      "9745/9745 [==============================] - 3s 289us/step - loss: 1.8709 - val_loss: 1.8601\n",
      "Epoch 61/100\n",
      "9745/9745 [==============================] - 3s 271us/step - loss: 1.8643 - val_loss: 1.7606\n",
      "Epoch 62/100\n",
      "9745/9745 [==============================] - 3s 291us/step - loss: 1.8627 - val_loss: 1.8038\n",
      "Epoch 63/100\n",
      "9745/9745 [==============================] - 3s 276us/step - loss: 1.8530 - val_loss: 1.7295\n",
      "Epoch 64/100\n",
      "9745/9745 [==============================] - 3s 275us/step - loss: 1.8391 - val_loss: 1.7322\n",
      "Epoch 65/100\n",
      "9745/9745 [==============================] - 3s 285us/step - loss: 1.8392 - val_loss: 1.7298\n",
      "Epoch 66/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 1.8201 - val_loss: 1.7706\n",
      "Epoch 67/100\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 1.8129 - val_loss: 1.7121\n",
      "Epoch 68/100\n",
      "9745/9745 [==============================] - 3s 282us/step - loss: 1.8170 - val_loss: 1.9103\n",
      "Epoch 69/100\n",
      "9745/9745 [==============================] - 3s 275us/step - loss: 1.8096 - val_loss: 1.7451\n",
      "Epoch 70/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 1.7962 - val_loss: 1.6967\n",
      "Epoch 71/100\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 1.7851 - val_loss: 2.3064\n",
      "Epoch 72/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 1.7971 - val_loss: 1.6876\n",
      "Epoch 73/100\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 1.7733 - val_loss: 1.6731\n",
      "Epoch 74/100\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 1.7754 - val_loss: 1.6823\n",
      "Epoch 75/100\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 1.7626 - val_loss: 1.6590\n",
      "Epoch 76/100\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 1.7631 - val_loss: 1.6714\n",
      "Epoch 77/100\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 1.7526 - val_loss: 1.6958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/100\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 1.7438 - val_loss: 1.6463\n",
      "Epoch 79/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 1.7434 - val_loss: 1.7479\n",
      "Epoch 80/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 1.7397 - val_loss: 1.6290\n",
      "Epoch 81/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 1.7263 - val_loss: 1.6239\n",
      "Epoch 82/100\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 1.7165 - val_loss: 1.6276\n",
      "Epoch 83/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 1.7305 - val_loss: 1.6443\n",
      "Epoch 84/100\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 1.7083 - val_loss: 1.6104\n",
      "Epoch 85/100\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 1.7055 - val_loss: 1.6183\n",
      "Epoch 86/100\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 1.6992 - val_loss: 1.6822\n",
      "Epoch 87/100\n",
      "9745/9745 [==============================] - 2s 257us/step - loss: 1.6977 - val_loss: 1.6094\n",
      "Epoch 88/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 1.6948 - val_loss: 1.5987\n",
      "Epoch 89/100\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 1.6772 - val_loss: 1.5862\n",
      "Epoch 90/100\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 1.6767 - val_loss: 1.6122\n",
      "Epoch 91/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 1.6739 - val_loss: 1.5882\n",
      "Epoch 92/100\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 1.6642 - val_loss: 1.5847\n",
      "Epoch 93/100\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 1.6536 - val_loss: 1.5733\n",
      "Epoch 94/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 1.6585 - val_loss: 1.5771\n",
      "Epoch 95/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 1.6522 - val_loss: 1.5664\n",
      "Epoch 96/100\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 1.6441 - val_loss: 1.5578\n",
      "Epoch 97/100\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: 1.6375 - val_loss: 1.5803\n",
      "Epoch 98/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 1.6369 - val_loss: 1.5678\n",
      "Epoch 99/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 1.6367 - val_loss: 1.5509\n",
      "Epoch 100/100\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 1.6378 - val_loss: 1.5376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:31: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=1275, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:33: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/100\n",
      "9745/9745 [==============================] - 3s 297us/step - loss: 97.3437 - val_loss: 81.6344\n",
      "Epoch 2/100\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 72.5553 - val_loss: 69.9574\n",
      "Epoch 3/100\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 63.9645 - val_loss: 62.9624\n",
      "Epoch 4/100\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 58.0349 - val_loss: 57.5738\n",
      "Epoch 5/100\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 53.6492 - val_loss: 53.3339\n",
      "Epoch 6/100\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 50.0635 - val_loss: 50.0735\n",
      "Epoch 7/100\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 47.1019 - val_loss: 47.2733\n",
      "Epoch 8/100\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 44.5414 - val_loss: 44.8446\n",
      "Epoch 9/100\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 42.2886 - val_loss: 42.5803\n",
      "Epoch 10/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 40.2782 - val_loss: 40.7214\n",
      "Epoch 11/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 38.4666 - val_loss: 38.9007\n",
      "Epoch 12/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 36.8344 - val_loss: 37.2929\n",
      "Epoch 13/100\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 35.3389 - val_loss: 35.8394\n",
      "Epoch 14/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 33.9534 - val_loss: 34.6097\n",
      "Epoch 15/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 32.6792 - val_loss: 33.2698\n",
      "Epoch 16/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 31.5176 - val_loss: 32.0902\n",
      "Epoch 17/100\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 30.4085 - val_loss: 31.0229\n",
      "Epoch 18/100\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 29.3824 - val_loss: 29.9939\n",
      "Epoch 19/100\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 28.4162 - val_loss: 29.0112\n",
      "Epoch 20/100\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 27.5085 - val_loss: 28.1217\n",
      "Epoch 21/100\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 26.6635 - val_loss: 27.2833\n",
      "Epoch 22/100\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 25.8706 - val_loss: 26.4994\n",
      "Epoch 23/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 25.1146 - val_loss: 25.7324\n",
      "Epoch 24/100\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 24.3987 - val_loss: 25.0295\n",
      "Epoch 25/100\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 23.7181 - val_loss: 24.3477\n",
      "Epoch 26/100\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 23.0804 - val_loss: 23.6762\n",
      "Epoch 27/100\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 22.4711 - val_loss: 23.0636\n",
      "Epoch 28/100\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 21.8921 - val_loss: 22.5905\n",
      "Epoch 29/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 21.3407 - val_loss: 21.9456\n",
      "Epoch 30/100\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 20.8047 - val_loss: 21.4017\n",
      "Epoch 31/100\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 20.2932 - val_loss: 20.8972\n",
      "Epoch 32/100\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 19.8073 - val_loss: 20.4050\n",
      "Epoch 33/100\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 19.3536 - val_loss: 19.9292\n",
      "Epoch 34/100\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 18.8984 - val_loss: 19.4851\n",
      "Epoch 35/100\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 18.4754 - val_loss: 19.0394\n",
      "Epoch 36/100\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 18.0603 - val_loss: 18.6565\n",
      "Epoch 37/100\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 17.6731 - val_loss: 18.2311\n",
      "Epoch 38/100\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 17.2902 - val_loss: 17.8504\n",
      "Epoch 39/100\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 16.9290 - val_loss: 17.5091\n",
      "Epoch 40/100\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 16.5764 - val_loss: 17.1156\n",
      "Epoch 41/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 16.2385 - val_loss: 16.7827\n",
      "Epoch 42/100\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 15.9097 - val_loss: 16.4348\n",
      "Epoch 43/100\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 15.5891 - val_loss: 16.1140\n",
      "Epoch 44/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 15.2849 - val_loss: 15.7916\n",
      "Epoch 45/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 14.9792 - val_loss: 15.5572\n",
      "Epoch 46/100\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 14.7104 - val_loss: 15.2023\n",
      "Epoch 47/100\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 14.4291 - val_loss: 14.9252\n",
      "Epoch 48/100\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 14.1505 - val_loss: 14.8161\n",
      "Epoch 49/100\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 13.9073 - val_loss: 14.4001\n",
      "Epoch 50/100\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 13.6509 - val_loss: 14.1917\n",
      "Epoch 51/100\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 13.4065 - val_loss: 13.9097\n",
      "Epoch 52/100\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 13.1708 - val_loss: 13.6407\n",
      "Epoch 53/100\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 12.9399 - val_loss: 13.4078\n",
      "Epoch 54/100\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 12.7272 - val_loss: 13.1777\n",
      "Epoch 55/100\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 12.5076 - val_loss: 12.9554\n",
      "Epoch 56/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 12.3029 - val_loss: 12.7548\n",
      "Epoch 57/100\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 12.0950 - val_loss: 12.5471\n",
      "Epoch 58/100\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 11.8965 - val_loss: 12.3866\n",
      "Epoch 59/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 11.7071 - val_loss: 12.2376\n",
      "Epoch 60/100\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 11.5239 - val_loss: 11.9452\n",
      "Epoch 61/100\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 11.3372 - val_loss: 11.7627\n",
      "Epoch 62/100\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 11.1632 - val_loss: 11.5788\n",
      "Epoch 63/100\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 10.9857 - val_loss: 11.4045\n",
      "Epoch 64/100\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 10.8200 - val_loss: 11.2195\n",
      "Epoch 65/100\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 10.6531 - val_loss: 11.0542\n",
      "Epoch 66/100\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 10.5050 - val_loss: 10.9175\n",
      "Epoch 67/100\n",
      "9745/9745 [==============================] - 3s 324us/step - loss: 10.3472 - val_loss: 10.7301\n",
      "Epoch 68/100\n",
      "9745/9745 [==============================] - 3s 319us/step - loss: 10.1985 - val_loss: 10.5956\n",
      "Epoch 69/100\n",
      "9745/9745 [==============================] - 3s 318us/step - loss: 10.0475 - val_loss: 10.4218\n",
      "Epoch 70/100\n",
      "9745/9745 [==============================] - 3s 320us/step - loss: 9.9001 - val_loss: 10.2824\n",
      "Epoch 71/100\n",
      "9745/9745 [==============================] - 3s 281us/step - loss: 9.7690 - val_loss: 10.1368\n",
      "Epoch 72/100\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 9.6283 - val_loss: 10.0223\n",
      "Epoch 73/100\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 9.5014 - val_loss: 9.8957\n",
      "Epoch 74/100\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 9.3711 - val_loss: 9.7245\n",
      "Epoch 75/100\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 9.2360 - val_loss: 9.6226\n",
      "Epoch 76/100\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 9.1253 - val_loss: 9.4811\n",
      "Epoch 77/100\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 9.0026 - val_loss: 9.3401\n",
      "Epoch 78/100\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 8.8836 - val_loss: 9.2429\n",
      "Epoch 79/100\n",
      "9745/9745 [==============================] - 2s 227us/step - loss: 8.7656 - val_loss: 9.1069\n",
      "Epoch 80/100\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 8.6590 - val_loss: 8.9898\n",
      "Epoch 81/100\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 8.5494 - val_loss: 8.8753\n",
      "Epoch 82/100\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 8.4420 - val_loss: 8.7512\n",
      "Epoch 83/100\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 8.3358 - val_loss: 8.6538\n",
      "Epoch 84/100\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 8.2342 - val_loss: 8.5444\n",
      "Epoch 85/100\n",
      "9745/9745 [==============================] - 2s 228us/step - loss: 8.1301 - val_loss: 8.4452\n",
      "Epoch 86/100\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 8.0366 - val_loss: 8.3779\n",
      "Epoch 87/100\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 7.9453 - val_loss: 8.2364\n",
      "Epoch 88/100\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 7.8476 - val_loss: 8.1668\n",
      "Epoch 89/100\n",
      "9745/9745 [==============================] - 2s 235us/step - loss: 7.7569 - val_loss: 8.1584\n",
      "Epoch 90/100\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 7.6731 - val_loss: 7.9551\n",
      "Epoch 91/100\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 7.5821 - val_loss: 7.8640\n",
      "Epoch 92/100\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 7.4948 - val_loss: 7.7820\n",
      "Epoch 93/100\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 7.4125 - val_loss: 7.6932\n",
      "Epoch 94/100\n",
      "9745/9745 [==============================] - 2s 237us/step - loss: 7.3306 - val_loss: 7.6131\n",
      "Epoch 95/100\n",
      "9745/9745 [==============================] - 2s 226us/step - loss: 7.2526 - val_loss: 7.5227\n",
      "Epoch 96/100\n",
      "9745/9745 [==============================] - 2s 240us/step - loss: 7.1740 - val_loss: 7.4401\n",
      "Epoch 97/100\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 7.1024 - val_loss: 7.3806\n",
      "Epoch 98/100\n",
      "9745/9745 [==============================] - 2s 229us/step - loss: 7.0248 - val_loss: 7.3388\n",
      "Epoch 99/100\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 6.9520 - val_loss: 7.2063\n",
      "Epoch 100/100\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 6.8745 - val_loss: 7.1327\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "moptimizer = Adagrad(lr=0.01)\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1, kernel_initializer='uniform'))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_wd_sig__onelayer = model.fit(X_train_scaled,y_train,batch_size=50,epochs=100,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "moptimizer = Adagrad(lr=0.001)\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform'))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_wd_rel_onelayer  = model.fit(X_train_scaled,y_train,batch_size=50,epochs=100,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "moptimizer = Adagrad(lr=0.01)\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Dense(1, kernel_initializer='uniform',W_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_wd_sig_twolayers = model.fit(X_train_scaled,y_train,batch_size=50,epochs=100,validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "moptimizer = Adagrad(lr=0.001)\n",
    "idim=X_train_scaled.shape[1]\n",
    "model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform',W_regularizer=regularizers.l1(0.01)))\n",
    "model.add(Activation('linear'))\n",
    "model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "history_wd_rel_twolayers = model.fit(X_train_scaled,y_train,batch_size=50,epochs=100,validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x1584 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2,figsize=(16,22))\n",
    "plt.subplot(4, 2, 1)\n",
    "plt.plot(history_wd_sig__onelayer.history['val_loss'])\n",
    "plt.plot(history_wd_sig__onelayer.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDE --WD CON L1')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 2)\n",
    "plt.plot(history_wd_rel_onelayer.history['val_loss'])\n",
    "plt.plot(history_wd_rel_onelayer.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO RELU --WD CON L1')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 3)\n",
    "plt.plot(history_wd_sig_twolayers.history['val_loss'])\n",
    "plt.plot(history_wd_sig_twolayers.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDE --WD CON L1')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(4, 2, 4)\n",
    "plt.plot(history_wd_rel_twolayers.history['val_loss'])\n",
    "plt.plot(history_wd_rel_twolayers.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO RELU --WD CON L1')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify><b>i) Entrene los modelos obtenidos en b) y c) utilizando *Dropout*. Compare los desempeños de prueba obtenidos antes y después de regularizar. Experimente con distintos valores del parámetro de regularización y comente.</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 4s 361us/step - loss: 1.7155 - val_loss: 0.5985\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 3s 285us/step - loss: 0.8339 - val_loss: 0.5620\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 3s 282us/step - loss: 0.7556 - val_loss: 0.4303\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 0.7130 - val_loss: 0.4222\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 3s 275us/step - loss: 0.6696 - val_loss: 0.6594\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 0.6320 - val_loss: 0.4761\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 0.6059 - val_loss: 0.3568\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 0.5756 - val_loss: 0.3466\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 0.5633 - val_loss: 0.3292\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 3s 311us/step - loss: 0.5613 - val_loss: 0.3828\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 3s 283us/step - loss: 0.5342 - val_loss: 0.4678\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.5361 - val_loss: 0.3124\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 0.4949 - val_loss: 0.3114\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 3s 292us/step - loss: 0.5003 - val_loss: 0.3034\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 3s 312us/step - loss: 0.4933 - val_loss: 0.4292\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 0.4735 - val_loss: 0.2559\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 0.4725 - val_loss: 0.3352\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 0.4685 - val_loss: 0.2886\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 3s 306us/step - loss: 0.4639 - val_loss: 0.2564\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 4s 400us/step - loss: 0.4579 - val_loss: 0.2437\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 3s 351us/step - loss: 0.4509 - val_loss: 0.2570\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 3s 320us/step - loss: 0.4475 - val_loss: 0.2372\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 3s 325us/step - loss: 0.4383 - val_loss: 0.2907\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.4310 - val_loss: 0.5098\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.4301 - val_loss: 0.3018\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4096 - val_loss: 0.2652\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4235 - val_loss: 0.2339\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.4120 - val_loss: 0.2218\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 0.4128 - val_loss: 0.2573\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 0.3946 - val_loss: 0.2825\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.4084 - val_loss: 0.2307\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4005 - val_loss: 0.3350\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.3942 - val_loss: 0.2270\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.3937 - val_loss: 0.2169\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 3s 276us/step - loss: 0.3837 - val_loss: 0.2083\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.3889 - val_loss: 0.2054\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.3773 - val_loss: 0.2504\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 3s 277us/step - loss: 0.3694 - val_loss: 0.3458\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 0.3782 - val_loss: 0.1987\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 0.3656 - val_loss: 0.3349\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3730 - val_loss: 0.1969\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.3702 - val_loss: 0.1892\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 0.3644 - val_loss: 0.1938\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.3742 - val_loss: 0.2764\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3665 - val_loss: 0.2734\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.3614 - val_loss: 0.2080\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.3600 - val_loss: 0.2346\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.3560 - val_loss: 0.1852\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.3532 - val_loss: 0.2042\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.3613 - val_loss: 0.2218\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.3571 - val_loss: 0.1803\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3465 - val_loss: 0.2010\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 0.3472 - val_loss: 0.3908\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.3369 - val_loss: 0.1848\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 0.3405 - val_loss: 0.2010\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.3366 - val_loss: 0.2376\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.3369 - val_loss: 0.2251\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.3333 - val_loss: 0.1743\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 0.3330 - val_loss: 0.1826\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.3476 - val_loss: 0.2852\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.3285 - val_loss: 0.2083\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.3323 - val_loss: 0.1865\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.3265 - val_loss: 0.2374\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 0.3355 - val_loss: 0.1794\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.3316 - val_loss: 0.1939\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.3271 - val_loss: 0.1928\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 0.3216 - val_loss: 0.1859\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 0.3195 - val_loss: 0.1760\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3229 - val_loss: 0.1841\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3212 - val_loss: 0.1803\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.3223 - val_loss: 0.2058\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 0.3194 - val_loss: 0.1811\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.3176 - val_loss: 0.1873\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 239us/step - loss: 0.3171 - val_loss: 0.1783\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.3167 - val_loss: 0.1803\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.3216 - val_loss: 0.1742\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.3085 - val_loss: 0.1937\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.3173 - val_loss: 0.1619\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.3171 - val_loss: 0.1752\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 240us/step - loss: 0.3089 - val_loss: 0.1741\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.3027 - val_loss: 0.1825\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.3143 - val_loss: 0.3495\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3126 - val_loss: 0.1909\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.3157 - val_loss: 0.1641\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.3114 - val_loss: 0.1612\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 232us/step - loss: 0.3109 - val_loss: 0.1635\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.3038 - val_loss: 0.1914\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.3017 - val_loss: 0.1651\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.3005 - val_loss: 0.1601\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.3023 - val_loss: 0.2189\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.3056 - val_loss: 0.1601\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.3032 - val_loss: 0.1733\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.3005 - val_loss: 0.1648\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3042 - val_loss: 0.1582\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 3s 279us/step - loss: 0.3028 - val_loss: 0.1709\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.2975 - val_loss: 0.1853\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 0.2930 - val_loss: 0.1772\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 240us/step - loss: 0.2922 - val_loss: 0.1809\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.2929 - val_loss: 0.2187\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2978 - val_loss: 0.1562\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.3003 - val_loss: 0.1580\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 3s 280us/step - loss: 0.2996 - val_loss: 0.1987\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 3s 286us/step - loss: 0.2972 - val_loss: 0.1705\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 3s 274us/step - loss: 0.2980 - val_loss: 0.1550\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: 0.2932 - val_loss: 0.1720\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.2906 - val_loss: 0.1581\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2913 - val_loss: 0.1588\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.2919 - val_loss: 0.1590\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 0.2860 - val_loss: 0.1566\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2858 - val_loss: 0.1828\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2905 - val_loss: 0.1547\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.2824 - val_loss: 0.2091\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2934 - val_loss: 0.1515\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 0.2905 - val_loss: 0.1589\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.2871 - val_loss: 0.1724\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 3s 261us/step - loss: 0.2842 - val_loss: 0.1792\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2851 - val_loss: 0.1732\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.2870 - val_loss: 0.1778\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.2911 - val_loss: 0.1954\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2858 - val_loss: 0.2349\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2927 - val_loss: 0.3988\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.2809 - val_loss: 0.1543\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.2858 - val_loss: 0.1716\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 0.2799 - val_loss: 0.1998\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2787 - val_loss: 0.2347\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2836 - val_loss: 0.1583\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2808 - val_loss: 0.1497\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.2796 - val_loss: 0.1673\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2783 - val_loss: 0.1868\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.2859 - val_loss: 0.1542\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2771 - val_loss: 0.1849\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.2808 - val_loss: 0.1547\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2792 - val_loss: 0.1742\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 3s 272us/step - loss: 0.2784 - val_loss: 0.1917\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: 0.2717 - val_loss: 0.1677\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 3s 279us/step - loss: 0.2742 - val_loss: 0.1768\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.2817 - val_loss: 0.1471\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 3s 281us/step - loss: 0.2773 - val_loss: 0.1699\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: 0.2820 - val_loss: 0.1692\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: 0.2746 - val_loss: 0.1563\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 3s 284us/step - loss: 0.2702 - val_loss: 0.1442\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.2645 - val_loss: 0.1451\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 3s 277us/step - loss: 0.2741 - val_loss: 0.1886\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: 0.2788 - val_loss: 0.1443\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 0.2731 - val_loss: 0.1623\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 0.2726 - val_loss: 0.1499\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 3s 286us/step - loss: 0.2751 - val_loss: 0.2153\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 3s 288us/step - loss: 0.2742 - val_loss: 0.1560\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 3s 292us/step - loss: 0.2701 - val_loss: 0.1467\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.2756 - val_loss: 0.2087\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 3s 286us/step - loss: 0.2754 - val_loss: 0.1627\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 3s 281us/step - loss: 0.2707 - val_loss: 0.1543\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.2731 - val_loss: 0.1450\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 3s 293us/step - loss: 0.2761 - val_loss: 0.1504\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 3s 276us/step - loss: 0.2695 - val_loss: 0.1491\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 3s 291us/step - loss: 0.2693 - val_loss: 0.1743\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.2698 - val_loss: 0.2004\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2653 - val_loss: 0.1455\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2693 - val_loss: 0.1790\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.2769 - val_loss: 0.1424\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.2714 - val_loss: 0.1547\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.2641 - val_loss: 0.2640\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.2683 - val_loss: 0.1672\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.2604 - val_loss: 0.1480\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 0.2678 - val_loss: 0.1532\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.2660 - val_loss: 0.1527\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2699 - val_loss: 0.1535\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2646 - val_loss: 0.2420\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2665 - val_loss: 0.1453\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2607 - val_loss: 0.1523\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2684 - val_loss: 0.1659\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.2608 - val_loss: 0.1720\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.2687 - val_loss: 0.1588\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.2608 - val_loss: 0.2300\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.2613 - val_loss: 0.1521\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2640 - val_loss: 0.1784\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2628 - val_loss: 0.1478\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2564 - val_loss: 0.1594\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.2632 - val_loss: 0.1416\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.2629 - val_loss: 0.1555\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.2526 - val_loss: 0.1421\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.2602 - val_loss: 0.2023\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.2563 - val_loss: 0.1726\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.2585 - val_loss: 0.1395\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2602 - val_loss: 0.1689\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.2572 - val_loss: 0.2194\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.2593 - val_loss: 0.1449\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2609 - val_loss: 0.1501\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 3s 271us/step - loss: 0.2617 - val_loss: 0.1540\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.2592 - val_loss: 0.2505\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2610 - val_loss: 0.1745\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 233us/step - loss: 0.2517 - val_loss: 0.1524\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.2609 - val_loss: 0.1433\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.2589 - val_loss: 0.1654\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.2576 - val_loss: 0.1589\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.2602 - val_loss: 0.1484\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.2584 - val_loss: 0.2381\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2588 - val_loss: 0.1384\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.2672 - val_loss: 0.2278\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.2550 - val_loss: 0.1502\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.2587 - val_loss: 0.1426\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 234us/step - loss: 0.2534 - val_loss: 0.1405\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 238us/step - loss: 0.2572 - val_loss: 0.1405\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 231us/step - loss: 0.2546 - val_loss: 0.1910\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 236us/step - loss: 0.2609 - val_loss: 0.1462\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.2557 - val_loss: 0.1552\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.2451 - val_loss: 0.1515\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 3s 291us/step - loss: 0.2542 - val_loss: 0.2000\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 3s 286us/step - loss: 0.2532 - val_loss: 0.1530\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.2504 - val_loss: 0.1487\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 3s 285us/step - loss: 0.2567 - val_loss: 0.1615\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.2552 - val_loss: 0.1725\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 0.2505 - val_loss: 0.2074\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 3s 273us/step - loss: 0.2539 - val_loss: 0.1826\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 0.2507 - val_loss: 0.1700\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 0.2533 - val_loss: 0.1938\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 0.2539 - val_loss: 0.1401\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 3s 286us/step - loss: 0.2564 - val_loss: 0.3680\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 0.2547 - val_loss: 0.1774\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 3s 275us/step - loss: 0.2481 - val_loss: 0.1734\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.2495 - val_loss: 0.1634\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 0.2547 - val_loss: 0.1518\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.2473 - val_loss: 0.1381\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 0.2471 - val_loss: 0.1547\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.2557 - val_loss: 0.1371\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.2500 - val_loss: 0.1586\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.2459 - val_loss: 0.1474\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2487 - val_loss: 0.1390\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2514 - val_loss: 0.1469\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.2580 - val_loss: 0.1926\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 0.2482 - val_loss: 0.1466\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2575 - val_loss: 0.2017\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2601 - val_loss: 0.1475\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2471 - val_loss: 0.1408\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2488 - val_loss: 0.1612\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2515 - val_loss: 0.1424\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.2469 - val_loss: 0.1513\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.2451 - val_loss: 0.1498\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.2512 - val_loss: 0.1825\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2477 - val_loss: 0.1767\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.2492 - val_loss: 0.1538\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2495 - val_loss: 0.1878\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2463 - val_loss: 0.1364\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2481 - val_loss: 0.1602\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.2474 - val_loss: 0.1412\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2450 - val_loss: 0.1501\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2455 - val_loss: 0.1453\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2423 - val_loss: 0.2056\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2464 - val_loss: 0.1541\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2491 - val_loss: 0.1537\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 3s 335us/step - loss: 2.0705 - val_loss: 0.8731\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 1.1438 - val_loss: 0.6207\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 1.0173 - val_loss: 0.6302\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.9703 - val_loss: 0.4593\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 0.8925 - val_loss: 0.5115\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.8562 - val_loss: 0.7274\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.8618 - val_loss: 0.6514\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.8226 - val_loss: 0.4119\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.8246 - val_loss: 0.3592\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.7953 - val_loss: 0.4075\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.7781 - val_loss: 0.3376\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.7601 - val_loss: 0.3279\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.7270 - val_loss: 0.4535\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.7229 - val_loss: 0.3415\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.7143 - val_loss: 0.3934\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.6933 - val_loss: 0.3248\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.6962 - val_loss: 0.3037\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.6981 - val_loss: 0.3819\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.6745 - val_loss: 0.3022\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.6683 - val_loss: 0.3704\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.6782 - val_loss: 0.3122\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.6648 - val_loss: 0.3451\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.6485 - val_loss: 0.3048\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.6473 - val_loss: 0.2964\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: 0.6282 - val_loss: 0.3539\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 257us/step - loss: 0.6394 - val_loss: 0.2973\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 0.6119 - val_loss: 0.3506\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.6099 - val_loss: 0.2703\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.6245 - val_loss: 0.2848\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.6098 - val_loss: 0.2920\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.6069 - val_loss: 0.3020\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.6050 - val_loss: 0.3195\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.6000 - val_loss: 0.2813\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 0.5792 - val_loss: 0.4884\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.5843 - val_loss: 0.4295\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.5747 - val_loss: 0.2843\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.5680 - val_loss: 0.3914\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.5636 - val_loss: 0.2693\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.5812 - val_loss: 0.3524\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.5624 - val_loss: 0.2853\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.5737 - val_loss: 0.2571\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5618 - val_loss: 0.4437\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.5552 - val_loss: 0.2496\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.5510 - val_loss: 0.5208\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.5504 - val_loss: 0.2505\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.5536 - val_loss: 0.2701\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5336 - val_loss: 0.3179\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.5444 - val_loss: 0.3650\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5406 - val_loss: 0.3156\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.5260 - val_loss: 0.4416\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.5288 - val_loss: 0.2600\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.5390 - val_loss: 0.2529\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.5202 - val_loss: 0.2581\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.5229 - val_loss: 0.3776\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.5385 - val_loss: 0.2857\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.5246 - val_loss: 0.4450\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.5354 - val_loss: 0.2519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 0.5239 - val_loss: 0.2884\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.5116 - val_loss: 0.2419\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.5080 - val_loss: 0.2473\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5143 - val_loss: 0.2590\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.5083 - val_loss: 0.2754\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.5130 - val_loss: 0.2452\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.5239 - val_loss: 0.2582\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5085 - val_loss: 0.2356\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 0.5042 - val_loss: 0.2568\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.5128 - val_loss: 0.2344\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.5095 - val_loss: 0.2390\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.5126 - val_loss: 0.2382\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.5005 - val_loss: 0.2324\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4996 - val_loss: 0.3858\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4935 - val_loss: 0.2343\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5032 - val_loss: 0.2556\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4993 - val_loss: 0.2298\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4978 - val_loss: 0.2583\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4939 - val_loss: 0.2775\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4958 - val_loss: 0.2962\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4858 - val_loss: 0.2794\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4906 - val_loss: 0.2547\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4889 - val_loss: 0.2396\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4995 - val_loss: 0.4842\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4820 - val_loss: 0.2705\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4910 - val_loss: 0.2301\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4883 - val_loss: 0.2576\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4863 - val_loss: 0.2500\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4832 - val_loss: 0.2319\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4783 - val_loss: 0.2426\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4857 - val_loss: 0.2401\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4903 - val_loss: 0.4126\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4788 - val_loss: 0.2327\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4802 - val_loss: 0.2258\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4805 - val_loss: 0.2234\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4814 - val_loss: 0.4239\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4674 - val_loss: 0.2501\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4763 - val_loss: 0.2447\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4805 - val_loss: 0.2573\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.4577 - val_loss: 0.2340\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4690 - val_loss: 0.2149\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4813 - val_loss: 0.2290\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4748 - val_loss: 0.2260\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4741 - val_loss: 0.2302\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4697 - val_loss: 0.2196\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.4808 - val_loss: 0.2240\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4707 - val_loss: 0.2795\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4671 - val_loss: 0.2619\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4823 - val_loss: 0.2327\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4716 - val_loss: 0.2208\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4651 - val_loss: 0.2181\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4523 - val_loss: 0.2625\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4726 - val_loss: 0.2203\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4705 - val_loss: 0.2331\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4736 - val_loss: 0.2153\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4738 - val_loss: 0.2333\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4622 - val_loss: 0.2218\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.4704 - val_loss: 0.2212\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4737 - val_loss: 0.2122\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4546 - val_loss: 0.2146\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4584 - val_loss: 0.2370\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.4642 - val_loss: 0.2261\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4657 - val_loss: 0.2207\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4526 - val_loss: 0.2139\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4633 - val_loss: 0.2361\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4612 - val_loss: 0.3326\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4575 - val_loss: 0.3510\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4597 - val_loss: 0.2183\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4555 - val_loss: 0.2364\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.4572 - val_loss: 0.2127\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4670 - val_loss: 0.2168\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4526 - val_loss: 0.2793\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4607 - val_loss: 0.3548\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4475 - val_loss: 0.2111\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4531 - val_loss: 0.2124\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4515 - val_loss: 0.2705\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4527 - val_loss: 0.2969\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4490 - val_loss: 0.2683\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4458 - val_loss: 0.2487\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 3s 282us/step - loss: 0.4557 - val_loss: 0.2081\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 4s 369us/step - loss: 0.4527 - val_loss: 0.2288\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 4s 373us/step - loss: 0.4545 - val_loss: 0.2069\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 3s 329us/step - loss: 0.4476 - val_loss: 0.2113\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 3s 297us/step - loss: 0.4519 - val_loss: 0.2065\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 0.4529 - val_loss: 0.2288\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4647 - val_loss: 0.2092\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.4491 - val_loss: 0.2127\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4620 - val_loss: 0.2271\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4458 - val_loss: 0.2080\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4566 - val_loss: 0.2068\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4463 - val_loss: 0.3827\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4448 - val_loss: 0.2150\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4304 - val_loss: 0.3441\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4380 - val_loss: 0.2625\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.4495 - val_loss: 0.3454\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4451 - val_loss: 0.2644\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4423 - val_loss: 0.2237\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4569 - val_loss: 0.2126\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4483 - val_loss: 0.2237\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4474 - val_loss: 0.2391\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4400 - val_loss: 0.2024\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4376 - val_loss: 0.2424\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.4468 - val_loss: 0.2281\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 257us/step - loss: 0.4415 - val_loss: 0.2156\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4468 - val_loss: 0.3911\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4375 - val_loss: 0.2150\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.4427 - val_loss: 0.3411\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4429 - val_loss: 0.2461\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4401 - val_loss: 0.2011\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4426 - val_loss: 0.2117\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4472 - val_loss: 0.3365\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4418 - val_loss: 0.2135\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4367 - val_loss: 0.2434\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4415 - val_loss: 0.2114\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4440 - val_loss: 0.2636\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4454 - val_loss: 0.6806\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4399 - val_loss: 0.2855\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4461 - val_loss: 0.2560\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4400 - val_loss: 0.2935\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4436 - val_loss: 0.2001\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4351 - val_loss: 0.2214\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4435 - val_loss: 0.2515\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.4370 - val_loss: 0.2192\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4281 - val_loss: 0.2966\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4461 - val_loss: 0.2003\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4299 - val_loss: 0.2446\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4390 - val_loss: 0.2038\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4327 - val_loss: 0.2026\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4381 - val_loss: 0.2082\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4376 - val_loss: 0.1933\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4231 - val_loss: 0.2165\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.4239 - val_loss: 0.2319\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.4328 - val_loss: 0.2216\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4237 - val_loss: 0.1989\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4339 - val_loss: 0.2602\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4384 - val_loss: 0.2427\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4360 - val_loss: 0.2857\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4307 - val_loss: 0.2065\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4323 - val_loss: 0.2115\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4233 - val_loss: 0.2057\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4323 - val_loss: 0.2474\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4399 - val_loss: 0.2413\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4344 - val_loss: 0.2013\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4288 - val_loss: 0.2009\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4344 - val_loss: 0.1996\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4301 - val_loss: 0.2165\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4391 - val_loss: 0.2444\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4331 - val_loss: 0.2230\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4236 - val_loss: 0.2282\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 3s 274us/step - loss: 0.4385 - val_loss: 0.2150\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4248 - val_loss: 0.2154\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4279 - val_loss: 0.2083\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4275 - val_loss: 0.2460\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4417 - val_loss: 0.2215\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4343 - val_loss: 0.2896\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 0.4376 - val_loss: 0.1975\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4252 - val_loss: 0.1903\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.4357 - val_loss: 0.2104\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4245 - val_loss: 0.2000\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4382 - val_loss: 0.1974\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4246 - val_loss: 0.1993\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.4270 - val_loss: 0.5120\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4283 - val_loss: 0.2182\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4118 - val_loss: 0.1961\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4160 - val_loss: 0.3143\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.4261 - val_loss: 0.2115\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.4318 - val_loss: 0.1971\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4233 - val_loss: 0.1918\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4371 - val_loss: 0.2709\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4129 - val_loss: 0.3068\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4381 - val_loss: 0.2113\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4224 - val_loss: 0.2000\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.4327 - val_loss: 0.2604\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.4220 - val_loss: 0.1941\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4230 - val_loss: 0.2226\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4252 - val_loss: 0.1908\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4213 - val_loss: 0.2207\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4251 - val_loss: 0.1998\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4233 - val_loss: 0.3471\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4205 - val_loss: 0.1952\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4186 - val_loss: 0.2393\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4236 - val_loss: 0.1913\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4294 - val_loss: 0.2348\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4298 - val_loss: 0.2045\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.4099 - val_loss: 0.3619\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4310 - val_loss: 0.2195\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4270 - val_loss: 0.2088\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4232 - val_loss: 0.2517\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.4295 - val_loss: 0.1940\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4267 - val_loss: 0.2044\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4181 - val_loss: 0.1936\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4177 - val_loss: 0.2057\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.4172 - val_loss: 0.3086\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "model.compile(optimizer=SGD(lr=0.01),loss='mean_squared_error')\n",
    "history_dp_sigm_20 = model.fit(X_train_scaled, y_train, epochs=250, verbose=1, validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "model.compile(optimizer=SGD(lr=0.01),loss='mean_squared_error')\n",
    "history_dp_sigm_40 = model.fit(X_train_scaled, y_train, epochs=250, verbose=1, validation_data=(X_val_scaled, y_val))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2,figsize=(16,10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history_dp_sigm_20.history['val_loss'])\n",
    "plt.plot(history_dp_sigm_20.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDAL--DROPOUT DE 20%')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history_dp_sigm_40.history['val_loss'])\n",
    "plt.plot(history_dp_sigm_40.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO SIGMOIDAL--DROPOUT DE 40%')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<IMG SRC=\"1.PNG\" WIDTH=640 HEIGHT=480 BORDER=0 ALT=\"Un beb&eacute;\" ALIGN=\"CENTER\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=justify>En este caso hemos importado la respuesta grande del modelo original B que es tan comumente llamado en todo el ejercicio para poder compararlo con los resultados del Dropout de <font color=red><b>20%</font> </b>y de <font color=red><b>40%</font></b>, en este caso es importante señal que como primera medida tenemos un error en la data de validación inferior que en la función de perdida dde entrenamiento, aunque con unos comportamiento un poco inestables, pero es en el primer modelo que ocurre este comportamiento en todo momento, además que la magnitud del error es bastante pequeña, tambien podemos analizar que el mejor comportamiento se encuentra con un Dropout de<font color=red><b> 20%</font> </b>, en el de <font color=red><b>40%</font> </b> los márgenes de error se elevan un  poco, aunque es una cantidad despreciable con los porcentajes de error que se tienen modificando otro tipo de parámetros</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 3s 342us/step - loss: 1.6283 - val_loss: 0.6995\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.8254 - val_loss: 0.5177\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.7462 - val_loss: 0.4809\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.6928 - val_loss: 1.4124\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.6388 - val_loss: 0.3823\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.6279 - val_loss: 0.3480\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.5888 - val_loss: 0.4046\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.5792 - val_loss: 0.3681\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.5649 - val_loss: 0.3332\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.5367 - val_loss: 0.2976\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.5307 - val_loss: 0.3104\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.5170 - val_loss: 0.2817\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.4983 - val_loss: 0.5578\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4945 - val_loss: 0.4319\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4898 - val_loss: 0.2851\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4750 - val_loss: 0.2676\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4598 - val_loss: 0.2858\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4600 - val_loss: 0.3275\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.4493 - val_loss: 0.2465\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.4449 - val_loss: 0.4657\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4406 - val_loss: 0.2449\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 3s 259us/step - loss: 0.4385 - val_loss: 0.3052\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4301 - val_loss: 0.3697\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4216 - val_loss: 0.2197\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4127 - val_loss: 0.2149\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.4215 - val_loss: 0.3181\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.4031 - val_loss: 0.2186\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4168 - val_loss: 0.2473\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4047 - val_loss: 0.2574\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4052 - val_loss: 0.2071\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.3966 - val_loss: 0.2317\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3865 - val_loss: 0.2080\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.3943 - val_loss: 0.2276\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3910 - val_loss: 0.2025\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.3856 - val_loss: 0.2037\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3781 - val_loss: 0.2808\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3788 - val_loss: 0.2832\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3780 - val_loss: 0.2144\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.3665 - val_loss: 0.2577\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 0.3628 - val_loss: 0.3061\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3738 - val_loss: 0.2298\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.3615 - val_loss: 0.2296\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.3723 - val_loss: 0.2378\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3511 - val_loss: 0.2141\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3612 - val_loss: 0.3527\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3553 - val_loss: 0.2316\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3483 - val_loss: 0.1912\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.3430 - val_loss: 0.3920\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3530 - val_loss: 0.1800\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.3446 - val_loss: 0.2000\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3546 - val_loss: 0.2211\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3517 - val_loss: 0.2123\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3424 - val_loss: 0.2035\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3349 - val_loss: 0.1824\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.3345 - val_loss: 0.2021\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.3390 - val_loss: 0.2257\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.3373 - val_loss: 0.2770\n",
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.3243 - val_loss: 0.2397\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.3371 - val_loss: 0.1741\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.3351 - val_loss: 0.2057\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3360 - val_loss: 0.2154\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.3307 - val_loss: 0.2684\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.3327 - val_loss: 0.1808\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3257 - val_loss: 0.1768\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3334 - val_loss: 0.1702\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.3260 - val_loss: 0.1728\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.3204 - val_loss: 0.1693\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3214 - val_loss: 0.1666\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3221 - val_loss: 0.1852\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.3104 - val_loss: 0.1758\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.3140 - val_loss: 0.5563\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.3113 - val_loss: 0.1694\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3131 - val_loss: 0.1672\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.3180 - val_loss: 0.1642\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.3143 - val_loss: 0.1664\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3126 - val_loss: 0.1907\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.3106 - val_loss: 0.1650\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.3080 - val_loss: 0.1639\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3118 - val_loss: 0.1616\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.3161 - val_loss: 0.2173\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.3078 - val_loss: 0.1848\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2986 - val_loss: 0.1980\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.3115 - val_loss: 0.2931\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3072 - val_loss: 0.1760\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.3137 - val_loss: 0.2776\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.3157 - val_loss: 0.1690\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.3024 - val_loss: 0.1626\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2981 - val_loss: 0.1934\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.3018 - val_loss: 0.1666\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3022 - val_loss: 0.1567\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3016 - val_loss: 0.1710\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2970 - val_loss: 0.1608\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.3003 - val_loss: 0.2020\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3059 - val_loss: 0.2265\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2995 - val_loss: 0.1585\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.3014 - val_loss: 0.1565\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.2961 - val_loss: 0.1767\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.3020 - val_loss: 0.2198\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.2866 - val_loss: 0.1532\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2909 - val_loss: 0.1713\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2945 - val_loss: 0.3579\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2998 - val_loss: 0.3121\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2979 - val_loss: 0.1566\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2931 - val_loss: 0.1627\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2887 - val_loss: 0.1676\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2890 - val_loss: 0.1532\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2867 - val_loss: 0.2035\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2859 - val_loss: 0.1556\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2860 - val_loss: 0.1653\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2886 - val_loss: 0.1666\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2923 - val_loss: 0.2866\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2827 - val_loss: 0.1546\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2832 - val_loss: 0.1725\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2899 - val_loss: 0.1575\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2872 - val_loss: 0.1652\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.2876 - val_loss: 0.1964\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2864 - val_loss: 0.1837\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2825 - val_loss: 0.1816\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2824 - val_loss: 0.1522\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.2833 - val_loss: 0.1540\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.2788 - val_loss: 0.1598\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.2911 - val_loss: 0.1796\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.2801 - val_loss: 0.1512\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2878 - val_loss: 0.2386\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.2825 - val_loss: 0.3442\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2730 - val_loss: 0.1627\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2791 - val_loss: 0.1706\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.2790 - val_loss: 0.1522\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2771 - val_loss: 0.1639\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2823 - val_loss: 0.1817\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2743 - val_loss: 0.1470\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2787 - val_loss: 0.1514\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.2764 - val_loss: 0.1544\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2711 - val_loss: 0.1931\n",
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2795 - val_loss: 0.1639\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2766 - val_loss: 0.1732\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 3s 299us/step - loss: 0.2795 - val_loss: 0.1550\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.2768 - val_loss: 0.1585\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2798 - val_loss: 0.1673\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2710 - val_loss: 0.1837\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 3s 264us/step - loss: 0.2656 - val_loss: 0.1562\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.2747 - val_loss: 0.2578\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 3s 305us/step - loss: 0.2699 - val_loss: 0.1525\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 0.2724 - val_loss: 0.1490\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.2699 - val_loss: 0.1704\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.2767 - val_loss: 0.1493\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2721 - val_loss: 0.1449\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2704 - val_loss: 0.1972\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2742 - val_loss: 0.1561\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.2744 - val_loss: 0.1484\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.2681 - val_loss: 0.1565\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.2657 - val_loss: 0.1493\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2690 - val_loss: 0.1437\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2679 - val_loss: 0.1573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2666 - val_loss: 0.1605\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.2715 - val_loss: 0.1706\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2740 - val_loss: 0.2209\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2650 - val_loss: 0.1512\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2691 - val_loss: 0.1887\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2693 - val_loss: 0.1504\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2658 - val_loss: 0.1521\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2695 - val_loss: 0.2058\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2710 - val_loss: 0.1570\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2642 - val_loss: 0.1493\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2633 - val_loss: 0.2379\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2656 - val_loss: 0.1590\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2749 - val_loss: 0.1488\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.2673 - val_loss: 0.2554\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.2685 - val_loss: 0.1743\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.2641 - val_loss: 0.1540\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2578 - val_loss: 0.1566\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2669 - val_loss: 0.1676\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.2615 - val_loss: 0.1607\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2628 - val_loss: 0.1687\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2653 - val_loss: 0.1430\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 242us/step - loss: 0.2606 - val_loss: 0.1486\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2585 - val_loss: 0.2752\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2654 - val_loss: 0.1428\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2668 - val_loss: 0.1445\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2575 - val_loss: 0.1438\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2592 - val_loss: 0.1438\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.2620 - val_loss: 0.1403\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2605 - val_loss: 0.1532\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.2600 - val_loss: 0.1494\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2604 - val_loss: 0.1425\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.2630 - val_loss: 0.1451\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2566 - val_loss: 0.1552\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2613 - val_loss: 0.1890\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2538 - val_loss: 0.1693\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2640 - val_loss: 0.3717\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2657 - val_loss: 0.1384\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.2545 - val_loss: 0.1635\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2570 - val_loss: 0.1482\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2618 - val_loss: 0.1405\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.2616 - val_loss: 0.1610\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 247us/step - loss: 0.2553 - val_loss: 0.2299\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2576 - val_loss: 0.1407\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2561 - val_loss: 0.1689\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.2563 - val_loss: 0.1835\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2545 - val_loss: 0.1482\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.2561 - val_loss: 0.1690\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2539 - val_loss: 0.1387\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.2602 - val_loss: 0.1434\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2607 - val_loss: 0.2163\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.2559 - val_loss: 0.1403\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2602 - val_loss: 0.2058\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.2543 - val_loss: 0.1445\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2537 - val_loss: 0.1373\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2552 - val_loss: 0.1381\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2538 - val_loss: 0.1521\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2540 - val_loss: 0.1383\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 0.2536 - val_loss: 0.2328\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 3s 287us/step - loss: 0.2568 - val_loss: 0.1480\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2634 - val_loss: 0.1486\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2474 - val_loss: 0.1858\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.2507 - val_loss: 0.2167\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2519 - val_loss: 0.1446\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2553 - val_loss: 0.1472\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.2470 - val_loss: 0.1957\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2529 - val_loss: 0.1390\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2505 - val_loss: 0.1467\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2497 - val_loss: 0.1967\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2536 - val_loss: 0.1508\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2502 - val_loss: 0.1390\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2525 - val_loss: 0.2327\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.2452 - val_loss: 0.1429\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2467 - val_loss: 0.1374\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.2489 - val_loss: 0.1422\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2444 - val_loss: 0.1370\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2459 - val_loss: 0.1831\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2494 - val_loss: 0.1605\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.2479 - val_loss: 0.1815\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.2504 - val_loss: 0.1351\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2486 - val_loss: 0.1399\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2479 - val_loss: 0.1344\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.2461 - val_loss: 0.1395\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2423 - val_loss: 0.2020\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.2496 - val_loss: 0.1356\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2485 - val_loss: 0.1389\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2442 - val_loss: 0.1563\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2498 - val_loss: 0.1529\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2513 - val_loss: 0.3024\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 241us/step - loss: 0.2493 - val_loss: 0.2048\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.2475 - val_loss: 0.1339\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.2502 - val_loss: 0.1386\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2437 - val_loss: 0.1580\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 243us/step - loss: 0.2472 - val_loss: 0.1562\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2450 - val_loss: 0.1442\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.2405 - val_loss: 0.1400\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.2499 - val_loss: 0.1612\n",
      "Train on 9745 samples, validate on 4060 samples\n",
      "Epoch 1/250\n",
      "9745/9745 [==============================] - 3s 330us/step - loss: 2.0756 - val_loss: 0.6187\n",
      "Epoch 2/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 1.1109 - val_loss: 0.4985\n",
      "Epoch 3/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 1.0247 - val_loss: 0.6312\n",
      "Epoch 4/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.9478 - val_loss: 2.8600\n",
      "Epoch 5/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.9114 - val_loss: 0.4282\n",
      "Epoch 6/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.8764 - val_loss: 0.4421\n",
      "Epoch 7/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.8637 - val_loss: 0.5623\n",
      "Epoch 8/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.8325 - val_loss: 0.5774\n",
      "Epoch 9/250\n",
      "9745/9745 [==============================] - 3s 324us/step - loss: 0.8194 - val_loss: 0.4010\n",
      "Epoch 10/250\n",
      "9745/9745 [==============================] - 4s 404us/step - loss: 0.8111 - val_loss: 0.3857\n",
      "Epoch 11/250\n",
      "9745/9745 [==============================] - 3s 333us/step - loss: 0.7784 - val_loss: 0.7766\n",
      "Epoch 12/250\n",
      "9745/9745 [==============================] - 3s 308us/step - loss: 0.7497 - val_loss: 0.8711\n",
      "Epoch 13/250\n",
      "9745/9745 [==============================] - 3s 290us/step - loss: 0.7524 - val_loss: 0.3471\n",
      "Epoch 14/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 0.7401 - val_loss: 0.3710\n",
      "Epoch 15/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 0.7207 - val_loss: 0.4951\n",
      "Epoch 16/250\n",
      "9745/9745 [==============================] - 3s 277us/step - loss: 0.7232 - val_loss: 0.3486\n",
      "Epoch 17/250\n",
      "9745/9745 [==============================] - 3s 266us/step - loss: 0.7245 - val_loss: 0.5364\n",
      "Epoch 18/250\n",
      "9745/9745 [==============================] - 3s 269us/step - loss: 0.6783 - val_loss: 0.3064\n",
      "Epoch 19/250\n",
      "9745/9745 [==============================] - 3s 290us/step - loss: 0.6652 - val_loss: 0.3261\n",
      "Epoch 20/250\n",
      "9745/9745 [==============================] - 3s 272us/step - loss: 0.6702 - val_loss: 0.3541\n",
      "Epoch 21/250\n",
      "9745/9745 [==============================] - 3s 285us/step - loss: 0.6619 - val_loss: 0.3115\n",
      "Epoch 22/250\n",
      "9745/9745 [==============================] - 3s 281us/step - loss: 0.6545 - val_loss: 0.3671\n",
      "Epoch 23/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.6474 - val_loss: 0.2979\n",
      "Epoch 24/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 0.6398 - val_loss: 0.4185\n",
      "Epoch 25/250\n",
      "9745/9745 [==============================] - 3s 289us/step - loss: 0.6324 - val_loss: 0.3486\n",
      "Epoch 26/250\n",
      "9745/9745 [==============================] - 3s 280us/step - loss: 0.6329 - val_loss: 0.3833\n",
      "Epoch 27/250\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 0.6227 - val_loss: 0.2977\n",
      "Epoch 28/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 0.6263 - val_loss: 0.3909\n",
      "Epoch 29/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 0.6116 - val_loss: 0.9564\n",
      "Epoch 30/250\n",
      "9745/9745 [==============================] - 3s 267us/step - loss: 0.6179 - val_loss: 0.3259\n",
      "Epoch 31/250\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 0.5902 - val_loss: 0.2709\n",
      "Epoch 32/250\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 0.5882 - val_loss: 0.2840\n",
      "Epoch 33/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.6068 - val_loss: 0.5531\n",
      "Epoch 34/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.5898 - val_loss: 0.2918\n",
      "Epoch 35/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.5849 - val_loss: 0.2999\n",
      "Epoch 36/250\n",
      "9745/9745 [==============================] - 2s 257us/step - loss: 0.5812 - val_loss: 0.3151\n",
      "Epoch 37/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5744 - val_loss: 0.2601\n",
      "Epoch 38/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.5583 - val_loss: 0.3215\n",
      "Epoch 39/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.5538 - val_loss: 0.3235\n",
      "Epoch 40/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.5525 - val_loss: 0.2947\n",
      "Epoch 41/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.5653 - val_loss: 0.2887\n",
      "Epoch 42/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.5588 - val_loss: 0.3842\n",
      "Epoch 43/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.5498 - val_loss: 0.2587\n",
      "Epoch 44/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.5557 - val_loss: 0.2552\n",
      "Epoch 45/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.5616 - val_loss: 0.2688\n",
      "Epoch 46/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.5582 - val_loss: 0.3098\n",
      "Epoch 47/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 0.5421 - val_loss: 0.2538\n",
      "Epoch 48/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.5454 - val_loss: 0.2535\n",
      "Epoch 49/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 0.5452 - val_loss: 0.2605\n",
      "Epoch 50/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.5463 - val_loss: 0.2709\n",
      "Epoch 51/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.5407 - val_loss: 0.2589\n",
      "Epoch 52/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.5347 - val_loss: 0.3272\n",
      "Epoch 53/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.5354 - val_loss: 0.2455\n",
      "Epoch 54/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.5243 - val_loss: 0.5280\n",
      "Epoch 55/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.5285 - val_loss: 0.3115\n",
      "Epoch 56/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.5332 - val_loss: 0.2436\n",
      "Epoch 57/250\n",
      "9745/9745 [==============================] - 3s 263us/step - loss: 0.5273 - val_loss: 0.2380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5279 - val_loss: 0.2569\n",
      "Epoch 59/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.5245 - val_loss: 0.3453\n",
      "Epoch 60/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.5183 - val_loss: 0.2411\n",
      "Epoch 61/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.5115 - val_loss: 0.3244\n",
      "Epoch 62/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5178 - val_loss: 0.2365\n",
      "Epoch 63/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.5068 - val_loss: 0.3762\n",
      "Epoch 64/250\n",
      "9745/9745 [==============================] - 3s 262us/step - loss: 0.5204 - val_loss: 0.2450\n",
      "Epoch 65/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5151 - val_loss: 0.2376\n",
      "Epoch 66/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.5120 - val_loss: 0.2834\n",
      "Epoch 67/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.5123 - val_loss: 0.2489\n",
      "Epoch 68/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.5033 - val_loss: 0.2357\n",
      "Epoch 69/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4993 - val_loss: 0.2508\n",
      "Epoch 70/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.5028 - val_loss: 0.2496\n",
      "Epoch 71/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5155 - val_loss: 0.2366\n",
      "Epoch 72/250\n",
      "9745/9745 [==============================] - 3s 279us/step - loss: 0.5134 - val_loss: 0.2762\n",
      "Epoch 73/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5220 - val_loss: 0.3654\n",
      "Epoch 74/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4908 - val_loss: 0.2392\n",
      "Epoch 75/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 0.4969 - val_loss: 0.2334\n",
      "Epoch 76/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.5032 - val_loss: 0.3007\n",
      "Epoch 77/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.5080 - val_loss: 0.3834\n",
      "Epoch 78/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4878 - val_loss: 0.2422\n",
      "Epoch 79/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4804 - val_loss: 0.2531\n",
      "Epoch 80/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4904 - val_loss: 0.2389\n",
      "Epoch 81/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4864 - val_loss: 0.2463\n",
      "Epoch 82/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4976 - val_loss: 0.2410\n",
      "Epoch 83/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4869 - val_loss: 0.2696\n",
      "Epoch 84/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4911 - val_loss: 0.2393\n",
      "Epoch 85/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4864 - val_loss: 0.3274\n",
      "Epoch 86/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4784 - val_loss: 0.2431\n",
      "Epoch 87/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4852 - val_loss: 0.3054\n",
      "Epoch 88/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4849 - val_loss: 0.5505\n",
      "Epoch 89/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4799 - val_loss: 0.2662\n",
      "Epoch 90/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4780 - val_loss: 0.2310\n",
      "Epoch 91/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4665 - val_loss: 0.3812\n",
      "Epoch 92/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4835 - val_loss: 0.2270\n",
      "Epoch 93/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4771 - val_loss: 0.2564\n",
      "Epoch 94/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4841 - val_loss: 0.2609\n",
      "Epoch 95/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4776 - val_loss: 0.3008\n",
      "Epoch 96/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4715 - val_loss: 0.3312\n",
      "Epoch 97/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4754 - val_loss: 0.4220\n",
      "Epoch 98/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4817 - val_loss: 0.3055\n",
      "Epoch 99/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4698 - val_loss: 0.2303\n",
      "Epoch 100/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4828 - val_loss: 0.2395\n",
      "Epoch 101/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4796 - val_loss: 0.2443\n",
      "Epoch 102/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4832 - val_loss: 0.2815\n",
      "Epoch 103/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4634 - val_loss: 0.2512\n",
      "Epoch 104/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4675 - val_loss: 0.2965\n",
      "Epoch 105/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4706 - val_loss: 0.2536\n",
      "Epoch 106/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4681 - val_loss: 0.2736\n",
      "Epoch 107/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4721 - val_loss: 0.2537\n",
      "Epoch 108/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4769 - val_loss: 0.2226\n",
      "Epoch 109/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4668 - val_loss: 0.2281\n",
      "Epoch 110/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4738 - val_loss: 0.2273\n",
      "Epoch 111/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4592 - val_loss: 0.3351\n",
      "Epoch 112/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4695 - val_loss: 0.2540\n",
      "Epoch 113/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.4686 - val_loss: 0.2277\n",
      "Epoch 114/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4606 - val_loss: 0.2584\n",
      "Epoch 115/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4665 - val_loss: 0.5450\n",
      "Epoch 116/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4690 - val_loss: 0.2291\n",
      "Epoch 117/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4700 - val_loss: 0.2260\n",
      "Epoch 118/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4554 - val_loss: 0.2593\n",
      "Epoch 119/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4727 - val_loss: 0.2097\n",
      "Epoch 120/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4654 - val_loss: 0.3184\n",
      "Epoch 121/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4605 - val_loss: 0.2620\n",
      "Epoch 122/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4665 - val_loss: 0.3337\n",
      "Epoch 123/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4664 - val_loss: 0.3124\n",
      "Epoch 124/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4676 - val_loss: 0.2502\n",
      "Epoch 125/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4558 - val_loss: 0.2167\n",
      "Epoch 126/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.4633 - val_loss: 0.3174\n",
      "Epoch 127/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4581 - val_loss: 0.2627\n",
      "Epoch 128/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4538 - val_loss: 0.2354\n",
      "Epoch 129/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4674 - val_loss: 0.2344\n",
      "Epoch 130/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.4617 - val_loss: 0.3106\n",
      "Epoch 131/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4549 - val_loss: 0.2544\n",
      "Epoch 132/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4546 - val_loss: 0.2252\n",
      "Epoch 133/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4528 - val_loss: 0.2619\n",
      "Epoch 134/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4525 - val_loss: 0.2609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 135/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4499 - val_loss: 0.2261\n",
      "Epoch 136/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4403 - val_loss: 0.2501\n",
      "Epoch 137/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4523 - val_loss: 0.2099\n",
      "Epoch 138/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4462 - val_loss: 0.2293\n",
      "Epoch 139/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4488 - val_loss: 0.2066\n",
      "Epoch 140/250\n",
      "9745/9745 [==============================] - 2s 245us/step - loss: 0.4442 - val_loss: 0.2079\n",
      "Epoch 141/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4565 - val_loss: 0.2481\n",
      "Epoch 142/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4550 - val_loss: 0.2809\n",
      "Epoch 143/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4568 - val_loss: 0.2190\n",
      "Epoch 144/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4426 - val_loss: 0.2257\n",
      "Epoch 145/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4401 - val_loss: 0.2489\n",
      "Epoch 146/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4432 - val_loss: 0.3280\n",
      "Epoch 147/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4589 - val_loss: 0.2267\n",
      "Epoch 148/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.4509 - val_loss: 0.2062\n",
      "Epoch 149/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4479 - val_loss: 0.2542\n",
      "Epoch 150/250\n",
      "9745/9745 [==============================] - 3s 257us/step - loss: 0.4549 - val_loss: 0.2158\n",
      "Epoch 151/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4664 - val_loss: 0.2148\n",
      "Epoch 152/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.4536 - val_loss: 0.2275\n",
      "Epoch 153/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4370 - val_loss: 0.2105\n",
      "Epoch 154/250\n",
      "9745/9745 [==============================] - 3s 265us/step - loss: 0.4344 - val_loss: 0.2709\n",
      "Epoch 155/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4459 - val_loss: 0.2063\n",
      "Epoch 156/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4478 - val_loss: 0.2123\n",
      "Epoch 157/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4454 - val_loss: 0.2044\n",
      "Epoch 158/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4507 - val_loss: 0.7360\n",
      "Epoch 159/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4519 - val_loss: 0.2060\n",
      "Epoch 160/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4392 - val_loss: 0.2613\n",
      "Epoch 161/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.4389 - val_loss: 0.2542\n",
      "Epoch 162/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4594 - val_loss: 0.4786\n",
      "Epoch 163/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4451 - val_loss: 0.2055\n",
      "Epoch 164/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4352 - val_loss: 0.5822\n",
      "Epoch 165/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4512 - val_loss: 0.2481\n",
      "Epoch 166/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4393 - val_loss: 0.2381\n",
      "Epoch 167/250\n",
      "9745/9745 [==============================] - 3s 272us/step - loss: 0.4493 - val_loss: 0.2633\n",
      "Epoch 168/250\n",
      "9745/9745 [==============================] - 3s 270us/step - loss: 0.4443 - val_loss: 0.2009\n",
      "Epoch 169/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4347 - val_loss: 0.2121\n",
      "Epoch 170/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4211 - val_loss: 0.2017\n",
      "Epoch 171/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4487 - val_loss: 0.2020\n",
      "Epoch 172/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4330 - val_loss: 0.2379\n",
      "Epoch 173/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4414 - val_loss: 0.2352\n",
      "Epoch 174/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4525 - val_loss: 0.2160\n",
      "Epoch 175/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4438 - val_loss: 0.2331\n",
      "Epoch 176/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4433 - val_loss: 0.2003\n",
      "Epoch 177/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4342 - val_loss: 0.2919\n",
      "Epoch 178/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4414 - val_loss: 0.3888\n",
      "Epoch 179/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4381 - val_loss: 0.2370\n",
      "Epoch 180/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4432 - val_loss: 0.3896\n",
      "Epoch 181/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4294 - val_loss: 0.2149\n",
      "Epoch 182/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4325 - val_loss: 0.2106\n",
      "Epoch 183/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.4300 - val_loss: 0.2150\n",
      "Epoch 184/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4231 - val_loss: 0.4482\n",
      "Epoch 185/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4505 - val_loss: 0.2222\n",
      "Epoch 186/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4403 - val_loss: 0.2076\n",
      "Epoch 187/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4371 - val_loss: 0.4503\n",
      "Epoch 188/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4338 - val_loss: 0.2682\n",
      "Epoch 189/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4380 - val_loss: 0.3010\n",
      "Epoch 190/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4316 - val_loss: 0.2371\n",
      "Epoch 191/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4407 - val_loss: 0.2073\n",
      "Epoch 192/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4477 - val_loss: 0.2087\n",
      "Epoch 193/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4303 - val_loss: 0.2841\n",
      "Epoch 194/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4400 - val_loss: 0.2347\n",
      "Epoch 195/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4394 - val_loss: 0.2756\n",
      "Epoch 196/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4322 - val_loss: 0.2129\n",
      "Epoch 197/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4410 - val_loss: 0.2128\n",
      "Epoch 198/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4325 - val_loss: 0.2023\n",
      "Epoch 199/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4422 - val_loss: 0.2182\n",
      "Epoch 200/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4294 - val_loss: 0.2196\n",
      "Epoch 201/250\n",
      "9745/9745 [==============================] - 2s 254us/step - loss: 0.4413 - val_loss: 0.2681\n",
      "Epoch 202/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4261 - val_loss: 0.1979\n",
      "Epoch 203/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4322 - val_loss: 0.2237\n",
      "Epoch 204/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4341 - val_loss: 0.1990\n",
      "Epoch 205/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4257 - val_loss: 0.2731\n",
      "Epoch 206/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4377 - val_loss: 0.2148\n",
      "Epoch 207/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4368 - val_loss: 0.2134\n",
      "Epoch 208/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4203 - val_loss: 0.2346\n",
      "Epoch 209/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4202 - val_loss: 0.2660\n",
      "Epoch 210/250\n",
      "9745/9745 [==============================] - 3s 268us/step - loss: 0.4264 - val_loss: 0.2331\n",
      "Epoch 211/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4233 - val_loss: 0.2034\n",
      "Epoch 212/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4395 - val_loss: 0.1991\n",
      "Epoch 213/250\n",
      "9745/9745 [==============================] - 2s 244us/step - loss: 0.4314 - val_loss: 0.2536\n",
      "Epoch 214/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4182 - val_loss: 0.1959\n",
      "Epoch 215/250\n",
      "9745/9745 [==============================] - 2s 252us/step - loss: 0.4313 - val_loss: 0.3319\n",
      "Epoch 216/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4208 - val_loss: 0.3661\n",
      "Epoch 217/250\n",
      "9745/9745 [==============================] - 2s 249us/step - loss: 0.4284 - val_loss: 0.4570\n",
      "Epoch 218/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4325 - val_loss: 0.2041\n",
      "Epoch 219/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4262 - val_loss: 0.2044\n",
      "Epoch 220/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4254 - val_loss: 0.2039\n",
      "Epoch 221/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4356 - val_loss: 0.2075\n",
      "Epoch 222/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4251 - val_loss: 0.1972\n",
      "Epoch 223/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4212 - val_loss: 0.2727\n",
      "Epoch 224/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4353 - val_loss: 0.2065\n",
      "Epoch 225/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4217 - val_loss: 0.2242\n",
      "Epoch 226/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4227 - val_loss: 0.3238\n",
      "Epoch 227/250\n",
      "9745/9745 [==============================] - 2s 251us/step - loss: 0.4261 - val_loss: 0.2868\n",
      "Epoch 228/250\n",
      "9745/9745 [==============================] - 2s 255us/step - loss: 0.4173 - val_loss: 0.2048\n",
      "Epoch 229/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4357 - val_loss: 0.1993\n",
      "Epoch 230/250\n",
      "9745/9745 [==============================] - 2s 246us/step - loss: 0.4270 - val_loss: 0.2588\n",
      "Epoch 231/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4239 - val_loss: 0.2119\n",
      "Epoch 232/250\n",
      "9745/9745 [==============================] - 2s 256us/step - loss: 0.4262 - val_loss: 0.2045\n",
      "Epoch 233/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4246 - val_loss: 0.1979\n",
      "Epoch 234/250\n",
      "9745/9745 [==============================] - 2s 248us/step - loss: 0.4261 - val_loss: 0.2798\n",
      "Epoch 235/250\n",
      "9745/9745 [==============================] - 2s 250us/step - loss: 0.4270 - val_loss: 0.1973\n",
      "Epoch 236/250\n",
      "9745/9745 [==============================] - 3s 260us/step - loss: 0.4343 - val_loss: 0.1980\n",
      "Epoch 237/250\n",
      "9745/9745 [==============================] - 3s 258us/step - loss: 0.4144 - val_loss: 0.2242\n",
      "Epoch 238/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4155 - val_loss: 0.1924\n",
      "Epoch 239/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4211 - val_loss: 0.2105\n",
      "Epoch 240/250\n",
      "9745/9745 [==============================] - 2s 253us/step - loss: 0.4212 - val_loss: 0.1997\n",
      "Epoch 241/250\n",
      "9745/9745 [==============================] - 2s 223us/step - loss: 0.4291 - val_loss: 0.2096\n",
      "Epoch 242/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.4132 - val_loss: 0.2119\n",
      "Epoch 243/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.4346 - val_loss: 0.2463\n",
      "Epoch 244/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.4187 - val_loss: 0.1932\n",
      "Epoch 245/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.4117 - val_loss: 0.2300\n",
      "Epoch 246/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.4270 - val_loss: 0.1967\n",
      "Epoch 247/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.4283 - val_loss: 0.1976\n",
      "Epoch 248/250\n",
      "9745/9745 [==============================] - 2s 216us/step - loss: 0.4280 - val_loss: 0.2109\n",
      "Epoch 249/250\n",
      "9745/9745 [==============================] - 2s 218us/step - loss: 0.4262 - val_loss: 0.2086\n",
      "Epoch 250/250\n",
      "9745/9745 [==============================] - 2s 220us/step - loss: 0.4126 - val_loss: 0.2374\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "model.compile(optimizer=SGD(lr=0.01),loss='mean_squared_error')\n",
    "history_dp_relu_20 = model.fit(X_train_scaled, y_train, epochs=250, verbose=1, validation_data=(X_val_scaled, y_val))\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_dim=X_train_scaled.shape[1], kernel_initializer='uniform',activation=\"sigmoid\"))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1, kernel_initializer='uniform',activation=\"linear\")) \n",
    "model.compile(optimizer=SGD(lr=0.01),loss='mean_squared_error')\n",
    "history_dp_relu_40 = model.fit(X_train_scaled, y_train, epochs=250, verbose=1, validation_data=(X_val_scaled, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'Epochs')"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA7MAAAE0CAYAAAD+NGQmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3XmcXGWV//HPqSXd2XcIZCEJm4aEBAj7FgwKqKyiGHZhRGdwQFAH9Keo6DggjsimCIjIIhmURZRNVDSggIYQQtgTyNJkJUsnnU5vVef3x71VXV1dvSTd1bc69X2/XvVK961bVacq6Tx97nOe85i7IyIiIiIiItKbxKIOQERERERERGRbKZkVERERERGRXkfJrIiIiIiIiPQ6SmZFRERERESk11EyKyIiIiIiIr2OklkRERERERHpdZTMioiIiIiISK+jZFa6zMyWmFmDmY3IOz7fzNzMxuccO8zM/mJmm82s2sx+b2aTcu6fYWZpM6sJb1Vm9oCZHZj33G5mW3LOqzGz/wrv+46Z3dtOvOeb2atmVmtmq8zsZ2Y2pJ3z7wrfX42ZrTezp83sQ3nPl8qLpcbMds35fI5tI47n2vg8W53fTnxLzGxr+JluNLN/mNkXzSyWc0677yE8Z4yZ3Wdm68LP9p9m9sm8c3I/9/fN7MdmFu/sZxvG8f285xwfPm8i7/NLh+8r8/1ZBd575n1tDm8Lzex/zGxwXkxt/v3kPd9OZna/ma0I/33+3cwOzjvnTDNbGn4Oj5jZsJz7fmJmG8zseTMbnXP8LDO7oe2/RRGR7qWxWWNzZz/bUh+b85776DCu/HgvC99btZndaWYV4fGEmc0O/w6eMLOBOY/5f2Z2WXuvJ6VPyax0l/eAWZlvzGwK0Df3BDM7FPgj8DtgV2AC8ArwdzObmHPqCncfAAwEDgHeBJ41s5l5rznV3Qfk3H7YUZBm9hXgWuBrwODw+XcDnjazPu089IdhTKOB94Ff5N3/fF4sA9x9RUfxdKMT3X0gwXu5BriiQIxtvgcLErLngAZgH2AEcD3wazM7Pe95pobPMxM4E/h8+Bzb+9lm5X5+wLLwfWWO3dfGw34YvveRwOfC1/27mfXPOaezfz8DgH8BBwDDgF8Bj5nZgPA97gP8HDgH2BmoBX4a3ndQ+LhRBJ/l18Pjg4GvAld15jMQEelGGps1Nu8IY3Pm80gCNwAv5h0/DrgyfO/jgYnAd8O7TwOc4LPbBHwhfMwE4ETgps58BlK6lMxKd7kHODfn+/OAu/PO+SFwt7vf4O6b3X29u38TeAH4Tv4TeqDK3a8C7iD4z3i7mdkggv/c/tPdn3T3RndfAnyG4D/2szt6DnffCjwATOtKLMXi7tXu/ihwBnCemU0ucE6h93AZUANc6O6r3H2ru98P/Dfwv2ZmBZ7nTeBZYHJ3fLZd5e517v4v4CRgOMHgua3P8a67/9jdV7p7yt1vA/oAe4ennAX83t3nuHsN8C3gtPBK7wTgOXevB/5MMJhC8Ble5+7VXXqDIiLbTmNzCdDY3LWxOcdXCC68vJl3/DzgF+7+mrtvAL4HnB/eNwH4q7s3Ac/QPDbfCHw1PC69mJJZ6S4vAIPM7MNhacsZQLacyMz6AYcBvynw2AeAj3bw/A8B++dd0dtWhwGV4XNlhUnJE52IgfD1ZwGLuhBH0bn7P4Eq4Mj8+9p4Dx8FHnT3dN7pDwDjgL0KPM+k8Plfphs+2+7i7puBpynw3reVmU0jSGYzn9U+BDMWmddaTHDFfC/gNeBIM+tLcHX4NTObDuzt7r/uaiwiIttBY3MJ0di8/WOzme0GXABcXeDuFmNz+PXOZjYcWAh8JJyFPoZgbD4V+MDdW5WTS++jZFa6U+YK8EcJrpq9n3PfMIJ/bysLPG4lQflHe1YABuSun5kXroHI3I7r4DlGEPznVegqXEcxfNXMNgKbgSMIykxzHZIXy+IOYukJKwg+94z23sMI2v67ydyfMc/MNgC/J7gq/0u69tkWQ/573+a/n/CK9j3Ad3NmVQcA+TOs1cBAd18IPEjwy+M4gtmKG4BLzOwSM5tjwbqnNteAiYgUgcZmjc07wth8I/CtMBHPlz82Z74eCDxOUG4/Nzw+G/g2cIWZ/Xc4Nv+0syXXUnqUzEp3uodgncb5tC5j2gCkgV0KPG4X4IMOnns0wZqHjTnH9nf3ITm3pzp4jg+AEWaW2I4YfuTuQwjWYmyluew044W8WHbvIBaAJiBZ4HgSaDSzcblNEQDC5gVtNl3IMxpY38n38AFt/91k7s/Y392Huvvu7v7N8IpxZz/bQu85SfBvI//Kc1fkv/dt+vsJZ1d/Hz7uf3LuqgEG5Z0+iOCXENz9enef6u5nEMyAPEvw/+xFBLO1bxCs6xER6SkamzU29+qx2cxOJLho/H9tPG/+2Jz5enNYFn+lu+/r7hcRjMG3AtPD29EEFVgXbP/bkigpmZVu4+5LCa5+fZzWJS1bgOeBTxd46GcI1hi251RgXvg82+t5oJ6gGUBWWNpzQidiwN2XAZcCN4QJT1csA8blrnkJS752Apa6+zJv2XQBdz/BO266gAUdJkcTNI7ozHv4E/Apy+myGPoMsBx4u4P30tnPdhnBgJ1rArC8QBnVdgmbNR1LkEhuz+MrgEcIZi++kHf3a8DUnHMnAhXkfT5mtnP42KuBycACd28kaC617/bEJSKyPTQ2bzONzYFSGptnAtMt6Fa8iuBi8ZfN7Hfh/S3G5vDr1e6+Li+GyQSl17cBU4CX3N3R2NyrKZmV7nYh8JE2BrYrCRofXGJmA81sqAWt1Q+luetclgVGm9m3gX8DvrENccTMrDLnVhGWin4XuMnMjjezpAVbE/yGYA3LPZ15Ynd/mqBU5qJtiCeZF0+CoBtfHXBleKw/QbfDucDSbXjuLDMbZEHL/tnAve7+aiffw/UEVzJ/YWajwnhmAf8P+Fr4n32btuGzfRD4hJl9zMziFrTg/2YYb5eYWYWZHUCQiG4gKLHa1udIAr8luDp+boFB/D7gRDM7Mvz7uhp4KFwLlOvHwLfdvZbgl8gDw4F8BvDutsYlItJFGpsL09gcKOmxmaDZ4l4EzbGmAY8Ct9PcTOpu4EIzm2RmQ8PY78qLw4BbgEvDsf094AgLyouPRmNz7+XuuunWpRuwBDi2wPEEQfnR+JxjRwB/JSgJ2QQ8BkzOuX8GQUlLDbCF4D/13wKH5D23h/fX5Nx+Et73nfD+3FtVzmMvJGgIsBVYTbDVytB23t9dwPfzjp1BMHNXQVC6lcqLpQY4MOfzyY/n++F9k4CnCEp9Vofvdex2fP5bCUpdqwmuxF4MxDv7HsLvxwH3E5QAbSG4Unlygc99j3Zi6fCzJWiF/1IY61LgOqBvZ/9dFfi7aQjf+xaCq7PXAkNyzmn37yfv+Y4O32Nt3rlH5pxzJsFV7C0EW1kMy3uOY4DH8o79hGAQfwEYE/XPrG666bbj39r6PxSNzRqbe9nY3Mm/+8vD97aJIGGuyLv/AuCWvJ+D2eH7fYqgjDnyn1vdtv1m4V+oiIiIiIiISK+hMmMRERERERHpdZTMioiIiIiISK+jZFZERERERER6HSWzIiIiIiIi0usomRUREREREZFeJxF1ANtqxIgRPn78+KjDEBGRHcRLL730gbuPjDqO3kxjs4iIdKfOjs29LpkdP348c+fOjToMERHZQZjZ0qhj6O00NouISHfq7NisMmMRERERERHpdZTMioiIiIiISK+jZFZERERERER6nV63ZlZEpNw1NjZSVVVFXV1d1KH0KpWVlYwZM4ZkMhl1KCIisoPR2Lx9ujo2K5kVEellqqqqGDhwIOPHj8fMog6nV3B31q1bR1VVFRMmTIg6HBER2cFobN523TE2q8xYRKSXqaurY/jw4Rost4GZMXz4cF0xFxGRotDYvO26Y2xWMisi0gtpsNx2+sxERKSYNM5su65+ZkpmRUREREREpNcpz2S2Zg387Ah4/dGoIxER6XVmzJjBU0891eLYT37yE/7jP/6jzccMGDCgzfuWLFnC5MmTuy0+2XE8NK+Kn/11cdRhiIiUvHIdm8szmU2nYPWrUPtB1JGIiPQ6s2bNYvbs2S2OzZ49m1mzZkUUkeyonly4iodfroo6DBGRkleuY3PRuhmb2Z3AJ4E17l4wrTezGcBPgCTwgbsfXax4WojFgz/TqR55ORGRYvnu71/j9RWbuvU5J+06iG+fuE+b959++ul885vfpL6+noqKCpYsWcKKFSuYNm0aM2fOZMOGDTQ2NvL973+fk08+ebvjmD9/Pl/84hepra1l9913584772To0KHceOON3HrrrSQSCSZNmsTs2bP529/+xqWXXgoE62/mzJnDwIEDt/u1pTSkHdyjjkJEZNtobO65sbmYM7N3Ace3daeZDQF+Cpzk7vsAny5iLHkvHiaznu6xlxQR2VEMHz6cgw46iCeffBIIrvyeccYZ9O3bl4cffph58+bxzDPP8JWvfAXvQiZy7rnncu2117JgwQKmTJnCd7/7XQCuueYaXn75ZRYsWMCtt94KwI9+9CNuueUW5s+fz7PPPkvfvn27/kYlcu5OWtmsiEiHynVsLtrMrLvPMbPx7ZxyJvCQuy8Lz19TrFhayc7MNvXYS4qIFEN7V2mLKVPOdPLJJzN79mzuvPNO3J1vfOMbzJkzh1gsxvvvv8/q1asZNWrUNj9/dXU1Gzdu5Oijg4Kd8847j09/Orjmue+++3LWWWdxyimncMoppwBw+OGHc/nll3PWWWdx2mmnMWbMmO57sxKZtLtmZkWk19HY3HNjc5RrZvcChprZX83sJTM7t60TzewiM5trZnPXrl3b9VdWmbGISJeccsop/PnPf2bevHls3bqV/fffn/vuu4+1a9fy0ksvMX/+fHbeeeei7Ov62GOPcfHFF/PSSy9xwAEH0NTUxJVXXskdd9zB1q1bOeSQQ3jzzTe7/XWl56UdzcyKiHRSOY7NUSazCeAA4BPAccC3zGyvQie6+23uPt3dp48cObLrr5wtM1YyKyKyPQYMGMCMGTO44IILss0lqqur2WmnnUgmkzzzzDMsXbp0u59/8ODBDB06lGeffRaAe+65h6OPPpp0Os3y5cs55phj+OEPf8jGjRupqalh8eLFTJkyhSuuuILp06crmd1BpN1JK5cVEemUchybi1Zm3AlVBE2ftgBbzGwOMBV4u+ivrJlZEZEumzVrFqeddlq2e+JZZ53FiSeeyPTp05k2bRof+tCHOv1cb731Vovyo+uvv55f/epX2SYTEydO5Je//CWpVIqzzz6b6upq3J3LLruMIUOG8K1vfYtnnnmGeDzOpEmTOOGEE7r9/UrPc83Miohsk3Ibm6NMZn8H3GxmCaAPcDBwfY+8shpAiYh02amnntqiicSIESN4/vnnC55bU1PT5vOMHz+exsbGgve98MILrY4999xzrY7ddNNNHYUrvZDWzIqIbJtyG5uLuTXP/cAMYISZVQHfJtiCB3e/1d3fMLMngQVAGrjD3RcWK54WNDMrIiJS8oJkVtmsiIgUVsxuxh3u0Ovu1wHXFSuGNpkBpjWzIiI96NVXX+Wcc85pcayiooIXX3wxooik1AUNoKKOQkRkx9Xbx+Yoy4yjFUtoax4RkR40ZcoU5s+fH3UY0oton1kRkeLq7WNzlN2MoxWLq8xYRESkhGlmVkRE2lO+yazF1QBKRESkhGnNrIiItKd8k1nNzIqIiJS0tLbmERGRdpRvMmsxNYASEdlOAwYMiDoEKQPBmtmooxAR6R3KcWwu32RWM7MiIiIlTWXGIiLSnvJNZi2umVkRkW60dOlSZs6cyb777svMmTNZtmwZAL/5zW+YPHkyU6dO5aijjgLgtdde46CDDmLatGnsu+++vPPOO1GGLiUqnQblsiIi229HH5u1NY+ISG/2xJWw6tXufc5RU+CEa7b5YV/60pc499xzOe+887jzzju55JJLeOSRR7j66qt56qmnGD16NBs3bgTg1ltv5dJLL+Wss86ioaGBVEoXF6W1tLbmEZHeSGNzjynfmdlYPLjkKyIi3eL555/nzDPPBOCcc87hueeeA+Dwww/n/PPP5/bbb88OjIceeig/+MEPuPbaa1m6dCl9+/aNLG4pXa6teUREumRHH5vLd2ZWDaBEZEewHVdpe4qZAcGV3hdffJHHHnuMadOmMX/+fM4880wOPvhgHnvsMY477jjuuOMOPvKRj0QcsZQazcyKSK+ksbnHlPnMrJJZEZHucthhhzF79mwA7rvvPo444ggAFi9ezMEHH8zVV1/NiBEjWL58Oe+++y4TJ07kkksu4aSTTmLBggVRhi4lKmgAFXUUIiK9144+NpfxzKwaQImIbK/a2lrGjBmT/f7yyy/nxhtv5IILLuC6665j5MiR/PKXvwTga1/7Gu+88w7uzsyZM5k6dSrXXHMN9957L8lkklGjRnHVVVdF9VakhLmDo2xWRKQzynFsLt9kVjOzIiLbLd1Gz4G//OUvrY499NBDrY59/etf5+tf/3q3xyU7lrT2mRUR6bRyHJvLuMw4Aa4GUCIiIqUq7WjNrIiItKl8k1mLaWseERGREpZZM+tKaEVEpIDyTWZVZiwiIlLSMjmsclkRESmkfJNZNYASkV5MM1XbTp9Z75MpMVapsYj0Bhpntl1XP7PyTWY1MysivVRlZSXr1q3ToLkN3J1169ZRWVkZdSiRMrOxZvaMmb1hZq+Z2aUFzplhZtVmNj+8RdbOsjmZjSoCEZHO0di87bpjbC7fbsYWVwMoEemVxowZQ1VVFWvXro06lF6lsrKyxZYFZaoJ+Iq7zzOzgcBLZva0u7+ed96z7v7JCOJrIZPEanseESl1Gpu3T1fH5vJNZjUzKyK9VDKZZMKECVGHIb2Qu68EVoZfbzazN4DRQH4yWxIyMxya6BCRUqexORrlXWasNbMiIlKmzGw8sB/wYoG7DzWzV8zsCTPbp43HX2Rmc81sbrFmIjIzs1ozKyIihRQtmTWzO81sjZkt7OC8A80sZWanFyuWwi8cb7E1z5pNdbz3wZYeDUFERCQKZjYAeBD4srtvyrt7HrCbu08FbgIeKfQc7n6bu0939+kjR44sSpxaMysiIu0p5szsXcDx7Z1gZnHgWuCpIsZRWF6Z8Q+feov/vH9ej4chIiLSk8wsSZDI3ufuD+Xf7+6b3L0m/PpxIGlmI3o4TADSaXUzFhGRthUtmXX3OcD6Dk77T4IBdU2x4mhT3tY8NXVN1Nar7FhERHZcZmbAL4A33P3HbZwzKjwPMzuI4HeFdT0XZbPsPrPq1ygiIgVE1gDKzEYDpwIfAQ7s4NyLgIsAxo0b1z0BxOKQbh4dU+6kdOVXRER2bIcD5wCvmtn88Ng3gHEA7n4rcDrw72bWBGwFPusR7TWR0j6zIiLSjii7Gf8EuMLdU+EF4Da5+23AbQDTp0/vnhHNYi1mZt1dg6WIiOzQ3P05oN1B191vBm7umYjalxmXNTqLiEghUSaz04HZYSI7Avi4mTW5e8FGE90ub81sKu25E7UiIiISMXUzFhGR9kSWzLp7diMmM7sL+EOPJbIAsUSLbsYp12ApIiJSSlxlxiIi0o6iJbNmdj8wAxhhZlXAt4EkZNfkRCuvAZS7k1LvfxERkZKRGZaVy4qISCFFS2bdfdY2nHt+seJoU34DqLRrHzsREZESktbMrIiItKOY+8yWtrwGUEEyq8FSRESkFLh7dkZWF5tFRKSQ8k1m8xpApdXNWEREpGTkDskR7QwkIiIlrnyT2bw1s2lHa2ZFRERKRO4FZuWyIiJSSPkmswW25tFgKSIiUhpyry+rckpERAop42Q2oTJjERGREpU7JqtwSkRECinfZDavAVRaW/OIiIiUDNfMrIiIdKB8k9lWZcZakyMiIlIqWq6Z1QAtIiKtlW8ym98AKu2kNFiKiIiUBJUZi4hIR8o3mdXWPCIiIiUr3WJrnujiEBGR0lW+yazFAc+OkKlwc3aVMomIiETPW8zMamwWEZHWyjeZjcWDP8PZ2XR4CVilTCIiItHT1jwiItIRJbPpJoDsell1NBYREYleywZQEQYiIiIlq3yTWQuTWc/MzAbf6uqviIhI9NIqMxYRkQ6UbzKbX2YcDpQaL0VERKLXcp/Z6OIQEZHSVb7JbN7MbKa8WNvziIiIRE8zsyIi0pHyTWazM7NBfXHmqq8GTBERkehpax4REelI+SazFr51b1lmnFYtk4iISORyx2NtmyciIoWUbzKbt2Y2pa15RERESobWzIqISEfKOJlNBH+GW/NkrgBrax4REZHoac2siIh0pHyT2fytebLdjDVgioiIRE3JrIiIdKR8k9n8MmNXN2MREZFSoQZQIiLSkaIls2Z2p5mtMbOFbdx/lpktCG//MLOpxYqlcICZmdmwm3Hwh9bliIiIlIDcSiklsyIiUkgxZ2bvAo5v5/73gKPdfV/ge8BtRYyltVj41tPqZiwiIlJq0i0aQGlsFhGR1hLFemJ3n2Nm49u5/x85374AjClWLAXlrZnNlBdrwBQREYme1syKiEhHSmXN7IXAE23daWYXmdlcM5u7du3a7nnFnDWz7p4tYdLErIiISPTSKjMWEZEORJ7MmtkxBMnsFW2d4+63uft0d58+cuTI7nnhnK15chNYbc0jIiISgU0r4RfHwdt/BPL3mdXYLCIirRWtzLgzzGxf4A7gBHdf17Mv3twAKjeB1dY8IiIiEUg3wfIXoGZV8G2LMuOoghIRkVIW2cysmY0DHgLOcfe3ezyAnAZQuQOmtuYRERGJQDwZ/JluCv7QzKyIiHSgaDOzZnY/MAMYYWZVwLeBJIC73wpcBQwHfmpmAE3uPr1Y8bQOsLkBVO7MbGaLHhEREelBmeU/qUwyqzWzIiLSvmJ2M57Vwf3/BvxbsV6/QzkNoNQxUUREyoGZjQXuBkYBaeA2d78h7xwDbgA+DtQC57v7vKIHl+1l0Qjk7zOrsVlERFqLdM1spHJmZnNnY5XMiojIDqwJ+Iq7zzOzgcBLZva0u7+ec84JwJ7h7WDgZ+GfxZUpM04FyWzLMuOiv7qIiPRCkXczjkxON+PcdbLqZiwiIjsqd1+ZmWV1983AG8DovNNOBu72wAvAEDPbpejB5YzLAOm0qqZERKR9ZZzMZsqM0+qYKCIiZcfMxgP7AS/m3TUaWJ7zfRWtE97u3wM+pgZQIiKybco3mbXwrXuqxdVfrcsREZEdnZkNAB4Evuzum/LvLvCQVoNjt+8BH4sFY3O2zFgNoEREpH3lm8zmNIBSmbGIiJQLM0sSJLL3uftDBU6pAsbmfD8GWNETsRFL5MzMqsxYRETaV77JbFtb82i8FBGRHVTYqfgXwBvu/uM2TnsUONcChwDV7r6yRwKMJQuWGSuXFRGRQsq3m3HOzKxrXY6IiJSHw4FzgFfNbH547BvAOMjuA/84wbY8iwi25vlcj0UXTxQsM9bYLCIihZRvMpudmU3nzcxqwBQRkR2Tuz9H4TWxuec4cHHPRJQnp8zYtWZWREQ6UL5lxtmZWW3NIyIiUhJiSUiHM7PaA15ERDqgZDad0tVfERGRUhBPQqpQA6ioAhIRkVJWvslsiwZQzYc1MysiIhKRWFz7zIqISKeVbzKbuzWP1syKiIhEL6fMuEXVVFTxiIhISSvfZDZnZlalTCIiIiUgnszpZtx82HWhWURECijfZDY7M5tW+38REZFSEItDOgXkrZnVlWYRESmgfJNZC9+6q8xYRESkJOR2M1bVlIiIdKB8k9lYuMVuuqnFgKkGUCIiIhHJKTN2NYASEZEOlHEy29wAquW6nGjCERERKXuxRMEyY43NIiJSSPkmsy225tHMrIiISORiiZwy4+bDmpkVEZFCyjeZzW0ApTWzIiIi0WvRzVhb84iISPvKN5ltsTVP82ElsyIiIhGJJSDdBLTcjkdjs4iIFFK+yWwsfOvpFCl1TBQREYleTjKrfhYiItKRoiWzZnanma0xs4Vt3G9mdqOZLTKzBWa2f7FiaZPFg5lZrZkVERGJXhtlxtpnVkRECinmzOxdwPHt3H8CsGd4uwj4WRFjKSy8ApybwLou/4qIiESjjZlZ5bIiIlJI0ZJZd58DrG/nlJOBuz3wAjDEzHYpVjwFxeLh1jwqMxYREYlcLKk1syIi0mlRrpkdDSzP+b4qPNaKmV1kZnPNbO7atWu7LwKLg6dbDJIqMxYREYlIPNFcZqyqKRER6UCUyawVOFZwtHL329x9urtPHzlyZPdFEIsFDaDSzYd09VdERCQibTWAiigcEREpbVEms1XA2JzvxwArejSCTAMolTKJiIhEL5aEdIEGUBqbRUSkgCiT2UeBc8OuxocA1e6+skcj0JpZERGR0hFPQiqzZrb5sMZmEREpJFGsJzaz+4EZwAgzqwK+DSQB3P1W4HHg48AioBb4XLFiaTvIYGY2pa15REREoheL55QZa2ZWRETaV7Rk1t1ndXC/AxcX6/U7JZYIZ2abD6nJhIiISERalBk3H9bQLCIihURZZhy9sAFUusXMbITxiIiIlLN4EjwN6eadBhIxazFOi4iIZJR3MpspM1Ypk4iISPRiYcFYuilbKRWPmboZi4hIQeWdzIYNoFLay05ERCR62WS2MVtmnIiZLjSLiEhB5Z3MhjOzuQlsSgOmiIhINOLJ4M9UYzaBjcdMa2ZFRKSgdpNZMzs75+vD8+77UrGC6jEFZma1LEdERErZDj02x8JkNqc5Y0wzsyIi0oaOZmYvz/n6prz7LujmWHqexcHTpHL3slM2KyIipW3HHZtj8eDPdCPuTswgZkpmRUSksI6SWWvj60Lf9z7hfnauBlAiItJ77Lhjc16ZccyMmKlqSkRECusomfU2vi70fe+TV2YcM23NIyIiJW/HHZuzZcZBA6hYzDAzNWcUEZGCEh3c/yEzW0BwpXf38GvC7ycWNbKekLc1TyIe08ysiIiUuh13bM52M06FM7PBhWYNzSIiUkhHyeyHeySKqIQzs5lBMqkmEyIiUvp23LE5Hv5akmrE3cIyY43NIiJSWLvJrLsvzf3ezIYDRwHL3P2lYgbWIzINoMIy42RCM7PnMPuOAAAgAElEQVQiIlLaduixObfMOJ3MSWajDUtEREpTR1vz/MHMJodf7wIsJOiUeI+ZfbkH4iuuWKzFmtlELKY1syIiUtK6Mjab2Z1mtsbMFrZx/wwzqzaz+eHtqm5/A+3Jlhk3kXawsJ2VLjSLiEghHTWAmuDumQHvc8DT7n4icDC9vf0/BDOz6SbS7phBPIaaTIiISKnryth8F3B8B+c86+7TwtvVXQt1G2XLjJuauxnHtGZWREQK6yiZbcz5eibwOIC7bwZ6/xxmLAGeyg6Yca3LERGR0rfdY7O7zwHWFy+0LmrRzVj7zIqISPs6agC13Mz+E6gC9geeBDCzvkCyyLEVX3ZrHohb0P5fZcYiIlLiij02H2pmrwArgK+6+2uFTjKzi4CLAMaNG9cNL0tembFrzayIiLSro5nZC4F9gPOBM9x9Y3j8EOCXRYyrZ4QNoNLuxGIQj2kvOxERKXnFHJvnAbu5+1TgJuCRtk5099vcfbq7Tx85cmQXXzYUD3PxVGbNrGGmJUAiIlJYR92M1wBfLHD8GeCZYgXVY8IGUOl05uov2T1nRURESlExx2Z335Tz9eNm9lMzG+HuH3TleTstOzPbiOeUGWtoFhGRQtpNZs3s0fbud/eTujecHmZx8BQpd+IqZRIRkV6gmGOzmY0CVru7m9lBBBVc67b3+bZZbplxmuyFZq2ZFRGRQjpaM3sosBy4H3gRsKJH1JPCNbPptBOLGbGYkVY2KyIipW27x2Yzux+YAYwwsyrg24TrbN39VuB04N/NrAnYCnzWe7LGN1tm3NwAylADKBERKayjZHYU8FFgFnAm8Bhwf1vNIHqdWALSTcHMbExXf0VEpFfY7rHZ3Wd1cP/NwM3dEeR2yXYzbrlmVteZRUSkkHYbQLl7yt2fdPfzCBpLLAL+GnZR7P1iifDqL9l1OSmNmCIiUsJ26LE5Fg/+TDcFa2ZjmTWzGptFRKS1jroZY2YVZnYacC9wMXAj8FBnntzMjjezt8xskZldWeD+cWb2jJm9bGYLzOzj2/oGumTAzrBlDaQa1f5fRER6ja6MzSWtVZmxEYuhBlAiIlJQRw2gfgVMBp4AvuvuCzv7xGYWB24hKIWqAv5lZo+6++s5p30TeMDdf2Zmkwg2fh+/bW+hC4aMg3QT/es/IB6La2seEREpeV0Zm0tetsw4UzWVudCssVlERFrraM3sOcAWYC/gErNsjwkD3N0HtfPYg4BF7v4ugJnNBk4GcpNZBzLPMZhgg/aeMyTY5H1Iw0piNlZb84iISG/QlbG5tGW7GadIu2MWrJtV1ZSIiBTS0T6zHZYht2M0QbfFjCrg4LxzvgP8MVzn0x84ttATmdlFwEUA48aN60JIeYbsFvzRsJJYbGzQzVgDpoiIlLAujs2lLR7+WpJqxF1b84iISPuKOSAW2iogfzSaBdzl7mOAjwP3mFmrmNz9Nnef7u7TR44c2X0RDh4DwJCG1c37zCqbFRERiUaLMuPM1jxaMysiIoUVM5mtAsbmfD+G1mXEFwIPALj780AlMKKIMbWUrIQBoxjauDLYZ1ZXf0VERKKTLTNuam4ApTWzIiLShmIms/8C9jSzCWbWB/gs8GjeOcuAmQBm9mGCZHZtEWNqbchYhjWuyg6Y2ppHREQkItluxs37zCqZFRGRthQtmXX3JuBLwFPAGwRdi18zs6vN7KTwtK8AnzezV4D7gfO9p9sJDxnH8MZV2TJjjZciIiIRMQOLQ7ox2GfWgkMam0VEpJCOuhl3ibs/TrDdTu6xq3K+fh04vJgxdGjIOIY2PULC0sRjRkMqHWk4IiIiZS2WCMuMUdWUiIi0a8ftiNhZQ8aRIMVwNmBaMysiIhKteDIsMw5mZmMxjc0iIlKYktlwr9ldfA1xbc0jIiISrVgi7GasNbMiItI+JbPhXrO7pldpax4REZGohWXGmTWzgC40i4hIQUpmh06ggSQTUkt09VdERCRq8SSkGltszdPTvSFFRKR3UDIbT1CVHM/4pneJGWoyISIiEqVYMmgAlc40gNLMrIiIFKZkFliSmMD4pveIq/2/iIhItGLxsJuxYxYktI4GZxERaU3JLLAkMZFB6WqGpteTUjYrIiISnbDM2MOtecyMtHbNExGRApTMAu/GJwAwpmGx1syKiIhEKVNm7E4sRlhmrLFZRERaK8tktqEpzcL3q/mgph6Ad+PjARjbsFjdjEVERKKUU2bc3AAq6qBERKQUlWUyu25LPZ+86Tmefn01AJsZwAfxnRhdv1hNJkRERKKU7WYc7DNrmpkVEZE2lGUy278iAUBNXRMQDJJVFbuza91idTMWERGJUiwJ6cbsPrPaNk9ERNpSnslsnyCZ3VwfJLOptFPVZ3d2alhOMl0XZWgiIiLlLZaAdIp0tgEU6mUsIiIFlWUyG48Z/fvE2VLfPDO7omJ3YqQZn14ecXQiIiJlLJ4Iy4ybZ2Y1MSsiIoWUZTILMKAykVNmDCsq9wBgd38vyrBERETKW1hmnFkzq27GIiLSlvJNZisS1GRmZtPOuj67Uh/ry57pJdEGJiIiUs5iCUg3ac2siIh0qHyT2cpk85pZd2LxOGsqJ7KnL4k2MBERkXIWT0CqeWseMyOdjjooEREpRWWbzA6sSFBT1wgEDaDiZqzutyd7shQtzhEREYlITplxtgGUxmURESmgbJPZ3DJjd4jFgmR2ELVQrSZQIiIikagcDFvWkk6nMSNcMxt1UCIiUorKN5nNaQCVSgfrctb02yu4c+GDEUYmIiJSxnaZCnXV7JJeRcws6GaszXlERKSA8k1mc2ZmU+7EY8aqgfvwJ58Of/ouvPZwxBGKiIiUodH7A7BnahExCzoaa2ZWREQKKftk1t3DjomGxeJclroEdp0Gf7wq6hBFRETKz8gPQ7yCvVPvhDOzWjMrIiKFFTWZNbPjzewtM1tkZle2cc5nzOx1M3vNzH5dzHhyDahMkHbY2pgKy4yNeAzqPAlTZ0H1MtiwtKfCEREREYBEHxg1mb3Ti8N9ZjUzKyIihRUtmTWzOHALcAIwCZhlZpPyztkT+DpwuLvvA3y5WPHkG1CRAKCmrinoZhwLBsxU2mH8kcFJS57tqXBEREQkY9f92Tu9mDjpsAGUslkREWmtmDOzBwGL3P1dd28AZgMn553zeeAWd98A4O5rihhPCwMrg2R2c31Ttv1/9urvyA9Bv+Gw5LmeCkdERKTozOxOM1tjZgvbuN/M7MawomqBme3f0zECsOt+9GcrOzdWhfvMKpkVEZHWipnMjgZy97ipCo/l2gvYy8z+bmYvmNnxRYynhdyZ2bQ78ViQ0AKkMRh/BLz3rPacFRGRHcldQHtj7QnAnuHtIuBnPRBTa7vuB8DYujfCfWYjiUJEREpcMZNZK3AsfzhKEAyYM4BZwB1mNqTVE5ldZGZzzWzu2rVruyW4bDJb39RizSyE5Uzjj4RNVbBuUbe8noiISNTcfQ6wvp1TTgbu9sALwBAz26Vnossx8kPU0I/xtQvDrXlERERaK2YyWwWMzfl+DLCiwDm/c/dGd38PeIsguW3B3W9z9+nuPn3kyJHdEtyAyuZkNu1OLGZYODObcoc9PwaJvvB/Z8PmVd3ymiIiIiWuM1VVxReLsYC9GLdlodbMiohIm4qZzP4L2NPMJphZH+CzwKN55zwCHANgZiMIyo7fLWJMWQMrkkCmzBji4ZpZCMuZhu4GZ/0GNi6H+06HpoaeCEtERCRKnamqCk4sQtVUrpdtb3aqe5e+qRolsyIiUlDRkll3bwK+BDwFvAE84O6vmdnVZnZSeNpTwDozex14Bviau68rVky5cmdmgzJjsmXGqUyjiQlHwqduh1Wvwt+u6YmwREREotSZqiqgOFVTueb7XsRwRm95TVvziIhIQUXdZ9bdH3f3vdx9d3f/7/DYVe7+aPi1u/vl7j7J3ae4++xixpOrf0UcgE1bGwGIxZpnZltcAf7QJ2C/s+G562H16z0VnoiISBQeBc4NuxofAlS7+8ooAnnF9yRNnLE1C/ASmpl9Z/Vm/rHog6jDEBERipzMlrKKRJw+8Rib6oJkNrfMOJ3OO/mj3wOLwSv3tzj87toaTvvp36kOE2LpHiurt3LdU29qKwYRkW5mZvcDzwN7m1mVmV1oZl80sy+GpzxOsNxnEXA78B8RhcoWr2B1vz0Ys3l+Sc3M/vSvi/n6w69GHYaIiFDGySwEpcbVLWZmg+Ot1ub0GwZ7HAsLH2yR6b76fjXzlm1k0ZrNPRVyWfjzG2u45ZnFrKjeGnUoIiI7FHef5e67uHvS3ce4+y/c/VZ3vzW839394rCiaoq7z40q1rTDO0OPYtymeezN0qjCaKW2oYmtDamowxAREco9ma1IsGlrE0C4NU+BMuOMyafDpvdh2fPZQ3WNwWC2fotmZrtTYyod/llCl+JFRKRHpd15adSnqY/35+L4Q1GHk1XflKYhlV/CJSIiUSj7ZDYzMxuP0XJrnnx7nwDJfvCPm6C+BoC6xmAw27BFnY67U0NTusWfIiJSftyhITmY+buewSfi/8RXvxZ1SADUN6Y1PomIlIjyTmYrE9k1s7kzswX7TFQMgCMug7efgFsOhvXvsTUzM1urZLY7ZX5JaNSVbxGRspX2YKeBV0afSY1X4nP+N+qQAKhvSlGvZFZEpCSUdTI7MGdmNmbNa2ZTbXWaOPq/4II/QsNmePBCGurrAc3MdrdMEqtfFkREyleQzBoNfYZwd+pj2GsPwdq3ow6L+qY0qbS3/buCiIj0mLJOZgdUJqiuzZQZW7bMuN3N2ccdDJ/8Cbz/EvsvvQOA9Upmu1V9SjOzIiLlLu3B8h8z446mj0OyLzx5JdS33XRx+fpa1m6uL2pc9VoKIyJSMso6md1j5AA214cNoGJGvK2tefJNPg0mn87BK+5hJzawQWXG3UprZkVEyltmX9mYgRmsZxBNx3wb3n0Gfn4UbFpR8HEX3PUvfvD4G0WNrb4pWGKkMUpEJHplncweseeI7Ncxg1j4abQ7M5vxkW8S8xSXJB7SzGw3a9TMrIhIWctU8MZy9oBvmv55OO8PQSL79LdbPaamvol31tQU/QJzfdj8sT6l7XlERKJW1snslNGDGViZACCeM2AW7Gacb9gEnh96Ip+NP8MF638CKxcUM9SyoplZEZHyls6ZmW2xB/z4w+HQi+HVB6DqpRaPeWvVJqB527xiUZmxiEjpKOtkNhGPcdjuw4GgzDiTzHpnklng4SGf4+HUEcxs+hv8/Ei4/0xo2FK0eMtFZn9Z7eMnIlKeMsms5VxozlZNHXEZ9N8JHrywxYXk11dkktnijh2ZMmM1KRQRiV5ZJ7MAR+wRlBrHc7bm6WyDwvXpfnyt6YscXHczqaO/Dm89Bn/+XrFCLRuamRURKW+eU2bc3JwxvLNiIJxxLzTVwR0z4bGvwKaVvL4ySGaLmWS6u2ZmRURKSNknszP23ok+iRgjB1Z0vDVPnsw+s5voz/rpl8GBn4cXb4VlLxQr3LKQ/UVBM7MiImWpUJlxi6qpcQfDF5+Dfc+Al34F936KN1dsBKC+iGXGTWnPJtpKZkVEolf2yezYYf2Y+81jOXLPEa1LmTqQW8q0obYBjv0ODB4Lv7sYGrcWIdrykG0ApV8URETKUqEGUK2uM/cfASffDKf9HNa8xp6rnwCKOzOb+9y64CoiEr2yT2YBBlUmW67L6eT4VNeYon+fOBDuNVsxAE66EdYtCjotrlwAqWAf25Nufo57X1halPh3NA2amRURKWvNa2aDW+6xViadSt3IqVwSe4ChfVJFbQCVO+urmVkRkegpmc3RvGa2czOz9U1pdhnSF4ANme15dj8G9j8X/vnzoCnUXZ/AG7bw6vvVvLWq7Y3epVlDdmueTi5eFhGRHYqHeWLumtk2h+ZYjFcnXc4Y+4CvD3qquMls7sysklkRkcgpmc2Rufrbqa15CGZmdw2T2fW5+9p94scw6//guB/A8n+Svv9MdmMlWxqaujvkHVKmzFidIkVEylOHa2bzVA2ZzqOpQzl1y/9xWGouvPvXzpdZbYPccUljlIhI9BJRB1BKtnVrnrrGFLsOrgRyZmYB4knY+/jg6z4DiD3+Vf7S528sXHIwvP0VGHcIVA7q1th3JJmr3Y0qMxYRKUvZZDbWzprZHFvqU9zYeDYfS77C7cnr4O7rYMJRcOrPYdCu3RZXZlue/K9FRCQampnNkSkz7mwOVdeYZmBlggEVCdZvaSx80gHnseL8f3FT6lTG170Jv/40XDMOnrgS0hoIC8mUGauES0SkPGUS16CfReZY29ns1oYUaxjKbyb/nM83XE79x34IVS/BLz8ONWu6La76RpUZS/l6cuEqzrpDO3ZIadHMbI4Om0zkcHfqmlJUJuMM7Z9k/Zb6Ns+tSQ7n+qbTeXH0efz6o03w+u/gxZ/BxmXwqTugT7/uegs7BM3MioiUN88pM7ZO7DSQWcbTuNMUnk7Hqdn3WCrGHQC/OhFunwl9h8DmlRDvE2zp02/YdsWlbsZSzuYv38jfF62jKZUmEdd8mJQG/UvMEc92M+44ma1vSuMOlck4Q/r2oXprGzOzNA+y1Y1x2ONYOOkmOOE6ePsJ+NUnoWZt0NninT9BvZpENWhDehGRspa7NU94nbntBlAEM7MViRj9wh0G6prSMGY6fPY+GLQLDNgZJh4Dm96HhQ9ud1y5pcUao6TcZP79a724lJKiJrNmdryZvWVmi8zsynbOO93M3MymFzOejsRiHa/LyciUGlUkYgzum2w3md3aEPzw1zbklBUffBGccR+sfh3umAkPfR7u+xQ8cQU0bIHHvxZs7VOGMjOyuuotIlKeWjaA6qCbMcFF4/4VCSqTQTKb3UJn94/AhX+Es38Ln7odRk2Bl+/d7rhUZizlrC7891/MjuEi26poyayZxYFbgBOAScAsM5tU4LyBwCXAi8WKpbNinShlyqgLr05VJuMM7ptkY3szs/XBzGxtfjfjD30czn8MGmvh1d/ATpNg/q/hgXPhn7fBr8+Azau38930XpqZFREpb837zBqxWMtjhdQ2pOibjFOZDE6ua2xj/Jh2NqycD6sWbldc2ppHyllmZrZO//alhBRzZvYgYJG7v+vuDcBs4OQC530P+CFQV8RYOiWWszXPBzX1fObnz7N03ZaC52auSvVNxhnUN8mm9mZmw3Nr6wtcyRpzAFz0Nzj3d0FiWzEQFv0JJp8OdRvhxv3g2gnwwq1de3O9SPM+s/rPUkSkHHlOmXFnLjTX1qfoXxGnIhHOzLbVaXjfzwTrZn9/Kax8JSg5Xv16p+NqUWasMUrKTKYyoV4zs1JCipnMjgaW53xfFR7LMrP9gLHu/ocixtFpmW7G7s4L767jn++t59H5Kwqem7nqm5mZrd7a2OaWPlvCJLa2MVX4nMGjYeKMoCHFx6+DKZ+GU2+FMx+AfT8NoybDk1fAU/8vGOE3rwoG4U5uIdSbuDuNqeB96aq3iEh5ShdsANX2+bWNKfr1SVDR0cxsv2Fw2m2w9k34+VHw2wvgZ4fC3acEF5I7GFe1z6yUs+zMbFs/XyIRKGY3YytwLDtKmFkMuB44v8MnMrsIuAhg3Lhx3RRea5mrv6k0vLUqaMQ05521/OfMPVudm5mZrUwGa2YbU87WcDDNlykvTqWdhlQ6e+W4oKmfDW4AE44MbukUPHklPH8zVC+Hxc9A/SYYMg6OuAz2OxfiXf+r/PMbq7nxL4t46N8Pyyb2PS33SncmqRURkfKSbjEzG3zd3h7wtfVN9OvTPDNb194esPucCqP2hcV/gV2mwZJng6U9934KRuwFB/4bTJ1VcD/43BkpXXCVcpNJYrXHspSSYs7MVgFjc74fA+ROcw4EJgN/NbMlwCHAo4WaQLn7be4+3d2njxw5smgB527Nk0lm5y3byOa61iXEzclsnCH9kgBtNoHKbfxUsNS4I7E4nPBDOOgLwbY+wybCiTfAwF3gD5fB7cfAusXb/rx5Xqmq5pXlG6mpa+r45CJp0HokEZGy17xmNrefRdvnb2kILiZn1szWdzRzNHx3OOjzMPZAOPJyuHQBnPpzqBgET/wX/O+HgvF18V/g3b9CQ23wvOG41K9PXDOzUnY0MyulqJgzs/8C9jSzCcD7wGeBMzN3uns1MCLzvZn9Ffiqu88tYkztGtqvDwDvb9jKW6s3M2pQJas21fGPxes4bp9RLc7NLH7PzMxCkMzuMrhvq+dtkcw2phi6PcGZwQnXwoc/CWMOhGRf2P88eOPRYO3PLQeDxYLbsAlBGdWoKcFjt3wQnN+nf1BCZYVnXTONqrY0NDE4TNB7Wu5srNYjiYiUlw1bGuiTiNEUjgXxWPPWPO2tmd3aEMzMZrsZb+vMUaJPc2XU+/PgX3fAy/fB3DuD+weNgcmnMeOdt/iTHcyyyqm64CplRzOzUoqKNjPr7k3Al4CngDeAB9z9NTO72sxOKtbrdsWuQ/oycUR/nly4imXrazn9gDH07xNnzttrW52b2W6nIhHPJrMba9uamW2e6awNE8ZFazZz9/NLti1AM5hwVJCYZr6fdDJ84Vk46CI4+Atw4IWwdQPc9xnYtALWvgU3HQB3fBQ2LIHbZsCfry749M1dl6P7T0ozs9LbNTSl+czPn+dfS9ZHHYpIr7J4bQ37fe9p/vj6KlZUbwVg1KDK7JrZ9rfmyTSA6uTMbHtG7w+n/BS+8iac93v47K+h31B4/mZ2W/93ft3nv7kx9d98/83j4Y3fNz8unQ6WBYnsoDQzK6WomDOzuPvjwON5x65q49wZxYyls2bsvRN3/v09ACaPHsShu49gzjtrcffsgArNP9CZq8DQyTLj8Otf/WMp97ywlM8eOI4+iS5eUxgyFo7/QfP3Uz8Ldx4PNx8IicpgtnbtG8HsbVMdrHkjKFnevBL6j4DBY4Dgl4EgxujKjHM7GGtmVnqjD2rq+ed763l52QYOHD8s6nBEeo2xQ/sRM3hv7RZGDAzGoXHD+rF+SwPQ0cxsir7J5n1m210z21n9hgUXkAH2/jikGrnpDy+z/8vfYN/0ErbEB9L3D5fD+CMglgjW3NZVwzkPw6Bdu/76IiVGM7NSioq5ZrZXmrF385rcvUcN4ui9RrB8/VaWrKttcV5+AyhoL5nNmZkNE8bFa2sA2FRgPW6XjZoCFzwFk04JBuNzH4GPfR8wOP4aSDXAgxfC7R+Bm6bDs/8LqabszOzWLVuaL4G/92yQ/PZQ5+TMGqSY9a6tea747QKeeHVl1GFICcj8vG9t6D3/fkVKQZ9EjDFD+/HeulqWraulIhFj5MCK7JrZtoYhd2dLQ1OLmdm67t46xAwSfdhEf74av4ILh/+KG0d+B2rXBZVQd58MVXOhugp+eQLM/WVQHSWyA8kksV2qfBDpZkWdme2NDpowjL7JOI4zblg/jtwzSG6ffWctE0b0z56XuTrVNxknGQ6ebe01W9uQImZB84rML7qZZLZ6ayMjBlR0/xsZNRlOuaX5+12mwoGfD9YFLf0HvPEobyQ+TMWQXZj456vhrScYXH8R02wl+//2C7DbIbDboc0lyaOmwKz/C7YRKqJMaXH/ikSvKTN2dx56uYo1m+s4YcouUYcjEavJbsUVXYWDSG81fkR/3vughvrGFOOG9cPMiIWX3XNnZh95+X0GViaY+eGdqW9K4w59c9fMFumX7fqmFBWJOH3iMRbFJsJxP4AXboH6mqCB1LAJwcXiP3w5eMDOU2Cvj8G0s4KmUyK9WGdmZm+f8y4vvreeO85r1c9VpCiUzOapTMb56KSdWbelnnjMGD+iP+OG9WPO22s599Dx2fNyuxn3TcaJWTszs/UphvWv4IOaemobUmyqa2T1pnqg7QS4KBJBgys+ejU+ZDfOnDONwydO5Oajz4LHLudHdV+grk+Spvhgkov/Aouehg+fGOyB+6fvBqXL5zwEI1pvVdRdMrOxAyoSvWZmtr4pTWPKmb98Y6ty9CgsXlvDjX9+h+tOn9r1EnbZZpl18VsjXHsu0ltNHNGfeUs30JQKLihD7j6zjrvz/cfe4BfPvcfUMYOZ+eGds1VF/fskSMSCrXy6pcy4gPqmNBXJGH0SseCC6yFfDG65Lpkf7GP79lPwzh/huZ/AP28P1t5OODI4J52Cl+8J/tzn1KCKCoLp59ULIV4RJL+xdrbyE+lhnVkz+0rVRuYuVc8I6TlKZgv40aen4s1b4nLUXiN4eN77NDSls8lB5ge5MhknFjMG9U22ncw2NjFiQJ8wmW3i3bVbsve19ZiiGjaB2hnfYcMzTwVrkaacDhOO5nc3XMq4+ndYcejNnDS2DpY8B0f/F8STMPqAYD3QbTOCY30GBAPxB+/ATpPgEz8Kuj0+eQX03ylYi9tYC1M+DSP3hlRTsBeuO2xZCwN2KhhaZp1s/4oEqzfV9eCHsv0yv0htqG1k2fpadhvev4NHFNdf31rL7+av4NKZezJx5IBIYylHNSXQSE2ktxo/vB819U28s6aGQyYOB1puzTN36QZ+8dx7DKhIsGZzcFE487PWt08cM6MyGS/ezGxjmopEkMxmftYz5i3bQF1DisP2GAE7fTi4HfFl2Lgc7jsd7jkFxh4cHF/9Oiz7R/DAp74B0y8MxsjXHoaNy4LjA0bBrF8H428ZmbdsA/uNHRL5hWFpyd07NTNb25DK/l4k0hOUzBaQP5t11J4jufeFZby0dAOH7h4MrnVNKZJxIx7u5j64b7JVN+OqDbUM7puktj7F6KF9eXPVZmobUixaU5M9J5JkFtgYvm6msQYDRnINF7CmoZ5vxXeCiRNg4tHND9h1v6Br8m8vgKfDHl7D9wiaTb3xB5h9dlBetfTvQSOMpjrAgvW4A3eBzavgsC8F2wTNvw+mXwDH/Q8kK1vElVtm3FtmZnN/oZm/fGPkyeza8Be8/F+0pGdkfrHWzKzIthsfLuf+y/EAACAASURBVOdJpXNmZsP73J13Vgfj57Ef3ok/LFhJOu3Zn7n+fYJfaSqT8YIzs+7Buf0rtv9Xn9wy4/ylMNc//Tbrahp4/NIjWz5oyFj43BPwjxuDPWsXPhi8q5N/GizhefFWePFnQbPGicfAUf8VfP23a+FXJwXJ78ZlwWMatgTj5t4nBLsZjDsMPA0VO8aFy4XvV3PaT//B/Z8/JPv7VilZv6WBf7/3Ja4/Yxq7Dmm9FeOOLLcpZ3szs1vqm2hMefZnRaTYlMx2wqG7DycRM+a8szb7n+vWhhSVOT+kg/NmZlNp5+Sb/84p+42mtiGVXRdb25DKXk2GHi4zzrGxNkhi12WSWXK25mkrCRo8Gi54Eja9D031MHQCxGIw9Uy48zioXgYn3gDTzoZUPTTWBYN3dRXg8PcbgufZ49hg7773noUZVwYdl7eshUQFDRXHADCwF62Z3VzX/Hm9vGwjJ08r7rrijiiZjdaWTAOo7m5AI9JNzOx44AYgDtzh7tfk3X8+cB3BHvEAN7v7HT0R28QRzUlZJpnNNoAC3vughopEjH3HDOGR+StYX9uQ7UXRr08wJlckYgV/2X781VVc8eACXvjGTAZsZ0Jb39Q8M5s/Rm2obWj7AnW/YXDsdwrfd8pPYeZVEO/TXG4MsMdM+N3FwVi613HBsWT/YLxc+DDMuzt76tbdT+D93c9gj/o3YcmzwRi99/FQMThIdHeZGlRRlfhs58rqoCJrzebSrMx6c+UmXnxvPQuqqssumc39mepoZhagpq6JigFKZqX4lMx2wsDKJPuPG8qct9dyxfEfAv4/e+cd31Z9vf/31bTkvUecxHYm2SQhJGEEAmG1BcoolLYUCj9aCm2B0m+/bb8the4WOii7QEspq+wNIRuy93CG7XjvIduyJGvf3x9H90rySOxMWvy8Xnollq6urq6kez7POc95TiQ7ax6czB5o7qHD7aei1YXbHyTVZsZoUPD4g1S0uhiTYafW4dGfEwiF+eazW7nt3HHMGXv8x3l0R6rInW4/qqqiquCJLL7dh6ooKYo+ykdH4Ry48knorILZX5dtjCawJMKSe6PbzfqKSJaLz4aKZfD+D8UoIwYlE67HxjlMppINqp1QMIixcjlseATsWSJbHjUHkrLjj6G9QrLdUyJZ7L7w9Yhsuu0AzL4+fsFwlNCSAGajwo66rmO23yNFmytCZr0jZPZkIDqveeT8j+DTB0VRjMDDwBKgHtisKMpbqqru7bPpS6qq3n6ij68gLQGzUSEQUhmTqZFZeSwcVqlqd1OUmUh+qqh6WpxeffGskdkEs1F3xo/FgWYnLl+QFqeXpCNswfAFwyREemb7voazN3jkaqvkvIHv++qrA28f8MLBFdC6F3xOjOseY/zB96WimzdD/l3xy/jnZJTAzC/DhAtERZWQJjFz+X0yqm/8ElFh2TMlyZzYpzLqcchrWpNFDt1SCl9/C2zpR/aeB4CWaO/5lMYvbQLFZzFZHEtgD1mZjcQ+ty9E5n+HYGAEn3KMkNkh4uyJWdy/tIwddV28uaOBth4/CeaoHDnVZqahs1f/W2t+r+/00OsPYbcYsVuMePwhDra5mJKfQovTqwe+5m4vK/a3Mn1U6gkhs50RMhsMqzi9QUwGRR97cESL8KmXH36b8efF/P98+PYGqNskWWN7Fqz7K2M3Pso264vY6v3cYU3A8FtEspw6Ghp3wJ5X5PlJeVAwC0bPg6o1It0CWP9Q1GTjkz9B2VLJaG98TII1SBD/8kvoFpmHQjh82O20oDZ7TDrba7sIhMKYjSfPeGmkMnty4faNyIxH8KnGPKBCVdVKAEVRXgQuA/qS2ZMCk9HAmAw7B9vcjE7vawAFVe1uJuQkk5MiZLa1x0cgQirtEZmxVGb7//60RF+n2w/Z/R4eEnzBEKk2M9YByGx3bwCXL3hiYoA5ASZfIjfg5/XzaSjfwdP/dytGe4RcehwiQfY4oG4D7Po3rPyV3DS8dzcEeoU473s7/jWmflFagjLHQ/1mSUBrcdRkk9i85n648FcSK+s2wt43JXn8uQf6tRENBdqa6LiMLTwGcPZKXO35lB7f8YRvqJXZSAzs8X32ztEITg5GyOwQcfbEbO5fWsZX/rYBd2TUzriYzG7fyuymKiGzdY5egmGVRKsJu8VId2+Amg4PF0/LY1utWb8watLjYymt2VrTyQ1Pb+KjuxaRlxofVLp6o/Jih9tPojVaZT5hxjVGMxSdEf37wl9xsKWLTRXNWErOwFW5kWvnTcA69jRxVVYjwbJ5DzTvEiJc9oEYTy3+Pxh3Hrz+LfjXFTKGaMPDIrGqXSfyqssfkZm5H/4YVvwCzr5b9tG6V4KyOVGy0mNOh+4GCfh7XhMDjwlLpN933GKReNVtkn4lRdFJ4+TcRPZV1R6/cUtDxAiZPblwjxhAHRE+2NPE3KKMk/rb+YxgFFAX83c9cPoA212pKMrZQBlwp6qqdQNsc1xQnJWE0xvEFqm0apXZQChMrcPDkil55CTL96TV6dXH8dgjccwaU5lt6u7lmXU1/ODCSfq10RHTXjNc6AZQRgP+mAV9OKzqBMzZGyDzBH+Pa0IZrA3PpDNsJ0u7U1MgJWZB9kRRJXXWSAJ4zAJo3CYtP4v+R3p128uhZbeQUUcVbH5SKrAaMifA198WX4ysSbD857Dxcdm+7ANwtYgLc8gHfhdc9XdRajXvlmNp3g2rfgOTPid+G+1lkDUR0sfqL9EZqcxqa6NPG/TK7Ke0cnw8cSSV2RGM4ERghMwOEdMKUkm3m+n0BPR/EwaQGauR8ubmagcGJdowbzMbSbSY2NfUQyisMj4nKY4At0VIbKvTx7HC6rI2enxB9jU5+5PZGLMqh9sHRAPvSZNHGoxsnvJjfrR/N7cWjOPRsilccvb5ZCfHLAqKz5abBne7SKWMka/yTR/CC9fBhodR86YTuuEDTN21klk2WSRgN2yDT/4Ia/8sBLkv0ouhs1rIduFpEnxX/UYeSxsrrxlww2UPw6lfpdfj4lrjCr5Xtpx7E6oIPvJTmHY5LLgtLkifCITCauTz/PTKtP7bocn0R8js0OHyBfnWv7Zx5/kT+d75x2/01wiAqJ9SLNQ+f78NvKCqqk9RlG8BzwCL++1IUW4BbgEYM2bMMTvAu5ZMjEvsGiJstr6zl0BIpSQrkZwUjcz6dOKoG0DFVGbf2dnEY6sPcvmpBbS5hCj1NWscDrSeWavZGGeI0+ML6uqm7pNAZjXy53D7D50QSh8L6V+T/2eNhxlfij6WPVFuGs66C2o3gqMScibD6Pnx1dZz/w9K34DdL0vC95RLRQm15e/w0U/hyRpISI0qp0BUVat+LTcNOVNh1nVQt4HrK3dzkQVcFXNg10USjwvnCvH95E8S/3s7oXa9jA2ceoUQ5VAADq4Ex0E49auS9C59DdKLwNUqI44W/RBMg5ybgBfCwcMaaTkjcfWzmCw+VM+syycS+4LUhGjP7EhldgQnCCNkdogwGBR+eNFkQqpKh8vPHz8q6yczDoZV3P4QnW4/LU4fZ03I4uPydgASrUZsFiP7m3sAqerGk1mtMnvsyOzueunfrOv09Hsstorc4fLHOc6dzGxa7JzZ2L8HRWJW/N+2dPja67D5Sf7WMYN3n9zBm7efGX1cUaS/d84NsP9dqcIWLwKzTbLLpW/AgXclazzzWgmE1Z8IgVUUWP+wGGn0NEuF11HJZRue4lpzF12WKfyh+0vcnOshfctTktWedoX08JrtMGqu7M+aLJXg+s1Q+gZq2ftw9g9Q5t8qo4t2viiBe8wCIemmBHleSkH/9x8Owwf/KxKxs+6iu3Y3OWoHzWR+JoPtpwFaZXbEAGro0Prkmv9DxnH9h6MeGB3zdyHQGLuBqqodMX/+DfjdQDtSVfUJ4AmAuXPn9iXER4wpBSlMIUX/W6vMVraJk3FRViJWk5E0u5mWHq9ewdX+tZqNdEe+U9UdMgqvobOXdq0y6zmKyuwgbsaxZo4nY0qBVjE8mqpzPySkwsQLBn88ORe+u13im8UevX/hd8CWBuseksTwkl+IuZXRBKdeL5LnllLInSr/bnsWlv4EErNpNE3GpXZyuuMdeC3SL1y8SLbrdcDOF+S+pFyRRb//Q+kRbi8Hv6yvWPsXqRIbTBDyg8EM4YA4Qp95l1Skm/dILFYUqF4r8dhghHm3QEeF9Bx/7gFo2gUNWyRpfsrncbvdLDCUMqVhC6yILKFP/yZ01cDKX8OEC2HG1bIWad0fkWWr4HWK30da7E8vgt4ueX+Fcwcn28cbndXyHm1pg25yqMrsX5eX886uJpZ/fxGhsFwKXCOV2RGcIIyQ2WHg2nmSea5sc0XIbJQAptnNgJhRrDso64DLZo3SyazNYiLRYtJ/5CURMqs592lk9khmq6qqysfl7Wyo7GBuUTqLJ+eiqiq7G7oBqHP0J7Odbj9GgxKp5PlJtcnxG5STa1yjScMSI4uSI3I0NifAwttZ//dN7G/uQFXV+Hl1iiI9tdrwev15Njj9FrnFoiiGDE+5TP5tL4dHF8LHD9CYfhY/bj6Huy+7kYcf38C8BfNYdLlfTKu2/kOy1oNANSeyz5/NlA/+F+q3CEmu+QQpnvwxfuPC0yJVaQXcrWLm4e2GTY/L4007SN/3DqutBv4euoim3rvl/nBY3rOiSPZ5zytQOC8+Ax8LrU84HAY1JBXqUAAU49D6jD/j0H4/Iz2zQ4e2+G8dIbMnApuBCYqiFCNuxdcC18VuoChKvqqqkeZILgX2ndhD7Au5fle2CzEtjozvyU1OoMXpIydZqoW6AZTJQGskdtR0SPyr7+zV42znUZHZMNaIAVRYhWAojMloiCOwXSeDzPYdt3ei0DehDBJrZl8Pp35tYPfkWIVV8dlw+rckpmYUc//ft7K2o4PFRak8fWm2GE6t+CVYU+C2TUIKLXbIniyy5d3/ltg58xppNbImC8EtOQcu+YO4OluSJB4vvzcaj812SSqrKuTPgHn/T8ju2j9DYjb4XPCXWaLC0rD0J9yNFZvFLb+chsh72/kieLskTlYsgw9+CCmjoLuPMt9sl0p4+Uey3ig5V7w/Vv1OpkEkpMkaY+KF8rg9U25Gi/xriHEGHsjPo2kXNO2QJITHIcmC0fOij6uqJNlDfvlsElIkib/2L1L1tmfBFY/LuRsAWs+sooA/EP89S6pfzbXujbjdc/X7jliKraqfetft44Wlpc3MH5dJSoL5ZB/KfxRGyOwRoCQ7idOLMxidEc1ELhyXhcVo4C/LytlS7WBmYSrnTc7RH0+0GPWscX5qAklWE6k2s16p1Sqy7S4fobCqz68dCrbUdHL905sAmD4qlcWTc2nq9tIekVTVDkBmu3oDjE63Ud3hocPt1yVbmUnWYVVmA6Ewv3lvPzedVcyoY2BTr8m2EodamT0EWpw+fMEwHn+IlQdaqenwcNu544/6GAHImgA3LwNLEs+t87Gno5Y0uwWILCpSR4kpxvk/Fylzb2eErDaBzykZ47wZ7DGewhcf28i7xa8yqfwjsKXCxX+AWV+Gpp2SHQ70Qsse2PE8fBKRRtszwSOJEmZcI7MH975JR+H5rKrx8y3T2+w52AGvj4VdL8lzUgqFnPY0SXCfcwMceF8C37jFMPtrsgioXCVV5PYyIcv5M6FtvywSrntJ5iKGw1C1Wgh2rCyrdb/MEZ6wBIrOkoDUXiFO12YbjD3j0EEqHJKseHrR8DPU4TBUrhAp3DBnLvqDYdZWtHNuzG/2SOGKqcyGw6oukRzB4NCIQMundBzHfxNUVQ0qinI78CEymudpVVVLFUW5D9iiqupbwHcVRbkUCAIO4IaTdsBEK7MH21wkWU1kJcm1NifFSmuPD48/hMVo0E2XrGajLjOuihDgfU1OPb50Houe2cg8en+EzMZWZk/0yD1VVXX5a8eJJrOHwlAJiaLoyVVNAu7wKpA9SW7Tr5ZY2HcKQf4MufXFt9dF/29Nln/PvFMSwEEfjJoNGeOkWhvyR7cBGSWYmCNeGh/8CCZ/Dk67WeLmlqfYvPsg/+iYQmrxHP5000XQtF1amxKzpJ/Y3Saqr9Z9cMb3hFCiSFJ45a8lwT1+ibznHc/B5r+JweVlD0PlaiHb257p/56MVqnczv0GbHhU9j/hfHk/BhMk5cDWZyTGR08snPsTIdChAKz/q7w+SIIge7LEeb8Lpl0lyYF/Xg6XPijJiFBAtm/aAT4XhaE0njdvYpbxIPYmH7xylVSv28v5ZuNPsRj99L5QTaFyPaOVNi5dcRc4rxEvki1PS7vXtCujBYKuOvjoZ+JLkjdDztv7P5RzM/9WmZxRMFuq2b1d8h0w26F5p3yWfVy0H1h6gKuNqxlT8S9Y9EM+CJzKW7uaeOQrc+LPZTgkCYX970hVPW86hIKyfy1BEIoQcaMposyLfP/8HkkqHIcKelW7m1ue3covLp/G1+af2Ba1/3SMkNkjxL9uPh1TzCJ1dIadG84o4ok1lQA88KVZpNnNJFqMuP0hbBajbrKkGUel2Mx60NMyxmEVOtzRTPNQoEmvzp6YzfbaTlRVZVe9VGWzkizUOXr7PafbEyAvVbLanW6/TmCzk6zDqszurOvi6bVVJFmN3HXBpH6P13Z4CIbDlAxxDEIgKJVrTWY80HiFoUKrcne4/Ly6tZ7dDc5jR2ZBSB7g8u0kKcFESqS6HefCaIxk15Lz4JTP99tF+4FWgph4q+jH/OCb/4x/MLYiPP48CYwQzVo27xHiedpNcqGt38yq9jHcXbGbfcp4fup6GnZvhjk3SqDtqJBs88W/kyzs+odg7JmAKj3EH98vQXH61UKei8+SoN6wRbLFB1fA0xfDBfdBzXrJiNvSxcCjpVQWHc17xPxj3YOSmbZliKGIhuKz4ZwfS5Cq+EiCZepokYzteUWCu7dbAtsVT4hRiatFsvITLxSCX7laMt4zrpHeKEWRwPP2d+X52ZPhnB9JEmDcYpHCgRB+NRy/cIlg6d5mbn9+O8vuWsT4VGSB0HcsxRAR2yvrDYZ0h9URDA7dCO8YegaMYHCoqvoe8F6f+34W8/8fAT860cc1GLQ5s7UOD6eOTtOVNjnJCVS0tuPxB3XzJ5DKrC8YxhcM0dgt8S92bJrDfeRk0x8K6zJjEHJrt8RLi0+0zNjjD+mqL4frU0RmjwAamY1zCx6o+jtcKEr/qQsGa39Soo0eLJgF33g/en9GMVzwSx6uWs/GNgenhdKE+IyaA9/dBihSMU4tFPI2EL76asRsMpL4D/qFQGaNl6TyqV+VGN22X0i2p0NuQb/ImPe8JuMMbeliiln9sVRzAx4hZjO/DGf/QP62JInR5cpfyk3DmXfKc3e+BG37YMrlMPdGIcp+N/z7enjrOyLh7m6A1lLpc7bYGdVVj1vJ5T3T+ViMcGnp67D3DVBV2g3Z/Nn3BX7d8RzLLaIKC4ZTpOoLkDZG/Eq2PC0V9C/8Gd65UyrZ5Utl/dCwFXKnCWH98MeRz8gkLVe1GyT5YLbL+0vKg8/dL2ozix1/xmReW7Ge79h/BkoIXryOs43JpPhHE3x7AaauKiGiJYtkjGNHhex/39tCsLf/S9YuGSUiFd/zqrzexIvFBM2cAPNvk8kYtnT48ovymbTulfXCjC9B2YeSUDBZ5bOce2P85x8Oi5x+z2uSlJj/LfncG3dA5jh2N/SQhIekutWQliXrF3OCFAm2PwuTLhHTVFWV4w14xOy0b4W+46Cs76Z/CcYuGPi7CKIE3P2yFB4KZvV/PByGYK+M2WzYJp/P3JviXy8UlO+0yRpd754EjKyyjhAD2e7fvng8r29vYGZhGgvGyUJ4VLqNshYXiRYTNrOc7vE5UTLb4wsSCqu09vgwKEJmW53DI7N1jl6MBoUzx2eypqwNh9vPrvouTAaF8ybn8t6epn7P6er1U5KVREaiBYfbr/f5ZSdb2ds09AXlnoiU+ZOK9gHJ7A9e2UkgFOa1b5/R77GB4A+FMBoUEjSZ8RFWZv3BsJ6h7nD7aO3x4XAPv+o9FLh9IRIjlXYYngujtvDoHI4hiZbtzpsmNw1FZ9JWfRCADVlXcK8ymXuuPXdgOfHEi8HZIAEa5GK58VEx0yhZNPDrOhvhlZskAIH0RXVUCtmcfrVkik/5Apx/jxhxVH8Mzia44Jcw+nQhosvvg79fNMj7MsooiLzpsOq38Mh8ud9gEmOOZffI34k5Io9663YJjKmjRF7VVSPZ5P3vwctfl22NFgkqs74KL98gRHn+t+Sx+i3QUQ7Tv4Q7vJgJSj15L10MHbskOfCFv8j+nI1CoI1mqRgrBvkMXG1Qv0n6ucaeIYYkedNRvJ08bH6QuYYyzE8VwfWvymLM75bMc9ArhieFfbLFg6G3SwxYFIMkUFRVqvuH6G2Kw/73JOCe9f1PrXRLS+q1u3y6bHMEI9CgxduxGXZ+e2W0EpeTYqWtx4fLF8Qe0/aTEKnM1jk8uilTWUtPZF+K3qN9KLQ4vWQlWePiRTAUJhRW+1VmIT6J2X0UBlNHgtjX1gwA/1OhfTbOYUpUVx5oZXS6jfE5/ZOVxxLaccUZLFoSh/ZkRYkSWRBTyr5xwJokxHIgLP4/2PuWxOi+c4n9nvi+ZYArn5Ie4Lb9EkfzZ0XXDKMGiD+WRLj2BTHvqlojyeZrntMT8W9tq+POf+9ienYqbl+QS7/2fdj3JqBw68aJ7AylsfDsa/Av/QXpSg87pv6GH8zwSgyd/iWJ45ufhNW/g4dPFzJ21veFzLrbpMo7++tyrF01omjb/i8hvKfdLHHU1SLJ7o8fgJe+Gj104F1rovzeb98ItRvZtuIdEgP7Mex6UdY6iiKvnTMFrv4H5E6HZ78o64jpVwuRrf5Y1kKal8rO54XwOyolKZA7HZz18FCf87fiF9HzGvLDO3eIdD5nshQCmvfI/pp3yfGv+rXse/R82PUiJOUx3jKNrdZVWEuDUApYksUrpaNCKu7rHxJputku3i4gLuLZp4j6rbteCg9b/i7HuOVpeU9pY4W4KgZJ5vt6RBbf0yz7TUiDmz6CzHGSNGjcLuuVXS+CuwMu+o2Q8N5OmShy6V+FgL92i8jj9e9uqhRhLn3w2CSghoERMnsMkZJgZtmdi+IyxKPShMxqc2YBxmXLhU8jPz3eAG09PsZlJ1He6oq4OKby7y11NHb1csf5g/Q2RlDX6SE/NUEnydUdHnY3dDMpL5nxOUn0eIN0ewKk2qNZky5PgDS7mcwkCx1uvy6NzEm2sqV66EGktNEJwM76bnq8AZJjdP7hsMqehm5sw6hMBUIqZqOCNbJ4CRxhZTbWCbPD5aetx0dYlV6pYz36o8cXJNlq0sc1DCcrr/U3DWVxNRS09fhItBjJTUlgS8/UwftiTZYokQW54H7hL4feeUoB3PgelH1Ar9fHHbsK+fmlU8lPHUBePufrcovF6Hkw/Sox1OqqleysPUOkRs56ucBrx1R0lmSaZ1wjx9ZVJwEv5xTJ0qqq9AqXvi5EPHcanPczmH4VdXN+iL+lnHH5GZIl3foPuajbs2SRsPp3clHPmiSjJj5+gGu4n2us4HNlyIKhZp1kp1f+OjpXcTCs+YNIuJ31kF7E79wGSgy1vBs+ncvat8LzX4oGLE+Mr860K2Wx4HdLwFEMQlDTiyUomRMkqK/8DfgkaUT+TFm0dJQLQZ91nUieOqslUCYXiCxKMcoCYvuzch5BKuAzr5H/h0NCvkGCj6rKfZoruKpKsiO54IT0SWu/GVGm+MlNGf58yhH892JSXjJ/umYmiyfn6nETIDfZSjCs0tDZi90ajTMyZzZMdbu02EzIkdgKoow6nAGU2xfknD+s4u4LJ3HTmdHrpKYU0npmIerroH2HjQblhFdmYxOojhNMpI8l/MEwbn8IRRmeVDscVvnO89tZNCmbh6+bfRyPMHpcJ2VagNkWvYb3RV8iC0LexsyX21Bhsoh6awD4Isq5VJtZ1i6Fc6BwDqqqUrryfUCl0pvCg8FvAnBN0A4lMa9tNMHC22HSxZJctqaIDPrc/4v6emhIL5LbYFXuKZeKQixtDAS9tO5eRvO659mUcSU3Z5RARgmPbilmbWsHr928kNljIpJkV6usBbS4dssqIXaZ4yI7/pFUx7VWpVBQjjvoE4Jfco6Mt9r+T/EeKTpDtt/6D4njs66TWPr2d2U8JEhbWOE8iakX/hrmf1tI4Ss3ybpg3i1Qv5niprW8GDoXT8nF3Hp2kSS/3W3StjX/VjFKK31d4v2i/5X107J7ZVRkyig55hW/kGrvN5aKPLz6Y1lPZBQDiiTC04tkrZFSIPH/1Zvh8YiHTDCm1afwNFmDvPltqUYv/A6s+6usxQJekX+f8yP5Xgb90NMI25+Dx8+Ga/4lcv4ThBEye4wRSxhBKrMAdqtJJ7mazFgLyp2eAO0uHwvGZQqZdfr414Ya/u+NPViMBm47d/whB7DXd/YyOt1OUaaQ5Mo2Fztqu/jCrAJGZ8jr13V6SLWnAtJf0xUht+l2qcxq0sjsZCueYfT6lTY6dVfmjZUOzp+Sqz9W1+nB7Q/h9od0B8jDwR8MS+9Tn6z3cNESI1dsc/lod0V7ko81mXX7giRaTSiKQorNNKxh71r1uPMoZG+xaHP5yE62kmQ16b1ixxSKApMuZvvBdj4s3cjF0/K5/NRRQ3++Jo+KRVIO0CfLGQmSOtJGi5w69jjm3yq3PvjVihbKWhVWfH8mfP6PQqo3PwkLvydyrp4WOQ6T9N3RXs5brz9HdU0VoxZ/jyvPni2Ba/l9EvjyZ0gAUwwSFNSwkD1rkpDotX8Rd8wFt8H6hxgXbuZ/zT/gVdcMTr/ETcHSb4oMu+QcWPhdkaFteVqcsVPyJSvasEWOxdfTf1xU0VlikOJuhQ2PSVV67jdg2z9hx78Ofb6tqSLrLl8qsq3mXZJ5dVSKMyhI73TDVmgrk6xyaqEcpfYvawAAIABJREFUb2spJOdLBaCjEs74jgThtgMiQ0/Ol4QEqiQoatfLfT1N0oeVOV4WGok5koRILRTyvvlJWTxkT5J5k1WrOXPnk7xhqaBNTYeVm2DcTKkmg5wzNSSGJunFsgjxOCTZcOGvT/j4qxGceBgNCl88tbDf/VrSo6LVpcdakMqsLxjSnYzPGJ+lk9kJucmsrWg/5OtVtbvpDYRYdaB1YDJrMmKNxChfDJk1GhRykq0n3ADqv6Uy29Ur8TAvJYGmbi/eQCjOaHMwVHe4cfmCVLYdh5jXB5r8+bM4LUDrQ0+1mfX/gyT0gxGZu2ZqCuAarGUtcxx8c43E0SNNliakwqSoyuugdyxfXjWVmUoqN0fu09ZVce0rSX18MRIz+7cUxXpuaAlek1VIJcg6Ysl90W1s6XDeT+Ofc/kjQtRDfol9fSW4Y+ZLb3d3A+ROQVVVFty3lK5gkMWGHG4df5q0l8Xi3B/JLdb8a94t8UmA+q1ybrLGy7SO07/JYXH9m7ImMSXIGqB4kSTTLYkSa5f9XCTsYxeI1HnzU0J6L/1r/z722V+H178lqrgTiBEye5xRlJmIQYHkBJM+A0+roGpktrrDTTCsMiU/hde3N7C5upPXtteTnyoX9LKWHqYWpA76GnUOD4smZlOYbsegwEd7W+jxBZk7Np3CdLu+zbRRso/eQAh/KEy63UJmooWKVhduXxCryUCKzYyqDq3XzxcMUd7aw/ULinhuYw2fVLTHkdm9kaotQEu3jzGZA2QO++0zjCWmH+lIDaBiXaHLWnqIXGdp6/ExOW+QJx0hXN4gmZH3lpJgHlZGWVt4HI27ZizaerxCZhNMxzVzrPV4tx3DUVLHCk1OL/WO3mhCJn+mXHQ1JOfGPyFrAh/Yv8B7wWZ+EIqMAzFZxcCrL3Kn9r9vyb36f9WZX+biX76MNfMUcDlpLbyAgjtLJTMb25u15F6pJBv6LNQCvVKFTh0lFdvueslMa8Fq7jei2555l8iPwkGREQW9QiTDISF/1mQYs1BI++RL4PFFsPFxCaKnfF7Idc06IZcphUL6G3eIdNqeBefdI1JsnxNGnyaGISt+GX+8SXnyeCDWZE6R4F36ejwxz5wQlVmhACqYEyHgptCUyQ41nyKlmZztf4HtqlSXUUUy5e2W/iVbugTVytXy3ufeOEJmP8OYW5RBTrKYQE3IjS5ArRGn4YpWFykJJqYUyO/aYjIwNsPOux7/IVtONNfkLdWd+INhGrt6GZVu08dtWSIqHIivzKYkmOJG7g0FwVCY0kYnM0cPsW1gAGgxJyfZSsdJ7pn1BkK0u3z62mM40OTZozPsNHV76fEGh0RmNYVYVbvruJruhcMqPb7onNl+kxL+y6ElblJs5jg/k1hDNW28WnKC6dBuxn0rsYfBkx9XMi4niXMn5fD7D/YzZ2w6550SjeWaui1WdREdfXmSjAVTD5PoT0iVG9DY7aUrorA47PUjNgHQ9xwOtX0pFrlTReI9EOwZIhvWMHah3AZDwSy4dd0Jn3wxQmaPM748bwzTR6WSkmDm0pkF2MxGspNlUauR2YORjPGodBsZiRbe2tmAqsIDV8/kuic3UtrgHJTMegMhWnt8jM6wYzEZKEy3s2J/KwBzxqbrDrt1nR56vAF++c4+xmZJkEmzmclItNDh9uH2S3VRG4nj8R+ezJa3uAiEVE4dk0ZZSw8bKjviHt/XFCWzjd29QyKzgVAYi1HRK9FHNJqHKJlVlPjj0Cq0xxIuX5CkBDlXyTbzsHp9ojLjY1SZ7fExMTeZZKvpuA4s1zKdbcfhfA4H3kCIO17cwV0XTGRirvRKtff48IfCtLl8Q5arOvQK+dEtBL2mFCrCo1gUqf57/MGB5wNDfyILQvY0abglsX8WORZpo/vPLBzI2ROkD/n2zUKqY3ttp10JM66F3CmH7vtSVTHEaC+TwJc7Tfpq9r8j1djR88Sh09MhwdmWJsTc1SJ90827ofQ1kUd96Z+S3a1ZCztegIJZ/LRyLh/u66DXH+K3ny/h2uJekWy1l8Oa3wsRzp4oJHbj45IYuO4lGHfu4Mc8gv96ZCdbef22M7jln1uYENMrqRGg/c09FGUlUhhx2s9OspKRaCGsCgFMTxy4elAdIbO9gRAvbanjnjf3cN9l0yiJjAQqTLfpiVZNPdTdGyTVZh42mX11Wz0/fHU3H//PuXETEoYDrTJblJWoH/tQ4PIFeXB5OXecP+GYGdU9srKCv6+rZsfPLhi2P4XmHTEmw86mKgdOb4DsZCu3PbeNRKuR3181c8Dn7WmUNgxvIEyT03tMJisMBJc/iKpCVpKVdpeP3sBny+BPmy2bYjPFVWZjx0E1donhWk6yVfdiOVoEQ2H+8OEBFk3MZtGEbP72cSUNXflxZFYjsbEqN61I0PopTLr3heY/U5CacMzazk4aTsIIx8/Or/AkIdFq4vQSkTAUZSXy/84u0R/TyGxFhMxmJ1vJSbbicPuZOzad+SWZJFlN7GnspntNgIpWF7+7agadbj/+UJjclAQaIhcOTU5clJVIrcNDVpKFMRl2kb4mmHhjeyP/3lJPRatLd2FOs5vJSLLgDYRpdfpItBr1C7PHF4LDGBCXRgLI1IJUphR08/dPquOy3XubnNgtRjz+EE3d/R2VB4I/GJasty4zVof0vL5odnqxGA1kJ1v18UcA7T3Du0gEQuFDSrwhQmYj/VqptuFVZjWZscPjPyZZ3hanj7MmZJNkNeENhId0/EcCrSf5ZFdmD7a5+KC0mVlj0piYm4yqqvox1Xf2DpnMagFwWEZcA8DtjxqpweCzZgOhMI+tOsgNZxTF9ZkfK7y5o4E/fVTGsrsWRc2U9J6gPhh92iH3Vd/p4fKH1/HC/7uQCdOvij6QOU56oGMRK88y26J9T2MX9J/fXHKOPs+wa98mSrIT2dfkpNFjiPbajD4NvhIzp3nODVKtDvoGfz8j+ExhVJqNd75zZtx9VrN85/c2Ofn89HxdgpydbCU9UWvv8ceR2WAozI3/2Mz1C4qoanfrpPQXb+8lrMKWaoe+gJ+Sn8K+JokrWsLV2RvQyexA4/AGw87I5IGDba4jJ7ORik5xZqI+0WAoseST8jaeWFPJvKKMOFXVUFDa2M3zG2v5xWXT4iqhG6oc9HiDtDi9FAyTVGqL+DGR86Cpi3bUdekxdsBjaXBiMigEwypVbe7jRma14ylIS6Dd5cPlDX6myKwvGMJsVEi0mAiGVd2sL1ZZpsmMc1MSjtnM4+oON75gmMbuXtpdPgIhNU59B9GCgMsXxBeU36nWPney1ylDwa76LgwKzC/JZE1528k+nP84jFhGnkSk2OQiqJPZJKu+CP7CzAIMBoUpBSlsru7kwRXlvLSljgPNPdzwj81c8/h6wmGVukjQ1CQ9RZHq5+wx6Xowu2haHs1OL/5gmFvPGaf3NqTaLHo2e0tNJ4kWkz4+SFuUV7e74zJwsdACzNgMOyVZifhDYRo6o6R1b6OTM8aLo1lj19BkHv6gkK++Eq7hotXpIyfFSlayNa7qOZzK7OqyNqbe86F+jmMRjGTjVVXFHUNmUxJMw5QZy8XeHwzrErYjhdMbwOULUpCWoFeKj1VmtC9aj6PMuKm7d9DvXL9tI9+r+k75jJzeoF4p0RI9Q4GW1T3ajKh2vrP0yuzA72NLdScPfFTG8n2tR/V6g2F7bRfVHR5ajsHns7fRSbvLpy+6jwe6ewNkJFrITLLG9bsPiNTCESI7gjgoihJH3hIi/gwmg8Jti8eTn2qTUabJVtIjaqVOj59AKMxdL+1g+b4WNlU7+Li8nVe21lHV7mZqQQqT85JljqxBYVd9N3sbneSlJJCZZNUTrtrCubs3QMoRVGY15VBNx9AJcF9oMWdslp1ASB2yOqg+Eq+HQ741vLK1nuc21sZdZ4OhMLsj14n6zqFffzVovcYamXX2BgiGwjQ7vfqIpb5QVZXSxm7OmiBrjcp217Bfd6jQznNBxPSw5zPWN+sNhAfsF48ddRXrv3Ks+oo1GXlTl5fGCFnuO8YtVlXV5QnEOYp/2iuzbl+QFzfVccb4LPJSE+jyBFDVIyvkfFZxXMmsoigXKYpyQFGUCkVR/neAx+9SFGWvoii7FEVZrijKZ6r5Kc1mwRgJkiA//tyUBAwKXDxdGjunFaSyr8lJjzeIosD3XtzOzjpZqK6v7KAuEjBG62RWZFBzxkaHSf/+qpls++kS1vzPudx9wSQKI1nqNLuZ04rSURQhVYlWU7Qy6w9S3e7m/D+u5qrH1sW5A4P8+N7Z2cR5p+RgMCgUZ0lFRgskXR4/jd1e5o5NJ9Vmprl7aGQ2EIqvzA61ZzYcVrnv7b3sb5aLXnO3l7yUBLJiMu9ZSdZhyWKf/qQKfzCsX0g1fLS3hZn3LqXT7ccXDBMMqyRqZNZmHpYBlMPl112uj7YqqBG7/FSbfjzHq2/2ePXMBkJhLvzTGh5ddXBI2zc5NTLb2+94Goa4mBJDNG1E0tGS2Wggh8ErszURY5rBFmh90eMN8OTHlYTDQwtw2u+tsQ+h313fzbPrq4e0Dw1aBrx5iMd6JNCIQG6Ktd+1ZgQjGC60iut9l01jXHYSFpOBiTnJTMhJipJZd4CnP6nite0N/OHDAywtbQFgQ6WDqnY3xVmJLJ6cQ1aSlZvOKqay3c3GKkdc/y3EV2Y1MjvUtpFwWOVARDmkmVUdCZzeADazkdzISL++7RL1nR6m//zDuFm7cv+Rk9nSBomLscdd3urSk7JagnE40K7DWoXa6Q3Q2iMj9Xq8wQHJUWO3l05PgMWTc0i0GI+pCVSr0xtHKnQyG6n8HrInFAiF1SFfs/8T4AuGSDAbdBm/Rma171taxAA1wWwg1WY+ZmR2byTh0+H2U9kma8y+ldnYXlmH2x+3nvq0x5Rn1lfT4fZz55KJpNnNBMMq7kHWDiMYGMeNzCqKYgQeBi4GpgBfVhRlSp/NtgNzVVWdAbwC/P54Hc+nETaLkT9dM4ucFCuF6UJAvnFGMfdfPVOfMzu9UAJnSVYiXzx1FPubexidYSPVZubFzXXUd3qwGA3kRBbPUyOBVquI9oXRoHDDwiLddTHNbmFSpNfQbjFGK7O+EI+tPojBoHCw1c2Vj67TLyIAb+xooMcX5PoFkn8oiYwbqmp34wuGuPvlXQCcVpwRMbIaosw4QmbNRsmyD7UyW9Xh5um1VTz5cRUgF7rclAQyIouaVJuZUWkJtA/RHKPO4dGlHn1dgVfsb8HtD3GgpUe/WCcnaJVZM87e4JCyar5giB5fUHe3Ptp+TY0YFaQlkBwhs8fLcVGvzB7jntnyFhdOb1BPShwOTRGyNiCZ7RraYsrlCxKIyNmPtndZUzRkJcn3brBqe1VkATjUJM97u5v45bv72FnfdfiNiZpw9CWz9y89wD1vlQ5L8aDtq2mIx3ok0CSauckJh6/MjmAEh8G5k7L54I6zuGpO1AH59dsWcueSiXpM2FnfxZ+WlZGVZGF/cw8vba7DbjHS3RuguzdAcVYidy2ZyMq7F7FwnMTThq5epuRHyOwABlCpNjNpdrOYLA7wG+vuDbCvyaknPGscHr2SdSSV2co2F+/tbsLZGyTFZiIjct3p6BNLNlaK9HdjxNeitLEbVY0qu4ZLZsNhVW8zqo457p0xZHmoycSddV2sPCAKlS5PAJNBoSBN1j/O3mDcNaxpALXNtppOAKaOSqUkO0k37zpaNHT1svC3K/iwtFm/T6t4a7L1wyWLr35sHd94ZrOu5DqZcPmC/GVZua4kOBL0rcxqCiqHx4/ZqOgVa1H5mXD7hrYWOhxizUS3Rj5vtz8Ut76Jjd2dbr+eGBmVZutXxf00wR8M88SaShZPzmH2mHTSbPIbHo66I/b9flZxPCuz84AKVVUrVVX1Ay8Cl8VuoKrqSlVVtSvhBqC/9/5/OS6dWcCqu89h2V2LAJhSkMIVs6OnYWahmLVcd/oYblxYjEGBO8+fyBdPHcWHe5r5aG8Lo9Jtes/K6SWZrP/RYt25eCB844xilt+1iMyIFPL0YrHWToqpzB5sc/HqtnqumTuaF2+Zj8cX4spH13GguQdVVXl2fQ1T8lP02V2ZiRaSE0xUtrn55Tv7WLavhV9cNpXZY9IpSLMNWWbs02TGw6zMatntlftbCYVVncxq7zEn2SqV2SFWEl/aXIeCEPy+hhraxbSq3a1nZjWn6lSbGX8oHOf0B1L9e2hFeRwx1vo0tbnDR0ukYiuzmsz4uJHZCMFxuP1H7Dg9EDQjj8EWdv/aUMO1T6zX/9bIYENnr/TLRsi1zWwc8mJK+xzsFuMxqMxGemYPIzPWvlNDJYja+ajr7GVrjYPF9686ZLBr1clsdP9Ob4B1B9sJq8OTYDd3+yL/Hh2Z7fEG+KS8/0gUVVUjTrBmclIS+mXcRzCC4cJkNDA5LyXuPrvFhNlo0KtHD62swGww8OItC0i2mugNhLh1UVS+XpyViMloIDnBzIyYeKpVZrXe24YuufY4vfId1rwwunsDdHn8vLCplkAozKYqB6fet5SL//Ix1z+1iVBY1SXGhem2ASuzh6vqPfBRGd95YTstPV5SEsxkRKrOfXsVd0fMZcpaXGypdvC5Bz9hTXn7EVdmqzrceuWoNua4d9R1kWozk5VkHbLM+Dfv7+Puf+9EVVU6PQHS7NFz6PQG4q5Vfa9bwVCYB5eXMzbTzrSCVIqzEuOS7keD0oZugmGVtRVRY0ttLE9BqpDtgUwWH1lVwQubaulw+dhW28WqA2386r19cds8vLJiwGuhxx88bpXcd3c18qdlZayr6Dj8xoPAFwxhjanM6mTW5SfdbtE/N7vVSJLVRCCk9lsLDReqqrK30alLz7X1F0TjHIiqSivqdHoCemV2Ym4S7S6p7n8aUdfpocsT4PMz8oHoeM/hkNPbX9jGdX/b+JmWJh9PMjsKqIv5uz5y32C4CXj/OB7PpxYmo2FQ+/mS7CTeuv0MbjyjmOmFqWz88flcMbuQr84fg8VkwO0Lcvms+NOan3po8wODQaEoK+pcqhlU2S3R8UGPrT5IWIVbzi5h5ug0Xr1VrLh//8F+1pS3s7+5hxsWFul9SoqiUJKdRFlLD2/uaOCLp47iawuKIscz9MpsIBTGajLopkVDvRBqJk8dbj8f7ZXKaW6KlcxIFj47WfqRY3tmPYPNQAPe2dXIWROymZKfolfRQEYHlLVIsKxqd+tkUSOPWh90X6JR3eHh/qVlPL+xRr+vIzKWR6/MDnDxWlvRzgd7mvvdPxCaunsxKELctR7ew8mgYhEOq0O6GHoDIZzeoG6yMdgoiHaXj5++seeQ57kvNEe/6g73gMfy0d4WNlQ6dMKjkcHeQAiH2097JFkxvTB1yIRNkycVZyXS3Rs4qsWEJjPOSLKgKNA7yHvXyOlQfxfaYrPO4eGT8g4q292UNgzcwxoOq3rlPLaqsXJ/q16Bron5Tr+7qyku6bHuYDtv7mjQ/+57ro8U/9pQy1ef2tivb703ECIQUkm1mSlMt9Hh9g/rOzOCEQwHSVYTZqOCyaDw2NfmMD4niavnjsZiMvDV+WN134nYGJmeaNFNFjX1U36qjcl5ySwtbYn7DqdEFvS76ru44tF1/Oi13byzq5H3djdhNhq47dxx7Kjr4sXNtexrcmI0KCyZkkudwxO34H5hUy1zf7VMJ1B9EQ6rbDjYQSissrnKQYrNrLc39L2u7NHJbA+bq4UMbK3p1KXAdQ7PsK572v4SzIa4yuyOui5mjk5jdIaN+iEoY8JhldIGJx1uPw1dvXT3+km1mbGZjZgMCs7eQFxCru816LmNtZS3uvjJJadgMRkoyU6koWvonguHgjaXOFaa3VdmPFBl9ulPqvnLsnI2Vskc7/klGfx9bbWecPcGQvzxozL+vKws7nn+YJizf7+SJz6uPOpjHwjbauR9HGjpOcyWg2PQnlmPn4xEi77+SbSY9DXI0fp2tPX46HD7Oe8UcfaPPf5YFU+n268rBB0eP92RmcUT85IJq7JeKz+K9368oKkjNGl9mpYMG2JxQ1VVdtV1s7fJqU8y+SzieJLZgaz0BrxaKoryVWAu8IdBHr9FUZQtiqJsaWv77Ll8zShM0x2CtWA1PieZ3T+/gI0/Pp/vnT/hqPZ/WpFWmTVii/Rvtjh9XD5rlP4DK8pK5MYzilm+v5V73tzDqDQbl58aT6JLshLZVO3A6Q1y8bToMNf81AQ6PYFB+wdj4Q+GscQYQPWt+qmqym/e28fmakfc/fubnOSnJmAyKNzx0nbMRoVFk7LJjMiutMqsw+0nHMmIz/j5Uj4ewDWu1emlusPDmeOz+o062FYnCwGDApVtMWTWGpUZA/1MoLTgvyvGREfLno+LzB3um4lTVZUfv76bbz+3lXUH+2dx+6KpW6rRUk0YXmXW7Qsy91fLeHlL/WG31arbWoVisGr3B3uaeXZDDasPDP03q50nbyBMi9PH+oMdcedFkx9rJiNN3b36OKn6zl7aXD7MRoUp+SnUR6q1h4Mm7y7JTpKRHcPoeY7F0tJm6iKLw0SLCZvZOGBlNhxW9SrMUKudGpmt7/TofekVg1Qg2t0+3eQtlsx+sKdZ/55q+ytr6eG257fx783RvOOfl5XzszdL9XOnyYybj7JiWhZZSPTtadOcWFNtZj37fiQ9fCMYwVCgKAq3njOeR74yR2/H+Z+LJvH+984iPdHCwvFZWIwG3YdCw8zCNJKtprj7L5qWx+YaBwdb5TutuRkD3PTMFhxuP+l2Mx/uaWF1WRsLxmVy9wWTWFCSyW/f38/bOxspyUpkUm4ygZCqk9BQWOXRVQdxuP2sHOT6Wdbao8uJ3f4QyQkm8lMTyEtJ0ImUti/N96Gi1cX2WolhH5e34faHKMlOxBcMD8skZ09DNxaTgYXjsvTEmNMboKylh1mj0yhMtw+pMlvj8OgmSjvrutnT4KQ4KxFFUUhOMOH0Bmjs6iXZasKgxMuMvYEQDy4v54zxmSyJODFPzktBVenncxGLl7fU8cVH1h5WUaQZc+5rcurk2Km7GQ9MZrs8ftpdPpqdXp78uJIEs4E/RMYJaVLqg20uQmGVrbWdcZXFPY3dtLv8vLG9geOBbZHPvaz5yAld355Z7bx0uqUyq61/7BZjNKF+lGRW65ddPDkHRZEpcVoiPbYXttMToCSmZUuvzEZMTm/8xyaueGTdEZuKHi/09b3RK7NDlBk3dPXqv6GHVlZ8Zquzx5PM1gOxQxALgca+GymKcj7wE+BSVVUHvJqqqvqEqqpzVVWdm52dfVwO9j8Rx2pYd3ayle8vmcgXZhboPbOKAreeE+8Yev2CsSK77fBw27njdSmwhpKsRFRVsrVnTYh+Tlql+FBVqK01nVzxyFqaur2YjQYMBsmc973wbK3p5PE1ldz/4YG4+w+09DB7TDrzijPwBsL85JJTmJyXEpUZpySQlWQhFFbp9Ph5e2cjwbDKC5tq+x3LpghRnlecQXFWIq09Pj27uLW6E6NB4YzxWVS1u/T7k2IMoKA/IdLks3sauvXsu1bR1LKJfQ2gDrT0UNPhwWQw8J3nt/Pwyop+PZCAfvFq6u4lPyJ/SrLKcQwUSHbVd/XL+m2qduBw+3lxc//zocHtC3Lf23t1yZpWoWhzDUxytCC0qU/iYTCEwip7m5yMj5D7bbWdfOXJDfx1RQUg5F/LxO5qkJ6vpm4vsyNmZ/WdvbT1+MhKkh50jz80JOm2llTQZkgeiRFXbYeHW57dyh8/kmy7SPaNeAaoELT0ePEGwhGlgF/vYXp7p1RvBoIuM3b06lJ1bbHVb/8RWbDJoOjOj95AiFUH2rhsVgEJZoO+P63HTUsShMMi6eruDeiv09IdlZQPVPFYtrdFnzFd1e4eNLlxsE1TNMQft6ZiSLWZdQO76vYRMjuC44e7lkzUCRDIXFpNIXPXkon886Z5/eLbDy+azNM3nhY3huaiaXmoKnqVLcVm4pT8FMZlJ3LDwiLe++5ZfGFmAcv3t1DV7uacidkoisJvr5zOpNxkqjs8zBmbrs9g136Xqw60UuvwoCiSJBsImlw01q9BURQWjstkw8EOvdJa2SamTPOKM+gNhFhdJuR4e6389heOE2WWlkD61bt7eXz1oQ349jQ49fdZ0yFV3Y2VDsIqLCjJpDDdRmNX72Glnbtj1CVv7mig1uFh0cTsyLk00+OVntnRGXZykhP06xnAG9sb6HD7uf3cCfpaSDO+3FoTH3N21Xfxq3f3SpJg9UG213bphl+DLf7LW3uwmgwEw6qeZHX2itGWJlXvG19jr8nbaruYMzad0Rl2Jucl60ldrUKrqrB0b4u+/dZIxXx/c0+ccma4cPmC/Pb9/XExvrs3oFea9x8NmQ2Icm6wyqyWyEm0mnQTymNFZmcUpuntO7NGS/udphoKhsIykzjJSnKCKWIA5cdiNDA28tuqcwjpi5UpAzz1SRU/eHknIIaNgykhjhfqHR4spqjvjdYzO9S2M+379MVTR7G9tos9DYf3G/mwtFlPLv+34HiS2c3ABEVRihVFsQDXAm/FbqAoyqnA4wiR/ezWxz8F+M55E5hblIHNbMRiMnDxtDydVGhIs1u4+awSJuclxxlraCiOkLKzJmTrFV5A38/XntrEM+uq+8mZVFXl3rdL2VbbhcPt1xcRFpOhX/b0uY1CtjZWOfSKqdsXpNbhYVJeMt87bwLfXzKRry8sAtBlxjnJMqYHxLRIk+4u29vaj9htrnJgtxiZWpASXVxHgsuWGgdT8lOYWpBKrcOjL8QTY0bzQLTapEELhm5/SO/p0bLquckJJFlN/WTGH+5pQVHgmW/MIzvZyh8+PMDNz2yJ2yYcVrnqsfX85PXdNHV59cSB3jPr7Rtse/jiI+t44KP4ZMCGg7Iw2lbbRcMgi5AHV5Tz9NoqPZEwtUD6yAYjL5ppw6aqoZHZyjYX3kBY7x2AIvmRAAAgAElEQVR5YVMtYVWk1hAdYWFQYHd9F52eAL5gmLljRVlQ3+mh3RUlszC03lDtvEeTCsPvm12xXxYlWvLFHlE5eAeozGpEbUFE3t/S7WNvo5O7/r2De98u7be46vYE9O9ZrcOjVzbLWwYhs5EAP7UgRU9+bKvppDcQ4rxTchiTYdcXzdpiMtZRVVt87Kjrwu0L0uML6r/hvv2smnrgrpd20N0b4IpH1vKzN/f0OyZVVTkYWUz1NWiJJbPRRf2xcyQdwQiGg6wkK/Mjv81YjM6w6yomDZNykxmbaWf5/lamFqRw1oRsclMSWP79c/j5pVMpSLNx0dQ8Xd5/ziSRSo7NTOSVWxey6cfncc8XpsbFGX8wzOOrK8lLSeDK2YWsOtCmJ7y8gRB/XV7Ot57dyru7mxibaY8hf3LNXzAukw63n7JW+U1rv/ErZ4uSyhcM6wt8QDe3qnV4aOzq5clPqnhgadmgyeceb4Cd9V3MGJXKmMxoVXdtRTtWk4HZY9MoTLcRCKmDusiuLmvj6U+qpMJrNDAlP0UndosmyjkSM0XpmS1Is5GfFm1XUlWVp9dWcUp+CvNLop9JdrKV4qxEXUqtbXvv23v528dV/PDVXVS2uTEo4r/w87dKOe+B1f3eazisUtHq4sKpojDTiH+PV4y2zEYDCWZDP6KmEUZNqj6vSL5HiyZls6XGgcsX5EBLDxajgaJMe1wL0eZqh06SP4ohucM1j3p0VQWPrT7I69ujKitNKj21IIWKNteQ9rmzrovvvbg9bg0mlVkj1oEqs4lRib3dYoyqwyJrkCM1KNrb6KQwXUxPtYr4hNwkbGajntzu7g2gqpBuN5Nut9Dp8dMd6b/WzFTzUkS511eN9+/Ndby8tZ7aDg/ffm4rX3ly4yGPZ+WBVrYMkKC/+ZktPLSivN/9exq6D+lvUdfpoTDG9yZNr8wOfL6au70s+eNqPWZryYnbzh0P0E+12Bf+YJjvvrCdPy4tO+R2/2k4bmRWVdUgcDvwIbAP+LeqqqWKotynKMqlkc3+ACQBLyuKskNRlLcG2d0IThAUReG5m0/n11+cPuDjdy2ZyAd3nN0vaw3ohhuXTM+Lu3/m6DSe+NocRqXbuOetUi788xpOvW8pC3+znHve3MNDKyrYVd/N95dMZHJeMhNzZeFsNhooa3FR3iKmUw63n3d3N3Hh1FwMisy5A5EvqipMykvm9JJMvnNeNFM7NtNOSXYis8em67M/Pylvp7LdzTVzR+MPhXlntwgG/ramkkdWVbCxysHsMemYjAaKsiQoVbd7qGp3s6nKwdkTsyjJSiQQisq3tMpsap/KbHW7LE72NDiZG8kaa1Jjh9uH0aCQajOTnmhmZ10XS/64WpcjfVjazJwx6SwYl8kHd5zNzz4/hb1Nzrjs79K9LWyt6eS1bQ00dEUrs3azEUWBjyvaue/tvTrJ+u37+wmFVVbsb40jTesOdug9Yfe+VcrMe5fGVa0rWnt46uMqkVdHyEhfmfEb2xv0ABoKq+xvdmIxGiKjpQ6fZdQWIBdMycNsVPg4YpCxv7mHDpdPJ7OLJmazu6FbJ2oTc5NItZn1ymx2spWxkcXh9ph+J4fbT0ekX7O0sVuvPDrcfkwGRZfUH4mr9MoDbYxKs5FoMWI2KlhNxkFlxlpiZEGkIlLX6eHul3dGBsH7KGsRKaDmFqpVTMZlJ1Lr8ODyBTEalEFlxpoc+NQx6XT3BnD7gqw92I7JoDCvOJMxGYnUOuQYtO9iWYuLcFiNq5TsqOvS96UZ0fXtWWvq9tLa46Ox28u3nt1KpyfAlprOfoS82enVDWOq2gYns6k2M+l2MzUjMuMR/AdAURR+fMkp3HH+BF779kL9+h+LecUZpNnNFGclxvXhgiiGbBYjeSkJWEwGnt9Yy9WPr2dTtYPbF4/nc9PzcfmCPLrqIA8uL+fc+1fxwEdlrDzQytaaThaUZOpVKk3iuTAindaMi3bUdZFgNnDR1Hz9db9y+hj9//NLMjEocp15dWs9qgoqKg9FFDEgv1GNuPx7Sz0ef4ir5xbqpK26w836gx2cVpSB1WTU597vaXD2qwC19ni5/flt3PfOXt7Y3sAp+cnMLZLYWJyVqCe08lIT2NPopL6zl1FpCbqR5Du7GrnmiQ2Utbi46czifgq1uWPT2VLt0K9Bm6s72VrTSZLVxCtb60mymvj2OeNZX9nBP9ZVU+PwcMPTm+MIh/TdhlkwTqrM2yPtRZ0ev36ek6xmXWb8x4/KeGLNQSpaXSSYDVwf8QvRiPaiidkEQirrKto50NzDuJwkLp6ez/rKDqraxR9ia00niyfncEp+il41fnB5OeN/8j7T7/lQr9AfSkba4vTy1Ccy0WFVWZS0bavpRFHgS3NH4w+G9evr3kan3rPZF/9cX8ObOxp1Ig9az2y0MvvUJ1Wc8dsVdPUGyIgxgNLcjEEc/leXtTH7Fx+xfF9L/xc6DPY2OXUHcc3luiDNFhnjJvFcU1OlJ1pIT7Toldk0u5m81ARmjk7j55dOYfaYdH1dAZIo1npwH/joACsPtLGrvnvQRI4vGOKOF3dwz1ulcfd3uv0s29fC8xtr4z6fg20uLn94Lbc9t63fvvY0dOP2Balz9Ma1LiSYpSd5MAK8pqyN8lYX7+6Sdev+5h4K022Mz0kiLyUhrsf7oRXlvLylLu75+5ud+ILhfmO6/tNhOp47V1X1PeC9Pvf9LOb/5x/P1x/BkaFv9nmoGJ+TxNI7z2ZCn4ouwAVT81gyJZfXtjXwz/XVLJ6cS483wEtb6vAGwozPSeLb547n9sXj9eA0OS+Z1WVtrC5rozDdhjcy7uDOJRPxB8P8fW2VLjfVtu+L5AQzK75/DiCky2Y28st3xVnwrgsmsr2ukyfWVJJgMsY5Dt55vgT+2Iz5ygOtmI0Gvr6wSK9sPbexhjEZdr2XWctMbqpy8Nq2BlaXtbFwXCbdvQEunVXAviYn7+xq5PE1BylvdZGTbMVgUEi3W9gWCRr/88oufnLJKextcvKTS07Rj+mS6fn84t29vLurie+dPwFVVXlweTlJVpOeIc6PZC4NBoUki4k1ZW2sKWvTSf2yfa1Mzktmf3MPle1uxmUn0d0boLSxm+8snsDy/S0s3SsV4T98eIDPz8inyxPglme3YrcY+f4Fk7jnrVKMBoX8lARSEky09fjo8vj58eu7ATh3Ug7tLj/eQJgrZo/itW0NbK3p1KsSA2FDZQe/eGcvk/OSmZSXzOh0O5Xtbkal2Wjo6mVDpYO9TU5ykq2cMymHlQfadKKan2ajMN1GfaeHth4f0wpSmZyXLEmUNQf58mmjae3xccUj63D5glw6q4AXN9UyLlu+r50eP+mJFr2KP1yZsccfZH1lB1+bP5bcFCvL9koywmYx0eML8MelB7h67midLFe3u7EYDbok7pl11extcvKzz0/hvnf28v6eJp5ZV012spWldy7SyewZ47M4GCGC80syWFvRoY8DiUWL04tBgRmFUjlv6u7lk4oOZo1OI8lqYmymnU8q2vAHw+xtcpIRCf51nR5KG51YTAZmjEplR10XF0XI66wxaby6rb5fj68WEO0WI+srOzAZFNp6pGcs1ohO6ylMs5v7jbqKJbMAYzITD1uZVVWVd3c3sWRKLlbTwOZ5IxjBicCFU/P0Ct5AMBkN/PaK6Xo1ayAYDAo3n1nMmzsa8fiDPHzdbD43Ix9fMERGooU/L5OKz5njs3jgSzMpykzkkVUVfHX+WN10Tos9o9JskapfE2k2M89trOWiqXmk2s0UpCbQ2uPj6jmj+e37+0lOMJORaCE/1cbmKgf1XR4WjsukJDuRlzbXsWBcJhsqO/jXBklsnjc5h/3NPcwrymBGYZpOhLbWdHKgpYfLTi0A0JUx33xWlER3nj+RQChMfWcvrT0+fIEwuSlWWpw+lkzJjSTLavQqM8CNZxRx3d+kSpafZsNiMrC0tJk7XtzB6Aw73108nstmFfQ7l6cVZfDy1noqWl109Qb43Qf7yUy08MT1c7jqsfV8YWYBN5xRxP9v787jo6zOBY7/zsxkJpns+75BwhKWsCSAoohsYl1Qcd+trdZWra2t2/Xetrd2r8v1Krbu0laUVqnWWhQRlB2ChEUCJCGBhEBWskLWOfeP952XhCQ6vbUkgef7+fDJ5GUY3jl58z7znPOcc17bUMrcrFiumJjEra9s5lfL91id+N4O48yYIKamR/KPXYdZX1zD6n3VLMg2/s8QfwdNrR3srmjkfz8uJNDpYExCCMOjg7h+agoxIS6mmDtF5KRGEORy8I9dR9h7pIlpwyK57ew0/rjxAA+9tYNfXDGO2pZ2clIjSI8M5PEV+1i9t4rnP93P5NRwjh5r57G/F5AYHsDtr+bx40vHMH9s72vufz8upMujmTM6hjWFNbR2dOG021i9r5qRscFWzNl7pInkcDc3vLiRpHA37949vUengMej+WSfEcfWFFZb78M7MuudM7umsIZgfwcKyIgNpstzojLJ28G/fNcRVu+txqONDvrZo0+U93ente7VMXGsvZOSmhYuNdvcu/VPYlhAj5XvvaO+4W4nEW4/qpvbaO90EOZ24nTYeOc70wGjmumJj/ZR29xGZJCLrQeNUczQAD/eya/ApsCjjYTxmtwUTrZqTxUNxztobO3oEXvzzNLlioZWCg43WR39v3h/D50ezdqiGtYW1nBOptHRVNXUyoJn1/GNc9MpO3qM7OSeu4+Euf36XQDKO/K6tqiG788byd4jjdZn3wnJYVZMbmnr5OmVRYQE+HH5xEQc5jo03qlFRxpbOdLQSpw5APJlVu+tIq/0KD+4YOSXPreupd3aAu1U+bcms+LMMyK2d0LppZRi4eQkFnYrUT7W3sn6oloyYoKsRa683rhjGqW1x9hQXMvqvVUEuRzMGxPLqLgQvj93JM+sKqT86HH2VTYRHezqtWDHyaKDXfztnuk8+tddRAQ6iQ3x52eXj+OWlzdz/5+3kxETRE5qOG9sKeOcTGPULNDlICbYxeubDnKksZWbpqUSE+yPzbzptnZ4eGD+SOvcvaU1f9p0kHC3HzNHRrPanCszPimMMYmhrNpbTVSQi3tnZVoLkISZWypcmp3A+zsPc9+b+YyOD+nRVnGh/uSmRvDejgouzo7nfz4qZPfhRn595Xge/3AvlY1t1pYBAOOTQwlzO6lubOPplYV4tGZYdCDPXD+JOU98wuq91QyPDmJ9kbFdy1nDIxmbGMo/dh7myslJXP/iJr65OI/CymY6ujy8eEsu4xJD+c0Hewl02bHZFNHBLqqb2/jjxgPWKOTiDQesMrYbpqbybn4F64trOW9ENG9uKSM2xJ/zRxmJ7a5DDTyybCc7yhsYHh3IH26fit2mSI00ktnbpqfx1EeFrC+uoeBwE6PjQxhnJmnvmivuxof6kxQeQH5ZPbUt7UQFO1FKcc/5GXxjcR6P/b3AWOykrZMRsUG8vukgaZFuCquayS+rtxZp8f4Mvqgcqq2zq1fytL6olvZOD7NGxTA9I4o7Zhhzzd1+djbtr2NdUS3ri2tZeudZ2GyKvANHSY8KtEqmVhRUEhPs4paz03hzSxmLVhXT3uXh6LEOiqubOWCOok7PiGLxBmM17LmjY1lXVEtRVbP1AcXrSEMrUUEuazGl3Yeb2Flezz2zjIXiUiPdtHZ4WFdcQ3unh8umJvLyuhL2HmliZ3kDo+OCyUmL4KW1+61EemJy3yOz+WX1OO027puTyc/f38PdszJ46qNC8g/WEz+uWzJrjiLPGhnDezsO0+XR2G2KNzYfZK1ZRu79YJAW6bbmNTW3dXLvkm0EOO3My4plgbly+5rCGu5+fRu/uXI8V+V0X5pBiMFn/tj4L33OA/NH8cD8UT0+1LscdlbdP5OaljaCXA5iQ07c3x+7zEi82jq7mJcVa01bALhiUhJPrNjHltKjTEgO49dXjgeMTqnqpjbCA51kxARZuwZcnB3P7z8xVtG9f+5Izs2MYuehRu5+fRtgbA0Y7O/glbWltHd5+K9LsgDj3ut02PiflUayPd0sWU4MCyAy0Mmw6EAiA108vmIfShkrtR491sG9szMZGRvMd17/jOzkMKYNjyQ0wM+aYgLGNIwp6RFsLqkjISwAp91GR5cmxN/Bn791llVpdTLvKO+Vv9tAw/EObMpoq8mpEbx919kMizYqeTY+PBu3045SihunpbJ4Qyk3n5WKy2FnY4kxqp0RE8T35mbywedHuOmlzTjtNu6fZ3yYDzI7cn/9wR5sStHc1smmkjoum5CAv5+di8efSLSdDhtX5yTz6voSPNr4nBQT4s9/fG00D729k5tf3myde0JYAH/cdIA7Fm+lvcvDY5eNpaL+OLe/lsc1v99o7Be7spALxsSyt7KJzJhg7DZFXUs7f84r58rJSVwwJo6PCqrYVFLHjrJ6tpfV88srxpERE4RNGcms3abMLWwa2LC/lrOHR6G1pqmtk5LqFmqajYqlTwtrrPd88sgswHdnZ3LzWWk4HTZruk2g08GwqEAum5DA0rxy/OyKsYkhfLKvus+k9ZuL81hfVMPo+BB+feV4nA4byz47xOTUcLSG0dbIbID1NSbYZU3f8q57Ee42Rmb3VTbT0al7lNMDzBgRzeMr9rFidyXXTkkhr/QoDpvi3tmZ/PS93SyclMSawho+3VfTZzL79meHsNsUXR7N5pI6a979ltI6/OyKTo/mo4JKshKM9/pRQSX3zcnkz3nl/Gr5Hs4ePh2bTfHB55V0eTTvbKug/lhHr8+uYQHOfufMehPn7eUN1DS3UVzdwrwso2NjQkoYyz8/Ql1LO1tK62jv8lDT3ManhdXMGmWc67ayemshrfyyeuaH9t8R59XW2cUjb++koqGVq3OSCXDaqW1p67X9GRjTwS5ftI6nrpnYZ4fLv4sks2JAuZ0O5mT13VOnlCI9KpD0qECun9rzxjIuKZTf35QDGPM2Oro8PRbm6E9GTDBv3HGW9X1uWgSv3JrLL5fv4acLxpIVH8JdM4dbZaoAP5g3kr9sLcffz8a3zH0IIwOdhLn9SI1wc9G4EwHY5bBz4dg4c1Gtkbhddq5YtJ49Zu/ZvKxYoxToltwec5JTIgJICPXnlwvHMXVYBMVVLfzwgpE95h4DXDQ+nh+Z83ycDhv3zMpg4aQk9h5p4qW1JdbILMCfvjENgG0Hj3L5ovWEuf14+ZZc0qICGR4dyNItZXzw+RFrrs7ElDBcDrt1g75iYiLvbK/gnIwo/uOi0VZHxa1np1k9ojHB/qwrqmVdUS3njzQWN3l1fSkzR0TjtNsYlxjKeSOieWHNfjaX1Fm9hjdOS+HbMzO4609baevw8PCFo7g6J5lwszfPaP9qzhsRzYbiWv667RDHO7o4b8RwxiSEMCzamBflsCmigoxEcNXLW+jyaGuRiNmjY8iKD+HV9aVEBDp5/uYcpqRHsPNQA8OiA5n6s5UszSunttm7EqPDDPB9J7NPrNjHolVFzBoVwz2zMhmXFEplYys/e7+AcLef9SHKy+200+nROO028g4cZfGGUrISQtl64Cg/uiSLIJeDYH8HTa2dXDw+AbtNMWNEFHsrm6zR8+W7jlB+9BiRgU5Gm4HD6bAxwxzBKO6WzL63o4JX1pXS3ukhLtTfCvyvrS/Fo7F6hb1J7nvbjcWmFk42ktk9R5rYVdHAJdkJTEgOo6NLs9wsbUuPCiTE39Gr/Cr/YD1ZCSHcfs4wJqdGMDYxhEWriskvr+fCbr8XRVXNBPs7mJIewdvbDlFRf5z9NS089LYxmu+wKWued2pkIH/bXkFbZxevrivh4z1VxIf68/cdh7EpxSXZCfzuk2JiQ1xc2sfIjBBD2ckf9EPdftYKp31xOew8f3NOj2P3zs7ka+Pi2LC/jkvHJ1gln7+5Mpsus5Lp0YuyrO0lHr5wNJdPTGRLSR0XjY/Hz27jz3eexe8+KSY5IoDLJxqdqguyE1lXVMMcc3TNYbfx8i25vJlXRnNrh7W/vb+fnQ0Pz8bPbryX9cW1pES4SQwLYH9NM8OiglDK6LCelBKO02Fj+4/m9WqHH8wbya2vbGZMQog1PeH+eSP7TWTBuFd5y5//6+Is5oyOtdpvYsqJe7S3TQDum5PJsm2HuPR/19FuzhGNDXER5nYS5nbyyNdG88iynXxr1nBrJCsm2MVHBcbo5Q/mjWDxhgNUNbX1WmvE69vnD+eNLQc51t5ljaRdk5vMwbpj5JfVMyklnIzoIGw2xaMXZXHPkm3MNsuOR8UFk50UyvbyBi6fmMiybYe478183smv4IapKfzs8nEs2XyQtk4PX5+eTnKEG5fDxn8s20lF/XEum5DANbnJKGVsy/jxnip2HWogKsgJKJ5bXUx8aACPvbebT/ZVMzk1HKWMcvTFGw9Qf6ydMLez18gsGJUJ3mlnJ1YzdmCzKZ66diI3nZVKW6eH8rrjPPDWDjO+nUiC8krrWLG7knMzo/i8opGbXtqM1pqKhlaGm+tYeMuML5+YiJ/DmG8cG+LPygJjulS9VWZs7LVc09zG8Y4uqwTfa1xiKOMSQ3nyo31ckp1AXulRxiSGcnVOEtvL6vnO+RkoZYwmd3Z5rNHMoqpmNuyvZdXeKq6fksLSvDI2FNeywZyetaW0juykMLq0kcxemp3Ad9/YRkZMEN86bzipkW6+9+Z23vqsnKtykvnAnCvtncbjrdryCg3w63PObE1zGyU1LcwaFcPHe6p4eqUxEj+y28gsGKOvHxdUEexvzO/+y9ZyK5nNL6vnnIwoNu6vZXt5PfPHxrGyoJIlm8t4+roJuJ2908I3t5RZi6+9v+swawqr+exAPZ88MNOakwzGiP6jf92F2+noMZf9VJBkVgx5J99c/1lTh0Wy7NvTre+7J7IAV+cmc3Vuz9EfpRQv3ZJDfGhArw8fz904ucf3L92aY86lsXP7Oel9zvN59KIsfjhvFG6ngxumpvZ7rgsnJ1Hb0k5CqD/nZEZZc5NuPTuNY+2djI7vPTI+MSWcJ67OZmRcsDVna9aoGF5YU0JKhJv7Zo9gwYSEXiOOv7pyPD9eMMYKUF7dy0y+OyeTZz4usuZ42W02rv7dBt7edogxCSE4HTaeuX4Sj/51F8u2lfPA/JHUNbfz4toSlmw25nIsvXMak1N73viumJSI02EjIyaI66akUHesnfSoQK7NTcblsLPsruk8+NYOWju7sNsUZw+PYtENk7hnyTZGmDd2pRSvfj2XqsY2RseHWKPn3hv+18bF8+YWY5Gpm89KRSlFWIAf726vYHNJHSH+frj8bAQ6HaRFBfL0ykImpoSx9cBRLl+0jovGx7Npfx1NrR0svn1qr/bzdkTced4wdpQ38N/v7SbBHLG41uz1jQ/1p6m12SqXu2BMHC+uLeHRi7J4fMVe/ra9AoddkRLpJj7MH5uC9MhAUiMDcTpsfFpYzcLJSZQfPcaDf9lhzUudmxVLTLCLYJeDrQeOEhnotOa9eq/vtz4rJ8ztR1Z8CMkRAby+6SBNrZ1kJ4Vy1rBIooKcrN5bTbC5MmV8aIC1rcTmEqMneuehBq7JTcZuU1ZSPTohhPyD9T164IurmxkeHWRtnVBY1cQv3t9DaqSbxy4bS6c5UguQGuHGo6HgcBPPf7qf2aNiWHTjJG54YRM//Mt2Cg43sr64locvHCUlxkL0IyMmmIyYnvGgewI3Y0TPnSFGxYX0SDKcDhv3zu657V9WQohVQul1TmaU1VHWXfd1NbwVSN7z8uproa3upqRHsOvHF2CzKVIj3Lxya26PUuS+KKX44HszcNhsvaq9+hPmdvLYZWN5b0cFM0ZEE+RyWKtbA1w3JZkxCSFWsg7w26uy2bi/lsrGNq7JTebosQ5eWlvSq829ooJcfPPcYTyzqshqQ6UUD8wf1eu5F4+Pp7Wjy2pXpRTP3jCJ/dUtTEmP4JN91byTX0FCqD9/2nQQt9POO/kVnJsZRabZ6TxvTBzrimq4bXo6988bYd2Lvz93hDXi/vXp6UQE+vHbD/dx/m9X43TYGB4dZK4bEsalExJ4bcMBvvFaHhpjASyXw4bLz/jZjkkI6ZGInVjN+MR92Rvbj0QZydATH+6jtqWdhZOSuCY3mac/LiIi0Mnvb5pMcVUL1z6/AafDxqSUMD47WE+wv8MqWw8PdHLTNOPzUXyoP8c7upj/1BqqmlpRCiICnZw3MppX1pdS19JOWGDPzy42m+LHl45h4XPrue/NfPLL67l5WirB/n48fd1EwFiAbGleOVN+vpIxCSFcMCaOx/6+m9YOD06HjZvOSqWoqpnXNx+gtcODUmBTijtmDCPI5eA3H+xl5m9XE+b248Wbc/D3s7MgO5E/bDjAr5bvYWp6JBv211qdEkCvkdlQtx/F1cZ6MUpBdVM7pbUt1pZ73zx3GBuKa1m84QBpkW5mmLuHjEsMxaaMsv+P91YxY0Q0McEu/rjxAC98up+5WbHsr25h4aQkGo53kH+wnqrGVr6/dDsNxzt4aU0JE1PCeX/XYb4909gP+73th1lXXMOUtAhaO7t4aW2JtU7Ksx8X8ZMFYymqaubJFftoNleL/s2V461Kt1NFklkh/p9OTsD6ExPsb/Ve9bedkq8JeZDLwffnjuh1PDnCzS+uGN/vv7tiUs/Vp++dncmsUbFMSY/oN+D72W1WGVp/pg2LZNqwyB6JyycPzGTJ5jLGmgE7wGnn8auz+cmCMdY8mgUTEnnyo33MyIzqsx3HJ4Ux3ky+5mTF9hq9D3X78bubenYazMmKZeeP51m9qdCz7U922/Q0th6o45rcFG6bngbA1GERbDtYj00pjjS20m6u1NlwvIPR8SEs+eY02jo8/Oc7u1hZUMXElDDumzOiV6kvYJawGYtu3HnecB58awd/33GYB+ePshLdtMhAOj3amt+akxbBZ4/OJTzQye7DDfz8/T0APHzhKORAYJEAAA1ySURBVPzsNlIjAxkRZ5SVXT8lhVfXl7KvsonG453YbIq7Zg7nudXGqKXDbmPl/efR2NpJbIjL+nCZGuHm1rPTCHI5mD82DqUUI2OD+aigigvHxrFgQiL+fsZoz7XPbyTWHIk4a3gkr64vZdJPV/RYnOLk3u8JSaEs2VLG+J98SEJoABeOi2PbwXouGh9PutmZ8sjbuzjS2MrvbpzcYxsvwFp07ftL82ls7eR7c0fgcth57sbJ3PmHPBatLibY39GrWkMIcfrxVlw57DZresqX+f90cl2SncAl2X1XeiilyD7pPhfmdvYoH79xWio7DzWQm9Y7FnjdOzuTS7ITepSL9/f/nTx9IincbXVeP3zhKDaV1PHfC8Zw5x+28sKaEhw2xV3nndhO8elrJ6A1vSrWLh6fwIHaY/zPykKuykliWLSxMFn9sQ6mpkeQGB7AT98rYPaoGLKTwogNcVnre3R6NBGBLtx+dkID/LjMnPbhFRPsj8ths6qCuosL9WdUXDAf7q4kzO3HI8t28p/v7KLLo3lwvtGRPy4plL/fey4uPxtNrZ3Mf+pTsuJD+vzcdNXkZI61d7H1wFHGJIQwNysWt9PBuZnR/OHrU7j3jW19rqMyOTWca3OTeWNLGcEuR48tusCo6LpzxjAajnew/PMjrCmsYVxiKE9fN5GEMH9cDjvThhkJ6ZT0CGqa2thf00JuWji5aREEOu3UtrQzf2ycNXhgsyn+e8FYLnlmLbOfWE2XR/P16ensq2zi84pGa/HNE+3oYsXuSuY++Wmv8/euGD5vTCw7DzXw+jemWZUHgS4H45PCeGaVsXjbrJExnJ0Rya5DDfzs/QJ+/g9jXZgJyWFUNrayNK+MW17ZQmtHF7lp4SxaXUyX1rR3eliy+aC1p+/U9AgenD+KlXuq+OU/9hDm9mPmiGheN6sB3t1eYVRXuRzMGR3Dwkm9dzv5d1NDbYPdnJwcnZeX9+VPFEKIr0BHl4ctJXWMiAvuUd7W19yf7j47eNQomzJ7krXWbC9vYFxiqNWBUNPcRkeXp8diSV4Nxzt4cc1+5o+Ns7ZBKq5uJtjlICbEH601b392iCWbDxLk7+Ab5wxjekYkz3xcxHkjo63OAF8UHDZWHb00O6HHe1pvzqudOTIGrTV/23GYd/MPMWd0LE2tnazcU8mz10+y9nMGWFlQye2v5TFndAz7Kps5WHeMacMi+PXCbJIjApj9+Cd0eDxcm5vCt2cO79WGdS3tTPnZR/j72blnVgZ3ntdzv+v8snocNtVjlORfpZTaqrXO+fJniv5IbBbi1NNaU9PcTmiAX5+7TPTnWHtnnyWlJ2tp6zQ7thV7jjSRGunG7XTQcLyDYJejV7Jc3dRGZKCzz2lfG4qN1Zuvyklixe5Kdh5qINjfwdenp/fZmf/G5oMkhAX0qiLwhcej+516prWmrdPzpQMIdS3tLN91hEsnJFgd8WCUHT+ybCePX5VNc1sni1YX86uF4760PdcV1fCPXYfRGh67bCx/2HiApXll/O3uc3rEwbqWdjbtr8WjwaM1wf4OIgNdPLuqiNgQFz9ZMJaOLg92pXq9x8rGVv6ytZzCyiZ+etlYgs3Kun2VTSzZfJCiqmaevymHbWVHeeAvO3Dabdw9K4MJyWHMe/JTMmKC+O1V2bz1WbmxbsukJOvzSlndMWb+djX3zc7kqpxkFj63ntaOLsYlhfLLK8b7vJjUP8PX2CzJrBBCiK+U94NSW2cXRxpaSYlwW8HaG3O+qCOg4HAjCaEBXzhX8Kskyey/TmKzEEIMXUVVzcSF+vdI3E9WWtNCcoTb5xL+f5WvsVnKjIUQQnylvD3ULoe91xz0L0pivbyrVwohhBDi36+/xcu6O3mv7MHC95oEIYQQQgghhBBikJBkVgghhBBCCCHEkCPJrBBCCCGEEEKIIUeSWSGEEEIIIYQQQ44ks0IIIYQQQgghhhxJZoUQQgghhBBCDDmSzAohhBBCCCGEGHIkmRVCCCGEEEIIMeRIMiuEEEIIIYQQYshRWuuBPod/ilKqGjjwFb1cFFDzFb3W6UzayTfSTr6RdvKNtJNvvop2StVaR38VJ3Omktg8IKSdfCPt5BtpJ99IO/nmlMXmIZfMfpWUUnla65yBPo/BTtrJN9JOvpF28o20k2+knU4/8jP1jbSTb6SdfCPt5BtpJ9+cynaSMmMhhBBCCCGEEEOOJLNCCCGEEEIIIYacMz2ZfX6gT2CIkHbyjbSTb6SdfCPt5Btpp9OP/Ex9I+3kG2kn30g7+UbayTenrJ3O6DmzQgghhBBCCCGGpjN9ZFYIIYQQQgghxBB0RiazSqn5Sqm9SqkipdRDA30+g4lSqlQptVMpla+UyjOPRSilViilCs2v4QN9nqeaUuplpVSVUmpXt2N9tosyPG1eXzuUUpMG7sxPvX7a6sdKqUPmdZWvlPpat7972GyrvUqpCwbmrE8tpVSyUmqVUqpAKfW5Uuq75nG5prr5gnaS6+k0JLG5fxKb+yax2TcSl30jsdk3gy02n3HJrFLKDjwLXAhkAdcppbIG9qwGnfO11hO6Lan9ELBSa50JrDS/P9O8Csw/6Vh/7XIhkGn+uQN47hSd42DxKr3bCuBJ87qaoLV+H8D83bsWGGP+m0Xm7+jprhO4X2s9GpgGfMdsC7mmeuqvnUCup9OKxGafSGzu7VUkNvviVSQu+0Jis28GVWw+45JZYApQpLXer7VuB94AFgzwOQ12C4DXzMevAZcN4LkMCK31p0DdSYf7a5cFwGJt2AiEKaXiT82ZDrx+2qo/C4A3tNZtWusSoAjjd/S0prU+rLX+zHzcBBQAicg11cMXtFN/zsjr6TQhsfmfJ7FZYrNPJC77RmKzbwZbbD4Tk9lEoKzb9+V88Q/gTKOBD5VSW5VSd5jHYrXWh8G4gIGYATu7waW/dpFrrG93m2U4L3crhzvj20oplQZMBDYh11S/TmonkOvpdCM/uy8msdl3ch/1ndxH+yGx2TeDITaficms6uOYLOl8wnSt9SSM0onvKKVmDPQJDUFyjfX2HDAcmAAcBh43j5/RbaWUCgLeAu7TWjd+0VP7OHYmt5NcT6cf+dl9MYnN/zq5xnqS+2g/JDb7ZrDE5jMxmS0Hkrt9nwRUDNC5DDpa6wrzaxWwDKMMoNJbNmF+rRq4MxxU+msXucZOorWu1Fp3aa09wAucKC85Y9tKKeWHEQT+pLV+2zws19RJ+monuZ5OS/Kz+wISm/8pch/1gdxH+yax2TeDKTaficnsFiBTKZWulHJiTEh+d4DPaVBQSgUqpYK9j4F5wC6M9rnFfNotwDsDc4aDTn/t8i5ws7nK3TSgwVuecqY6aQ7J5RjXFRhtda1SyqWUSsdYRGHzqT6/U00ppYCXgAKt9RPd/kquqW76aye5nk5LEpv7IbH5nyb3UR/IfbQ3ic2+GWyx2fFVvdBQobXuVErdDXwA2IGXtdafD/BpDRaxwDLjGsUBvK61Xq6U2gIsVUrdDhwErhrAcxwQSqklwEwgSilVDvwI+CV9t8v7wNcwJrgfA2475Sc8gPppq5lKqQkYZSWlwJ0AWuvPlVJLgd0Yq+N9R2vdNRDnfYpNB24Cdiql8s1jjyDX1Mn6a6fr5Ho6vUhs/kISm/shsdk3Epd9JrHZN4MqNiutz5jSbiGEEEIIIYQQp4kzscxYCCGEEEIIIcQQJ8msEEIIIYQQQoghR5JZIYQQQgghhBBDjiSzQgghhBBCCCGGHElmhRBCCCGEEEIMOZLMCjEIKaW6lFL53f489BW+dppSateXP1MIIYQQXhKbhRh8zrh9ZoUYIo5rrScM9EkIIYQQwiKxWYhBRkZmhRhClFKlSqlfKaU2m38yzOOpSqmVSqkd5tcU83isUmqZUmq7+eds86XsSqkXlFKfK6U+VEoFmM+/Vym123ydNwbobQohhBBDhsRmIQaOJLNCDE4BJ5UyXdPt7xq11lOAZ4CnzGPPAIu11uOBPwFPm8efBj7RWmcDk4DPzeOZwLNa6zFAPbDQPP4QMNF8nW/9u96cEEIIMQRJbBZikFFa64E+ByHESZRSzVrroD6OlwKztNb7lVJ+wBGtdaRSqgaI11p3mMcPa62jlFLVQJLWuq3ba6QBK7TWmeb3DwJ+WuvHlFLLgWbgr8BftdbN/+a3KoQQQgwJEpuFGHxkZFaIoUf387i/5/SlrdvjLk7Mn78IeBaYDGxVSsm8eiGEEOLLSWwWYgBIMivE0HNNt68bzMfrgWvNxzcAa83HK4G7AJRSdqVUSH8vqpSyAcla61XAA0AY0KsHWgghhBC9SGwWYgBIz44Qg1OAUiq/2/fLtdbeLQBcSqlNGJ1R15nH7gVeVkr9EKgGbjOPfxd4Xil1O0Yv713A4X7+TzvwR6VUKKCAJ7XW9V/ZOxJCCCGGNonNQgwyMmdWiCHEnJeTo7WuGehzEUIIIYTEZiEGkpQZCyGEEEIIIYQYcmRkVgghhBBCCCHEkCMjs0IIIYQQQgghhhxJZoUQQgghhBBCDDmSzAohhBBCCCGEGHIkmRVCCCGEEEIIMeRIMiuEEEIIIYQQYsiRZFYIIYQQQgghxJDzfzk8BDBv02vuAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1152x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(2,figsize=(16,10))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.plot(history_dp_relu_20.history['val_loss'])\n",
    "plt.plot(history_dp_relu_20.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO RELU--DROPOUT DE 20%')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.plot(history_dp_relu_40.history['val_loss'])\n",
    "plt.plot(history_dp_relu_40.history['loss'])\n",
    "plt.legend(('Val_Loss', 'Loss' ))\n",
    "plt.title('MODELO RELU--DROPOUT DE 40%')\n",
    "plt.ylabel('MSE')\n",
    "plt.xlabel('Epochs')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<IMG SRC=\"2.PNG\" WIDTH=640 HEIGHT=480 BORDER=0 ALT=\"Un beb&eacute;\" ALIGN=\"CENTER\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=justify>Al igual que en el caso anterior la primera mención que se debe realizar es que en magnitud de error en ambos cosas con Dropout de 20% y 40% hay un mejor resultado que el modelo original, pero si se pueden observar unos picos en la función de pérdida de validación que en unos precisos instantes de tiempo suelen ser más altos que la función de pérdida en el set de entrenamiento, se debería analizar qué tan robusto es este tipo de algoritmo, pues al tener un comportamiento sin estabilidad definida se podría entrar en momentos para los cuales el algoritmo no es capaz de generalizar correctamente ante nuevas muestras. </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify><b> j) Fijando todos los demás hiper-parámetros del modelo definido en b) y en c), utilice validación cruzada con un número de *folds* igual a *K* = 5 y *K*=10 para determinar el mejor valor correspondiente a un parámetro que usted elija (tasa de aprendizaje, número de neuronas, parámetro de regularización, etc) ¿El mejor parámetro para la red con sigmoidal es distinto que para ReLU? ¿Porqué sucede? Además mida el error real del modelo sobre el conjunto de pruebas, compare y concluya. </b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:12: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(256, input_dim=1275, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "  if sys.path[0] == '':\n",
      "C:\\Users\\Jesus\\AppData\\Local\\conda\\conda\\envs\\keras1\\lib\\site-packages\\ipykernel_launcher.py:14: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, kernel_initializer=\"uniform\", kernel_regularizer=<keras.reg...)`\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/250\n",
      "7796/7796 [==============================] - 3s 445us/step - loss: 126.4633\n",
      "Epoch 2/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 110.9690\n",
      "Epoch 3/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 96.2813\n",
      "Epoch 4/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 82.1478\n",
      "Epoch 5/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 68.8160\n",
      "Epoch 6/250\n",
      "7796/7796 [==============================] - 3s 355us/step - loss: 56.5276\n",
      "Epoch 7/250\n",
      "7796/7796 [==============================] - 3s 420us/step - loss: 45.4896\n",
      "Epoch 8/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 35.8840\n",
      "Epoch 9/250\n",
      "7796/7796 [==============================] - 3s 378us/step - loss: 27.8413\n",
      "Epoch 10/250\n",
      "7796/7796 [==============================] - 3s 390us/step - loss: 21.2852\n",
      "Epoch 11/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 16.0819\n",
      "Epoch 12/250\n",
      "7796/7796 [==============================] - 3s 432us/step - loss: 12.1556\n",
      "Epoch 13/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 9.3425\n",
      "Epoch 14/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 7.4229\n",
      "Epoch 15/250\n",
      "7796/7796 [==============================] - 3s 346us/step - loss: 6.1618\n",
      "Epoch 16/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 5.3359\n",
      "Epoch 17/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 4.7425\n",
      "Epoch 18/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 4.2839\n",
      "Epoch 19/250\n",
      "7796/7796 [==============================] - 3s 411us/step - loss: 3.9223\n",
      "Epoch 20/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 3.6264\n",
      "Epoch 21/250\n",
      "7796/7796 [==============================] - 3s 412us/step - loss: 3.3725\n",
      "Epoch 22/250\n",
      "7796/7796 [==============================] - 3s 432us/step - loss: 3.1541\n",
      "Epoch 23/250\n",
      "7796/7796 [==============================] - 3s 396us/step - loss: 2.9637 \n",
      "Epoch 24/250\n",
      "7796/7796 [==============================] - 3s 420us/step - loss: 2.8032\n",
      "Epoch 25/250\n",
      "7796/7796 [==============================] - 3s 426us/step - loss: 2.6579\n",
      "Epoch 26/250\n",
      "7796/7796 [==============================] - 3s 414us/step - loss: 2.5299 0s - loss: 2\n",
      "Epoch 27/250\n",
      "7796/7796 [==============================] - 3s 413us/step - loss: 2.4150\n",
      "Epoch 28/250\n",
      "7796/7796 [==============================] - 3s 396us/step - loss: 2.3095\n",
      "Epoch 29/250\n",
      "7796/7796 [==============================] - 3s 384us/step - loss: 2.2140\n",
      "Epoch 30/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 2.1280\n",
      "Epoch 31/250\n",
      "7796/7796 [==============================] - 3s 405us/step - loss: 2.0480\n",
      "Epoch 32/250\n",
      "7796/7796 [==============================] - 3s 357us/step - loss: 1.9733\n",
      "Epoch 33/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 1.9035\n",
      "Epoch 34/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 1.8386\n",
      "Epoch 35/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 1.7784\n",
      "Epoch 36/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 1.7210\n",
      "Epoch 37/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 1.6683\n",
      "Epoch 38/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 1.6174\n",
      "Epoch 39/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 1.5699\n",
      "Epoch 40/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 1.5240\n",
      "Epoch 41/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 1.4825\n",
      "Epoch 42/250\n",
      "7796/7796 [==============================] - 3s 346us/step - loss: 1.4433\n",
      "Epoch 43/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 1.4051\n",
      "Epoch 44/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 1.3704\n",
      "Epoch 45/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 1.3377\n",
      "Epoch 46/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 1.3074\n",
      "Epoch 47/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 1.2779\n",
      "Epoch 48/250\n",
      "7796/7796 [==============================] - 3s 404us/step - loss: 1.2506\n",
      "Epoch 49/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 1.2246\n",
      "Epoch 50/250\n",
      "7796/7796 [==============================] - 3s 404us/step - loss: 1.1994\n",
      "Epoch 51/250\n",
      "7796/7796 [==============================] - 3s 389us/step - loss: 1.1756\n",
      "Epoch 52/250\n",
      "7796/7796 [==============================] - 3s 410us/step - loss: 1.1526\n",
      "Epoch 53/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 1.1303\n",
      "Epoch 54/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 1.1092\n",
      "Epoch 55/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 1.0887\n",
      "Epoch 56/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 1.0690\n",
      "Epoch 57/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 1.0507\n",
      "Epoch 58/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 1.0332\n",
      "Epoch 59/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 1.0157\n",
      "Epoch 60/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.9993\n",
      "Epoch 61/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.9837\n",
      "Epoch 62/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 0.9679\n",
      "Epoch 63/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 0.9544\n",
      "Epoch 64/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.9404\n",
      "Epoch 65/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.9272\n",
      "Epoch 66/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.9145\n",
      "Epoch 67/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.9024\n",
      "Epoch 68/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.8904\n",
      "Epoch 69/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.8788\n",
      "Epoch 70/250\n",
      "7796/7796 [==============================] - 3s 397us/step - loss: 0.8677\n",
      "Epoch 71/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.8569\n",
      "Epoch 72/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.8454\n",
      "Epoch 73/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 0.8358\n",
      "Epoch 74/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 0.8256\n",
      "Epoch 75/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.8165\n",
      "Epoch 76/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 0.8073\n",
      "Epoch 77/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 0.7984\n",
      "Epoch 78/250\n",
      "7796/7796 [==============================] - 3s 413us/step - loss: 0.7899\n",
      "Epoch 79/250\n",
      "7796/7796 [==============================] - 3s 429us/step - loss: 0.7815\n",
      "Epoch 80/250\n",
      "7796/7796 [==============================] - 3s 399us/step - loss: 0.7737\n",
      "Epoch 81/250\n",
      "7796/7796 [==============================] - 3s 422us/step - loss: 0.7661\n",
      "Epoch 82/250\n",
      "7796/7796 [==============================] - 3s 409us/step - loss: 0.7588\n",
      "Epoch 83/250\n",
      "7796/7796 [==============================] - 3s 422us/step - loss: 0.7517\n",
      "Epoch 84/250\n",
      "7796/7796 [==============================] - 3s 407us/step - loss: 0.7450\n",
      "Epoch 85/250\n",
      "7796/7796 [==============================] - 3s 411us/step - loss: 0.7385\n",
      "Epoch 86/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 0.7315\n",
      "Epoch 87/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.7253\n",
      "Epoch 88/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.7193\n",
      "Epoch 89/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 0.7137\n",
      "Epoch 90/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.7079\n",
      "Epoch 91/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.7023\n",
      "Epoch 92/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 0.6969\n",
      "Epoch 93/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.6918\n",
      "Epoch 94/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.6870\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 95/250\n",
      "7796/7796 [==============================] - 3s 403us/step - loss: 0.6823\n",
      "Epoch 96/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 0.6775\n",
      "Epoch 97/250\n",
      "7796/7796 [==============================] - 3s 418us/step - loss: 0.6725\n",
      "Epoch 98/250\n",
      "7796/7796 [==============================] - 3s 391us/step - loss: 0.6687\n",
      "Epoch 99/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.6641\n",
      "Epoch 100/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.6605\n",
      "Epoch 101/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.6562\n",
      "Epoch 102/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.6524\n",
      "Epoch 103/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.6487\n",
      "Epoch 104/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 0.6453\n",
      "Epoch 105/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 0.6418\n",
      "Epoch 106/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.6382\n",
      "Epoch 107/250\n",
      "7796/7796 [==============================] - ETA: 0s - loss: 0.635 - 3s 339us/step - loss: 0.6348\n",
      "Epoch 108/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.6322\n",
      "Epoch 109/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 0.6290\n",
      "Epoch 110/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.6258\n",
      "Epoch 111/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 0.6232\n",
      "Epoch 112/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 0.6199\n",
      "Epoch 113/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.6176\n",
      "Epoch 114/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 0.6146\n",
      "Epoch 115/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.6120\n",
      "Epoch 116/250\n",
      "7796/7796 [==============================] - 3s 323us/step - loss: 0.6095\n",
      "Epoch 117/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 0.6073\n",
      "Epoch 118/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 0.6045\n",
      "Epoch 119/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.6018\n",
      "Epoch 120/250\n",
      "7796/7796 [==============================] - 3s 322us/step - loss: 0.6000\n",
      "Epoch 121/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 0.5976\n",
      "Epoch 122/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 0.5953\n",
      "Epoch 123/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 0.5933\n",
      "Epoch 124/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 0.5912\n",
      "Epoch 125/250\n",
      "7796/7796 [==============================] - 3s 326us/step - loss: 0.5894\n",
      "Epoch 126/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 0.5868\n",
      "Epoch 127/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 0.5851\n",
      "Epoch 128/250\n",
      "7796/7796 [==============================] - 3s 325us/step - loss: 0.5835\n",
      "Epoch 129/250\n",
      "7796/7796 [==============================] - 3s 327us/step - loss: 0.5814\n",
      "Epoch 130/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.5795 0s - los\n",
      "Epoch 131/250\n",
      "7796/7796 [==============================] - 3s 327us/step - loss: 0.5778\n",
      "Epoch 132/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.5764\n",
      "Epoch 133/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 0.5742\n",
      "Epoch 134/250\n",
      "7796/7796 [==============================] - 3s 325us/step - loss: 0.5723\n",
      "Epoch 135/250\n",
      "7796/7796 [==============================] - 3s 326us/step - loss: 0.5707\n",
      "Epoch 136/250\n",
      "7796/7796 [==============================] - 3s 322us/step - loss: 0.5695\n",
      "Epoch 137/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.5677\n",
      "Epoch 138/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.5660\n",
      "Epoch 139/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.5646\n",
      "Epoch 140/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 0.5630 0s \n",
      "Epoch 141/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 0.5615\n",
      "Epoch 142/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.5602\n",
      "Epoch 143/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 0.5589\n",
      "Epoch 144/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.5574\n",
      "Epoch 145/250\n",
      "7796/7796 [==============================] - 3s 355us/step - loss: 0.5564\n",
      "Epoch 146/250\n",
      "7796/7796 [==============================] - 3s 400us/step - loss: 0.5545\n",
      "Epoch 147/250\n",
      "7796/7796 [==============================] - 3s 406us/step - loss: 0.5528\n",
      "Epoch 148/250\n",
      "7796/7796 [==============================] - 3s 355us/step - loss: 0.5519\n",
      "Epoch 149/250\n",
      "7796/7796 [==============================] - 3s 400us/step - loss: 0.5505\n",
      "Epoch 150/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 0.5497\n",
      "Epoch 151/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 0.5481\n",
      "Epoch 152/250\n",
      "7796/7796 [==============================] - 3s 421us/step - loss: 0.5464\n",
      "Epoch 153/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.5459\n",
      "Epoch 154/250\n",
      "7796/7796 [==============================] - 3s 325us/step - loss: 0.5447\n",
      "Epoch 155/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 0.5435\n",
      "Epoch 156/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 0.5425\n",
      "Epoch 157/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 0.5415\n",
      "Epoch 158/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 0.5405\n",
      "Epoch 159/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.5396\n",
      "Epoch 160/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 0.5379\n",
      "Epoch 161/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 0.5376\n",
      "Epoch 162/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 0.5360\n",
      "Epoch 163/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.5356\n",
      "Epoch 164/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 0.5342\n",
      "Epoch 165/250\n",
      "7796/7796 [==============================] - 3s 378us/step - loss: 0.5336\n",
      "Epoch 166/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 0.5324\n",
      "Epoch 167/250\n",
      "7796/7796 [==============================] - 3s 404us/step - loss: 0.5315 0s - \n",
      "Epoch 168/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.5307\n",
      "Epoch 169/250\n",
      "7796/7796 [==============================] - 3s 402us/step - loss: 0.5295 0s - \n",
      "Epoch 170/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.5289\n",
      "Epoch 171/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.5282\n",
      "Epoch 172/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.5271\n",
      "Epoch 173/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.5266\n",
      "Epoch 174/250\n",
      "7796/7796 [==============================] - 3s 385us/step - loss: 0.5255\n",
      "Epoch 175/250\n",
      "7796/7796 [==============================] - 3s 386us/step - loss: 0.5249\n",
      "Epoch 176/250\n",
      "7796/7796 [==============================] - 3s 381us/step - loss: 0.5238 0s - loss: 0\n",
      "Epoch 177/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.5231\n",
      "Epoch 178/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.5225\n",
      "Epoch 179/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.5218\n",
      "Epoch 180/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 0.5204\n",
      "Epoch 181/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.5204 \n",
      "Epoch 182/250\n",
      "7796/7796 [==============================] - 3s 326us/step - loss: 0.5190\n",
      "Epoch 183/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.5188\n",
      "Epoch 184/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.5179\n",
      "Epoch 185/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.5171\n",
      "Epoch 186/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 0.5166\n",
      "Epoch 187/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.5157\n",
      "Epoch 188/250\n",
      "7796/7796 [==============================] - 3s 355us/step - loss: 0.5150\n",
      "Epoch 189/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.5146\n",
      "Epoch 190/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.5141\n",
      "Epoch 191/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.5132\n",
      "Epoch 192/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.5129\n",
      "Epoch 193/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.5118\n",
      "Epoch 194/250\n",
      "7796/7796 [==============================] - 3s 426us/step - loss: 0.5111\n",
      "Epoch 195/250\n",
      "7796/7796 [==============================] - 3s 439us/step - loss: 0.5105 2s - los\n",
      "Epoch 196/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.5100\n",
      "Epoch 197/250\n",
      "7796/7796 [==============================] - 3s 368us/step - loss: 0.5094\n",
      "Epoch 198/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.5092\n",
      "Epoch 199/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 0.5085\n",
      "Epoch 200/250\n",
      "7796/7796 [==============================] - 3s 357us/step - loss: 0.5077\n",
      "Epoch 201/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.5075\n",
      "Epoch 202/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.5070\n",
      "Epoch 203/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.5061\n",
      "Epoch 204/250\n",
      "7796/7796 [==============================] - 3s 422us/step - loss: 0.5060\n",
      "Epoch 205/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.5052\n",
      "Epoch 206/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.5045\n",
      "Epoch 207/250\n",
      "7796/7796 [==============================] - 3s 391us/step - loss: 0.5042\n",
      "Epoch 208/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 0.5038\n",
      "Epoch 209/250\n",
      "7796/7796 [==============================] - 3s 412us/step - loss: 0.5032\n",
      "Epoch 210/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.5023\n",
      "Epoch 211/250\n",
      "7796/7796 [==============================] - 3s 407us/step - loss: 0.5019\n",
      "Epoch 212/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.5013\n",
      "Epoch 213/250\n",
      "7796/7796 [==============================] - 3s 371us/step - loss: 0.5010\n",
      "Epoch 214/250\n",
      "7796/7796 [==============================] - 3s 378us/step - loss: 0.5002\n",
      "Epoch 215/250\n",
      "7796/7796 [==============================] - 3s 408us/step - loss: 0.4997\n",
      "Epoch 216/250\n",
      "7796/7796 [==============================] - 3s 428us/step - loss: 0.4991\n",
      "Epoch 217/250\n",
      "7796/7796 [==============================] - 3s 374us/step - loss: 0.4987 0s - loss: 0.49\n",
      "Epoch 218/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.4977\n",
      "Epoch 219/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.4974\n",
      "Epoch 220/250\n",
      "7796/7796 [==============================] - 3s 391us/step - loss: 0.4970\n",
      "Epoch 221/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.4966\n",
      "Epoch 222/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.4963\n",
      "Epoch 223/250\n",
      "7796/7796 [==============================] - 3s 357us/step - loss: 0.4958\n",
      "Epoch 224/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 0.4950\n",
      "Epoch 225/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 0.4951\n",
      "Epoch 226/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 0.4947\n",
      "Epoch 227/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.4941\n",
      "Epoch 228/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 0.4938\n",
      "Epoch 229/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.4933\n",
      "Epoch 230/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.4928\n",
      "Epoch 231/250\n",
      "7796/7796 [==============================] - 3s 376us/step - loss: 0.4926\n",
      "Epoch 232/250\n",
      "7796/7796 [==============================] - 3s 412us/step - loss: 0.4919\n",
      "Epoch 233/250\n",
      "7796/7796 [==============================] - 3s 402us/step - loss: 0.4917\n",
      "Epoch 234/250\n",
      "7796/7796 [==============================] - 3s 346us/step - loss: 0.4913\n",
      "Epoch 235/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 0.4907\n",
      "Epoch 236/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 0.4902\n",
      "Epoch 237/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.4901\n",
      "Epoch 238/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 0.4894\n",
      "Epoch 239/250\n",
      "7796/7796 [==============================] - 3s 326us/step - loss: 0.4893\n",
      "Epoch 240/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.4887\n",
      "Epoch 241/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 0.4885\n",
      "Epoch 242/250\n",
      "7796/7796 [==============================] - 3s 327us/step - loss: 0.4879\n",
      "Epoch 243/250\n",
      "7796/7796 [==============================] - 3s 325us/step - loss: 0.4875\n",
      "Epoch 244/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.4874\n",
      "Epoch 245/250\n",
      "7796/7796 [==============================] - 3s 326us/step - loss: 0.4868\n",
      "Epoch 246/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.4867\n",
      "Epoch 247/250\n",
      "7796/7796 [==============================] - 3s 323us/step - loss: 0.4863\n",
      "Epoch 248/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.4858\n",
      "Epoch 249/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.4855 0s - los\n",
      "Epoch 250/250\n",
      "7796/7796 [==============================] - 3s 411us/step - loss: 0.4854\n",
      "1949/1949 [==============================] - 0s 116us/step\n",
      "Epoch 1/250\n",
      "7796/7796 [==============================] - 4s 501us/step - loss: 120.6025\n",
      "Epoch 2/250\n",
      "7796/7796 [==============================] - 3s 431us/step - loss: 104.9412\n",
      "Epoch 3/250\n",
      "7796/7796 [==============================] - 3s 385us/step - loss: 89.8886\n",
      "Epoch 4/250\n",
      "7796/7796 [==============================] - 3s 365us/step - loss: 75.8031\n",
      "Epoch 5/250\n",
      "7796/7796 [==============================] - 3s 421us/step - loss: 62.8885\n",
      "Epoch 6/250\n",
      "7796/7796 [==============================] - 3s 389us/step - loss: 51.3155\n",
      "Epoch 7/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 41.1757\n",
      "Epoch 8/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 32.5565\n",
      "Epoch 9/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 25.5031\n",
      "Epoch 10/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 19.8827\n",
      "Epoch 11/250\n",
      "7796/7796 [==============================] - 3s 383us/step - loss: 15.5631\n",
      "Epoch 12/250\n",
      "7796/7796 [==============================] - 3s 383us/step - loss: 12.3465\n",
      "Epoch 13/250\n",
      "7796/7796 [==============================] - 3s 397us/step - loss: 10.0129\n",
      "Epoch 14/250\n",
      "7796/7796 [==============================] - 3s 403us/step - loss: 8.3598\n",
      "Epoch 15/250\n",
      "7796/7796 [==============================] - 3s 385us/step - loss: 7.1804\n",
      "Epoch 16/250\n",
      "7796/7796 [==============================] - 3s 384us/step - loss: 6.3311\n",
      "Epoch 17/250\n",
      "7796/7796 [==============================] - 3s 394us/step - loss: 5.6646\n",
      "Epoch 18/250\n",
      "7796/7796 [==============================] - 4s 498us/step - loss: 5.1498\n",
      "Epoch 19/250\n",
      "7796/7796 [==============================] - 4s 563us/step - loss: 4.7311\n",
      "Epoch 20/250\n",
      "7796/7796 [==============================] - 3s 400us/step - loss: 4.3836\n",
      "Epoch 21/250\n",
      "7796/7796 [==============================] - 3s 396us/step - loss: 4.0804\n",
      "Epoch 22/250\n",
      "7796/7796 [==============================] - 3s 409us/step - loss: 3.8106\n",
      "Epoch 23/250\n",
      "7796/7796 [==============================] - 4s 453us/step - loss: 3.5629\n",
      "Epoch 24/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 3.3437\n",
      "Epoch 25/250\n",
      "7796/7796 [==============================] - 3s 382us/step - loss: 3.1551\n",
      "Epoch 26/250\n",
      "7796/7796 [==============================] - 3s 407us/step - loss: 2.9754\n",
      "Epoch 27/250\n",
      "7796/7796 [==============================] - 3s 402us/step - loss: 2.8161\n",
      "Epoch 28/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 2.6718\n",
      "Epoch 29/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7796/7796 [==============================] - 3s 390us/step - loss: 2.5386\n",
      "Epoch 30/250\n",
      "7796/7796 [==============================] - 3s 391us/step - loss: 2.4164\n",
      "Epoch 31/250\n",
      "7796/7796 [==============================] - 3s 383us/step - loss: 2.3058\n",
      "Epoch 32/250\n",
      "7796/7796 [==============================] - 3s 403us/step - loss: 2.2052\n",
      "Epoch 33/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 2.1139\n",
      "Epoch 34/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 2.0278 0s - \n",
      "Epoch 35/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 1.9539\n",
      "Epoch 36/250\n",
      "7796/7796 [==============================] - 3s 346us/step - loss: 1.8794\n",
      "Epoch 37/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 1.8092\n",
      "Epoch 38/250\n",
      "7796/7796 [==============================] - 3s 340us/step - loss: 1.7481\n",
      "Epoch 39/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 1.6923\n",
      "Epoch 40/250\n",
      "7796/7796 [==============================] - 3s 382us/step - loss: 1.6384\n",
      "Epoch 41/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 1.5894\n",
      "Epoch 42/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 1.5428\n",
      "Epoch 43/250\n",
      "7796/7796 [==============================] - 3s 357us/step - loss: 1.4996\n",
      "Epoch 44/250\n",
      "7796/7796 [==============================] - 3s 340us/step - loss: 1.4590\n",
      "Epoch 45/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 1.4199\n",
      "Epoch 46/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 1.3825\n",
      "Epoch 47/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 1.3454\n",
      "Epoch 48/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 1.3115\n",
      "Epoch 49/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 1.2799\n",
      "Epoch 50/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 1.2505\n",
      "Epoch 51/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 1.2230\n",
      "Epoch 52/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 1.1964\n",
      "Epoch 53/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 1.1729\n",
      "Epoch 54/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 1.1487\n",
      "Epoch 55/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 1.1267\n",
      "Epoch 56/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 1.1062 0s - loss: 1.108\n",
      "Epoch 57/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 1.0856\n",
      "Epoch 58/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 1.0675\n",
      "Epoch 59/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 1.0499\n",
      "Epoch 60/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 1.0321\n",
      "Epoch 61/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 1.0156\n",
      "Epoch 62/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 0.9998\n",
      "Epoch 63/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 0.9846\n",
      "Epoch 64/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 0.9700\n",
      "Epoch 65/250\n",
      "7796/7796 [==============================] - ETA: 0s - loss: 0.956 - 3s 360us/step - loss: 0.9558\n",
      "Epoch 66/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 0.9425\n",
      "Epoch 67/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 0.9294\n",
      "Epoch 68/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.9165\n",
      "Epoch 69/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.9047\n",
      "Epoch 70/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.8931\n",
      "Epoch 71/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.8819\n",
      "Epoch 72/250\n",
      "7796/7796 [==============================] - 3s 340us/step - loss: 0.8711\n",
      "Epoch 73/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 0.8606\n",
      "Epoch 74/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 0.8506\n",
      "Epoch 75/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.8405 0s - loss - ETA: 0s - loss: 0.\n",
      "Epoch 76/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.8315\n",
      "Epoch 77/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.8226\n",
      "Epoch 78/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.8128\n",
      "Epoch 79/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.8050\n",
      "Epoch 80/250\n",
      "7796/7796 [==============================] - 3s 357us/step - loss: 0.7973 1s - loss:\n",
      "Epoch 81/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.7892\n",
      "Epoch 82/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.7816\n",
      "Epoch 83/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.7747\n",
      "Epoch 84/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.7678\n",
      "Epoch 85/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.7613\n",
      "Epoch 86/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.7548\n",
      "Epoch 87/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.7489\n",
      "Epoch 88/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 0.7433\n",
      "Epoch 89/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.7372\n",
      "Epoch 90/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.7314\n",
      "Epoch 91/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.7260\n",
      "Epoch 92/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.7207\n",
      "Epoch 93/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 0.7158\n",
      "Epoch 94/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.7107\n",
      "Epoch 95/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 0.7058\n",
      "Epoch 96/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.7012\n",
      "Epoch 97/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.6965\n",
      "Epoch 98/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.6920\n",
      "Epoch 99/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 0.6877\n",
      "Epoch 100/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.6839\n",
      "Epoch 101/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.6801\n",
      "Epoch 102/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.6761\n",
      "Epoch 103/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.6725\n",
      "Epoch 104/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 0.6693\n",
      "Epoch 105/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.6659\n",
      "Epoch 106/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.6624\n",
      "Epoch 107/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.6590\n",
      "Epoch 108/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.6563\n",
      "Epoch 109/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 0.6531\n",
      "Epoch 110/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.6501\n",
      "Epoch 111/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.6473\n",
      "Epoch 112/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 0.6446\n",
      "Epoch 113/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 0.6416\n",
      "Epoch 114/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 0.6393\n",
      "Epoch 115/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.6369\n",
      "Epoch 116/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.6345\n",
      "Epoch 117/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.6317\n",
      "Epoch 118/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.6300\n",
      "Epoch 119/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.6271\n",
      "Epoch 120/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.6252\n",
      "Epoch 121/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 0.6229\n",
      "Epoch 122/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.6209\n",
      "Epoch 123/250\n",
      "7796/7796 [==============================] - 3s 385us/step - loss: 0.6185\n",
      "Epoch 124/250\n",
      "7796/7796 [==============================] - 3s 368us/step - loss: 0.6168\n",
      "Epoch 125/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 0.6145\n",
      "Epoch 126/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 0.6123\n",
      "Epoch 127/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.6109\n",
      "Epoch 128/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.6090\n",
      "Epoch 129/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.6069\n",
      "Epoch 130/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.6055\n",
      "Epoch 131/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.6037\n",
      "Epoch 132/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 0.6022\n",
      "Epoch 133/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.6004\n",
      "Epoch 134/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 0.5989\n",
      "Epoch 135/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.5976\n",
      "Epoch 136/250\n",
      "7796/7796 [==============================] - ETA: 0s - loss: 0.596 - 3s 361us/step - loss: 0.5960\n",
      "Epoch 137/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.5944\n",
      "Epoch 138/250\n",
      "7796/7796 [==============================] - 3s 388us/step - loss: 0.5931\n",
      "Epoch 139/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 0.5918\n",
      "Epoch 140/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.5903\n",
      "Epoch 141/250\n",
      "7796/7796 [==============================] - 3s 346us/step - loss: 0.5889\n",
      "Epoch 142/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.5873\n",
      "Epoch 143/250\n",
      "7796/7796 [==============================] - 3s 371us/step - loss: 0.5862\n",
      "Epoch 144/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.5849\n",
      "Epoch 145/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 0.5836\n",
      "Epoch 146/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.5821\n",
      "Epoch 147/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 0.5807\n",
      "Epoch 148/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.5798\n",
      "Epoch 149/250\n",
      "7796/7796 [==============================] - 3s 365us/step - loss: 0.5789\n",
      "Epoch 150/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.5775\n",
      "Epoch 151/250\n",
      "7796/7796 [==============================] - 3s 381us/step - loss: 0.5765\n",
      "Epoch 152/250\n",
      "7796/7796 [==============================] - 3s 389us/step - loss: 0.5747\n",
      "Epoch 153/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.5741\n",
      "Epoch 154/250\n",
      "7796/7796 [==============================] - 3s 392us/step - loss: 0.5732\n",
      "Epoch 155/250\n",
      "7796/7796 [==============================] - 3s 435us/step - loss: 0.5719\n",
      "Epoch 156/250\n",
      "7796/7796 [==============================] - 3s 418us/step - loss: 0.5711\n",
      "Epoch 157/250\n",
      "7796/7796 [==============================] - 3s 424us/step - loss: 0.5695 0s - loss: 0.56\n",
      "Epoch 158/250\n",
      "7796/7796 [==============================] - 3s 397us/step - loss: 0.5687\n",
      "Epoch 159/250\n",
      "7796/7796 [==============================] - 3s 442us/step - loss: 0.5680\n",
      "Epoch 160/250\n",
      "7796/7796 [==============================] - 3s 434us/step - loss: 0.5669\n",
      "Epoch 161/250\n",
      "7796/7796 [==============================] - 4s 460us/step - loss: 0.5656\n",
      "Epoch 162/250\n",
      "7796/7796 [==============================] - 3s 396us/step - loss: 0.5649\n",
      "Epoch 163/250\n",
      "7796/7796 [==============================] - 3s 426us/step - loss: 0.5640\n",
      "Epoch 164/250\n",
      "7796/7796 [==============================] - 4s 535us/step - loss: 0.5627 0\n",
      "Epoch 165/250\n",
      "7796/7796 [==============================] - 4s 451us/step - loss: 0.5620\n",
      "Epoch 166/250\n",
      "7796/7796 [==============================] - 4s 481us/step - loss: 0.5610\n",
      "Epoch 167/250\n",
      "7796/7796 [==============================] - 3s 394us/step - loss: 0.5604\n",
      "Epoch 168/250\n",
      "7796/7796 [==============================] - 3s 403us/step - loss: 0.5598\n",
      "Epoch 169/250\n",
      "7796/7796 [==============================] - 3s 436us/step - loss: 0.5588\n",
      "Epoch 170/250\n",
      "7796/7796 [==============================] - 3s 402us/step - loss: 0.5577\n",
      "Epoch 171/250\n",
      "7796/7796 [==============================] - 3s 383us/step - loss: 0.5571\n",
      "Epoch 172/250\n",
      "7796/7796 [==============================] - 3s 386us/step - loss: 0.5566\n",
      "Epoch 173/250\n",
      "7796/7796 [==============================] - 3s 394us/step - loss: 0.5557\n",
      "Epoch 174/250\n",
      "7796/7796 [==============================] - 3s 375us/step - loss: 0.5544\n",
      "Epoch 175/250\n",
      "7796/7796 [==============================] - 3s 402us/step - loss: 0.5541\n",
      "Epoch 176/250\n",
      "7796/7796 [==============================] - 3s 391us/step - loss: 0.5535\n",
      "Epoch 177/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 0.5524\n",
      "Epoch 178/250\n",
      "7796/7796 [==============================] - 3s 393us/step - loss: 0.5515\n",
      "Epoch 179/250\n",
      "7796/7796 [==============================] - 3s 383us/step - loss: 0.5511\n",
      "Epoch 180/250\n",
      "7796/7796 [==============================] - 3s 395us/step - loss: 0.5498\n",
      "Epoch 181/250\n",
      "7796/7796 [==============================] - 3s 374us/step - loss: 0.5492\n",
      "Epoch 182/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 0.5486\n",
      "Epoch 183/250\n",
      "7796/7796 [==============================] - 3s 391us/step - loss: 0.5481\n",
      "Epoch 184/250\n",
      "7796/7796 [==============================] - 3s 388us/step - loss: 0.5474\n",
      "Epoch 185/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.5467\n",
      "Epoch 186/250\n",
      "7796/7796 [==============================] - 4s 499us/step - loss: 0.5456 0s -\n",
      "Epoch 187/250\n",
      "7796/7796 [==============================] - 4s 452us/step - loss: 0.5452\n",
      "Epoch 188/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 0.5448\n",
      "Epoch 189/250\n",
      "7796/7796 [==============================] - 3s 412us/step - loss: 0.5441\n",
      "Epoch 190/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.5434\n",
      "Epoch 191/250\n",
      "7796/7796 [==============================] - 3s 379us/step - loss: 0.5424\n",
      "Epoch 192/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 0.5419\n",
      "Epoch 193/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.5415\n",
      "Epoch 194/250\n",
      "7796/7796 [==============================] - 3s 387us/step - loss: 0.5405\n",
      "Epoch 195/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 0.5402 0s - loss: 0.54\n",
      "Epoch 196/250\n",
      "7796/7796 [==============================] - 3s 383us/step - loss: 0.5399\n",
      "Epoch 197/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.5393\n",
      "Epoch 198/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 0.5384\n",
      "Epoch 199/250\n",
      "7796/7796 [==============================] - 3s 395us/step - loss: 0.5382\n",
      "Epoch 200/250\n",
      "7796/7796 [==============================] - 3s 365us/step - loss: 0.5372\n",
      "Epoch 201/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 0.5371\n",
      "Epoch 202/250\n",
      "7796/7796 [==============================] - 4s 456us/step - loss: 0.5365\n",
      "Epoch 203/250\n",
      "7796/7796 [==============================] - 4s 515us/step - loss: 0.5358\n",
      "Epoch 204/250\n",
      "7796/7796 [==============================] - 4s 463us/step - loss: 0.5355\n",
      "Epoch 205/250\n",
      "7796/7796 [==============================] - 4s 460us/step - loss: 0.5347\n",
      "Epoch 206/250\n",
      "7796/7796 [==============================] - 4s 481us/step - loss: 0.5343\n",
      "Epoch 207/250\n",
      "7796/7796 [==============================] - 4s 495us/step - loss: 0.5338 0s - loss: 0.534\n",
      "Epoch 208/250\n",
      "7796/7796 [==============================] - 4s 486us/step - loss: 0.5334\n",
      "Epoch 209/250\n",
      "7796/7796 [==============================] - 4s 513us/step - loss: 0.5326\n",
      "Epoch 210/250\n",
      "7796/7796 [==============================] - 4s 530us/step - loss: 0.5322 0s\n",
      "Epoch 211/250\n",
      "7796/7796 [==============================] - 4s 574us/step - loss: 0.5319\n",
      "Epoch 212/250\n",
      "7796/7796 [==============================] - 4s 507us/step - loss: 0.5311\n",
      "Epoch 213/250\n",
      "7796/7796 [==============================] - 4s 495us/step - loss: 0.5306\n",
      "Epoch 214/250\n",
      "7796/7796 [==============================] - 3s 444us/step - loss: 0.5303\n",
      "Epoch 215/250\n",
      "7796/7796 [==============================] - 3s 409us/step - loss: 0.5297\n",
      "Epoch 216/250\n",
      "7796/7796 [==============================] - 3s 419us/step - loss: 0.5292\n",
      "Epoch 217/250\n",
      "7796/7796 [==============================] - 4s 460us/step - loss: 0.5285\n",
      "Epoch 218/250\n",
      "7796/7796 [==============================] - 3s 417us/step - loss: 0.5283\n",
      "Epoch 219/250\n",
      "7796/7796 [==============================] - 3s 435us/step - loss: 0.5276\n",
      "Epoch 220/250\n",
      "7796/7796 [==============================] - 4s 458us/step - loss: 0.5273\n",
      "Epoch 221/250\n",
      "7796/7796 [==============================] - 3s 391us/step - loss: 0.5271\n",
      "Epoch 222/250\n",
      "7796/7796 [==============================] - 3s 395us/step - loss: 0.5266\n",
      "Epoch 223/250\n",
      "7796/7796 [==============================] - 3s 382us/step - loss: 0.5254\n",
      "Epoch 224/250\n",
      "7796/7796 [==============================] - 3s 411us/step - loss: 0.5255\n",
      "Epoch 225/250\n",
      "7796/7796 [==============================] - 3s 408us/step - loss: 0.5251\n",
      "Epoch 226/250\n",
      "7796/7796 [==============================] - 3s 423us/step - loss: 0.5247\n",
      "Epoch 227/250\n",
      "7796/7796 [==============================] - 3s 388us/step - loss: 0.5244\n",
      "Epoch 228/250\n",
      "7796/7796 [==============================] - 3s 398us/step - loss: 0.5237\n",
      "Epoch 229/250\n",
      "7796/7796 [==============================] - 3s 410us/step - loss: 0.5235\n",
      "Epoch 230/250\n",
      "7796/7796 [==============================] - 3s 421us/step - loss: 0.5229\n",
      "Epoch 231/250\n",
      "7796/7796 [==============================] - 3s 420us/step - loss: 0.5225\n",
      "Epoch 232/250\n",
      "7796/7796 [==============================] - 3s 433us/step - loss: 0.5220\n",
      "Epoch 233/250\n",
      "7796/7796 [==============================] - 3s 434us/step - loss: 0.5213\n",
      "Epoch 234/250\n",
      "7796/7796 [==============================] - 3s 391us/step - loss: 0.5214\n",
      "Epoch 235/250\n",
      "7796/7796 [==============================] - 3s 376us/step - loss: 0.5208\n",
      "Epoch 236/250\n",
      "7796/7796 [==============================] - 3s 368us/step - loss: 0.5205\n",
      "Epoch 237/250\n",
      "7796/7796 [==============================] - 3s 388us/step - loss: 0.5202\n",
      "Epoch 238/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 0.5195\n",
      "Epoch 239/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.5191\n",
      "Epoch 240/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 0.5186\n",
      "Epoch 241/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.5185\n",
      "Epoch 242/250\n",
      "7796/7796 [==============================] - 3s 374us/step - loss: 0.5179\n",
      "Epoch 243/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.5172\n",
      "Epoch 244/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.5171\n",
      "Epoch 245/250\n",
      "7796/7796 [==============================] - 3s 412us/step - loss: 0.5170\n",
      "Epoch 246/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.5166\n",
      "Epoch 247/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.5161\n",
      "Epoch 248/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 0.5159\n",
      "Epoch 249/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.5153\n",
      "Epoch 250/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 0.5150\n",
      "1949/1949 [==============================] - 0s 110us/step\n",
      "Epoch 1/250\n",
      "7796/7796 [==============================] - 3s 402us/step - loss: 133.9373\n",
      "Epoch 2/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 117.9541\n",
      "Epoch 3/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 102.5382\n",
      "Epoch 4/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 87.5792\n",
      "Epoch 5/250\n",
      "7796/7796 [==============================] - 3s 378us/step - loss: 73.3484\n",
      "Epoch 6/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 60.1990\n",
      "Epoch 7/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 48.4372\n",
      "Epoch 8/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 38.1700\n",
      "Epoch 9/250\n",
      "7796/7796 [==============================] - 3s 346us/step - loss: 29.4161\n",
      "Epoch 10/250\n",
      "7796/7796 [==============================] - 3s 355us/step - loss: 22.2696\n",
      "Epoch 11/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 16.6833\n",
      "Epoch 12/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 12.5261\n",
      "Epoch 13/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 9.5719\n",
      "Epoch 14/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 7.5736\n",
      "Epoch 15/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 6.2748\n",
      "Epoch 16/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 5.4165\n",
      "Epoch 17/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 4.7974\n",
      "Epoch 18/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 4.3146\n",
      "Epoch 19/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 3.9206\n",
      "Epoch 20/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 3.6054\n",
      "Epoch 21/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 3.3341\n",
      "Epoch 22/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 3.0968\n",
      "Epoch 23/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 2.8912\n",
      "Epoch 24/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 2.7077\n",
      "Epoch 25/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 2.5451\n",
      "Epoch 26/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 2.3998\n",
      "Epoch 27/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 2.2722\n",
      "Epoch 28/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 2.1563\n",
      "Epoch 29/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 2.0514\n",
      "Epoch 30/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 1.9571\n",
      "Epoch 31/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 1.8732\n",
      "Epoch 32/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 1.7956\n",
      "Epoch 33/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 1.7251 0s - loss: 1.\n",
      "Epoch 34/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 1.6591\n",
      "Epoch 35/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 1.5989\n",
      "Epoch 36/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 1.5424\n",
      "Epoch 37/250\n",
      "7796/7796 [==============================] - 3s 324us/step - loss: 1.4893\n",
      "Epoch 38/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 1.4389\n",
      "Epoch 39/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 1.3926\n",
      "Epoch 40/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 1.3485\n",
      "Epoch 41/250\n",
      "7796/7796 [==============================] - 3s 327us/step - loss: 1.3079\n",
      "Epoch 42/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 1.2705\n",
      "Epoch 43/250\n",
      "7796/7796 [==============================] - 3s 357us/step - loss: 1.2339\n",
      "Epoch 44/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 1.2005\n",
      "Epoch 45/250\n",
      "7796/7796 [==============================] - 3s 325us/step - loss: 1.1691\n",
      "Epoch 46/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 1.1387\n",
      "Epoch 47/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 1.1102\n",
      "Epoch 48/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 1.0835\n",
      "Epoch 49/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 1.0575\n",
      "Epoch 50/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 1.0334\n",
      "Epoch 51/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 1.0106\n",
      "Epoch 52/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.9895\n",
      "Epoch 53/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.9682\n",
      "Epoch 54/250\n",
      "7796/7796 [==============================] - 3s 346us/step - loss: 0.9490\n",
      "Epoch 55/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.9305\n",
      "Epoch 56/250\n",
      "7796/7796 [==============================] - 3s 326us/step - loss: 0.9126\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.8964\n",
      "Epoch 58/250\n",
      "7796/7796 [==============================] - 3s 340us/step - loss: 0.8806\n",
      "Epoch 59/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 0.8657\n",
      "Epoch 60/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 0.8513\n",
      "Epoch 61/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.8378\n",
      "Epoch 62/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.8241\n",
      "Epoch 63/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.8117\n",
      "Epoch 64/250\n",
      "7796/7796 [==============================] - 3s 327us/step - loss: 0.7991\n",
      "Epoch 65/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 0.7873\n",
      "Epoch 66/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.7757\n",
      "Epoch 67/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 0.7653\n",
      "Epoch 68/250\n",
      "7796/7796 [==============================] - 3s 329us/step - loss: 0.7542\n",
      "Epoch 69/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.7444\n",
      "Epoch 70/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.7351\n",
      "Epoch 71/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.7257\n",
      "Epoch 72/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.7166\n",
      "Epoch 73/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 0.7076\n",
      "Epoch 74/250\n",
      "7796/7796 [==============================] - 3s 365us/step - loss: 0.6993\n",
      "Epoch 75/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 0.6911\n",
      "Epoch 76/250\n",
      "7796/7796 [==============================] - 3s 327us/step - loss: 0.6832\n",
      "Epoch 77/250\n",
      "7796/7796 [==============================] - 3s 346us/step - loss: 0.6762\n",
      "Epoch 78/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 0.6688\n",
      "Epoch 79/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 0.6624\n",
      "Epoch 80/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 0.6558\n",
      "Epoch 81/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.6495\n",
      "Epoch 82/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 0.6430\n",
      "Epoch 83/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 0.6371\n",
      "Epoch 84/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.6311\n",
      "Epoch 85/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.6250\n",
      "Epoch 86/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.6196\n",
      "Epoch 87/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.6145\n",
      "Epoch 88/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 0.6090\n",
      "Epoch 89/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 0.6043\n",
      "Epoch 90/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 0.5987\n",
      "Epoch 91/250\n",
      "7796/7796 [==============================] - 3s 376us/step - loss: 0.5945\n",
      "Epoch 92/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.5898\n",
      "Epoch 93/250\n",
      "7796/7796 [==============================] - 3s 357us/step - loss: 0.5852\n",
      "Epoch 94/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.5812\n",
      "Epoch 95/250\n",
      "7796/7796 [==============================] - 3s 355us/step - loss: 0.5767\n",
      "Epoch 96/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.5728\n",
      "Epoch 97/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.5688\n",
      "Epoch 98/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.5651\n",
      "Epoch 99/250\n",
      "7796/7796 [==============================] - 3s 385us/step - loss: 0.5608\n",
      "Epoch 100/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.5572\n",
      "Epoch 101/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 0.5535\n",
      "Epoch 102/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 0.5502\n",
      "Epoch 103/250\n",
      "7796/7796 [==============================] - 3s 378us/step - loss: 0.5468\n",
      "Epoch 104/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.5435\n",
      "Epoch 105/250\n",
      "7796/7796 [==============================] - 3s 365us/step - loss: 0.5406\n",
      "Epoch 106/250\n",
      "7796/7796 [==============================] - 3s 387us/step - loss: 0.5375\n",
      "Epoch 107/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.5347\n",
      "Epoch 108/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.5316\n",
      "Epoch 109/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 0.5290\n",
      "Epoch 110/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.5261\n",
      "Epoch 111/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 0.5234\n",
      "Epoch 112/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 0.5208\n",
      "Epoch 113/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 0.5186\n",
      "Epoch 114/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.5159\n",
      "Epoch 115/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.5136\n",
      "Epoch 116/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 0.5111\n",
      "Epoch 117/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.5093\n",
      "Epoch 118/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.5073\n",
      "Epoch 119/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.5049\n",
      "Epoch 120/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.5032\n",
      "Epoch 121/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.5009\n",
      "Epoch 122/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.4990\n",
      "Epoch 123/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 0.4972\n",
      "Epoch 124/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 0.4951\n",
      "Epoch 125/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 0.4935\n",
      "Epoch 126/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.4917\n",
      "Epoch 127/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.4902\n",
      "Epoch 128/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.4879\n",
      "Epoch 129/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.4867\n",
      "Epoch 130/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.4851\n",
      "Epoch 131/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.4837\n",
      "Epoch 132/250\n",
      "7796/7796 [==============================] - 3s 326us/step - loss: 0.4824\n",
      "Epoch 133/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.4808\n",
      "Epoch 134/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.4794\n",
      "Epoch 135/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.4779\n",
      "Epoch 136/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.4764\n",
      "Epoch 137/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 0.4744\n",
      "Epoch 138/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 0.4734\n",
      "Epoch 139/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.4724\n",
      "Epoch 140/250\n",
      "7796/7796 [==============================] - 3s 327us/step - loss: 0.4709\n",
      "Epoch 141/250\n",
      "7796/7796 [==============================] - 3s 340us/step - loss: 0.4695\n",
      "Epoch 142/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 0.4685\n",
      "Epoch 143/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.4669\n",
      "Epoch 144/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.4665\n",
      "Epoch 145/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.4649\n",
      "Epoch 146/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.4637\n",
      "Epoch 147/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.4623\n",
      "Epoch 148/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.4612\n",
      "Epoch 149/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.4600\n",
      "Epoch 150/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.4585\n",
      "Epoch 151/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.4575\n",
      "Epoch 152/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 0.4567\n",
      "Epoch 153/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.4556\n",
      "Epoch 154/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 0.4548\n",
      "Epoch 155/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.4537\n",
      "Epoch 156/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 0.4527\n",
      "Epoch 157/250\n",
      "7796/7796 [==============================] - 3s 326us/step - loss: 0.4516\n",
      "Epoch 158/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 0.4511\n",
      "Epoch 159/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.4500\n",
      "Epoch 160/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 0.4489\n",
      "Epoch 161/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.4484\n",
      "Epoch 162/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.4472\n",
      "Epoch 163/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.4467\n",
      "Epoch 164/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.4453\n",
      "Epoch 165/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 0.4452\n",
      "Epoch 166/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.4440\n",
      "Epoch 167/250\n",
      "7796/7796 [==============================] - 3s 340us/step - loss: 0.4427 0s - loss: 0.4\n",
      "Epoch 168/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.4425\n",
      "Epoch 169/250\n",
      "7796/7796 [==============================] - 3s 327us/step - loss: 0.4415\n",
      "Epoch 170/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.4409\n",
      "Epoch 171/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.4398\n",
      "Epoch 172/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 0.4390\n",
      "Epoch 173/250\n",
      "7796/7796 [==============================] - 3s 328us/step - loss: 0.4385\n",
      "Epoch 174/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 0.4378\n",
      "Epoch 175/250\n",
      "7796/7796 [==============================] - 3s 386us/step - loss: 0.4369\n",
      "Epoch 176/250\n",
      "7796/7796 [==============================] - 3s 391us/step - loss: 0.4364\n",
      "Epoch 177/250\n",
      "7796/7796 [==============================] - 3s 346us/step - loss: 0.4357\n",
      "Epoch 178/250\n",
      "7796/7796 [==============================] - 3s 397us/step - loss: 0.4350 \n",
      "Epoch 179/250\n",
      "7796/7796 [==============================] - 3s 435us/step - loss: 0.4348\n",
      "Epoch 180/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 0.4339\n",
      "Epoch 181/250\n",
      "7796/7796 [==============================] - 3s 382us/step - loss: 0.4335\n",
      "Epoch 182/250\n",
      "7796/7796 [==============================] - 3s 376us/step - loss: 0.4326\n",
      "Epoch 183/250\n",
      "7796/7796 [==============================] - 3s 382us/step - loss: 0.4319\n",
      "Epoch 184/250\n",
      "7796/7796 [==============================] - 3s 420us/step - loss: 0.4316\n",
      "Epoch 185/250\n",
      "7796/7796 [==============================] - 3s 378us/step - loss: 0.4308\n",
      "Epoch 186/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 0.4303\n",
      "Epoch 187/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 0.4297\n",
      "Epoch 188/250\n",
      "7796/7796 [==============================] - 3s 379us/step - loss: 0.4291\n",
      "Epoch 189/250\n",
      "7796/7796 [==============================] - 3s 391us/step - loss: 0.4288\n",
      "Epoch 190/250\n",
      "7796/7796 [==============================] - 3s 411us/step - loss: 0.4278\n",
      "Epoch 191/250\n",
      "7796/7796 [==============================] - 3s 433us/step - loss: 0.4275 0s - loss: 0.427\n",
      "Epoch 192/250\n",
      "7796/7796 [==============================] - 3s 414us/step - loss: 0.4271\n",
      "Epoch 193/250\n",
      "7796/7796 [==============================] - 3s 443us/step - loss: 0.4263\n",
      "Epoch 194/250\n",
      "7796/7796 [==============================] - 4s 486us/step - loss: 0.4257\n",
      "Epoch 195/250\n",
      "7796/7796 [==============================] - 3s 413us/step - loss: 0.4258\n",
      "Epoch 196/250\n",
      "7796/7796 [==============================] - 4s 488us/step - loss: 0.4249\n",
      "Epoch 197/250\n",
      "7796/7796 [==============================] - 4s 481us/step - loss: 0.4246\n",
      "Epoch 198/250\n",
      "7796/7796 [==============================] - 3s 416us/step - loss: 0.4243\n",
      "Epoch 199/250\n",
      "7796/7796 [==============================] - 3s 383us/step - loss: 0.4238\n",
      "Epoch 200/250\n",
      "7796/7796 [==============================] - 3s 409us/step - loss: 0.4234\n",
      "Epoch 201/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 0.4229\n",
      "Epoch 202/250\n",
      "7796/7796 [==============================] - 3s 380us/step - loss: 0.4226\n",
      "Epoch 203/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 0.4218\n",
      "Epoch 204/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.4215\n",
      "Epoch 205/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.4208\n",
      "Epoch 206/250\n",
      "7796/7796 [==============================] - 3s 365us/step - loss: 0.4203\n",
      "Epoch 207/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.4200\n",
      "Epoch 208/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.4196\n",
      "Epoch 209/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.4193\n",
      "Epoch 210/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.4185\n",
      "Epoch 211/250\n",
      "7796/7796 [==============================] - 3s 398us/step - loss: 0.4184\n",
      "Epoch 212/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.4182\n",
      "Epoch 213/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 0.4178\n",
      "Epoch 214/250\n",
      "7796/7796 [==============================] - 3s 384us/step - loss: 0.4172\n",
      "Epoch 215/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.4167\n",
      "Epoch 216/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.4164\n",
      "Epoch 217/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.4161\n",
      "Epoch 218/250\n",
      "7796/7796 [==============================] - 3s 374us/step - loss: 0.4158\n",
      "Epoch 219/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.4153\n",
      "Epoch 220/250\n",
      "7796/7796 [==============================] - 3s 346us/step - loss: 0.4150\n",
      "Epoch 221/250\n",
      "7796/7796 [==============================] - 3s 332us/step - loss: 0.4144\n",
      "Epoch 222/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 0.4141\n",
      "Epoch 223/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 0.4138\n",
      "Epoch 224/250\n",
      "7796/7796 [==============================] - ETA: 0s - loss: 0.413 - 3s 351us/step - loss: 0.4135\n",
      "Epoch 225/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.4133\n",
      "Epoch 226/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.4126\n",
      "Epoch 227/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 0.4123\n",
      "Epoch 228/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.4121\n",
      "Epoch 229/250\n",
      "7796/7796 [==============================] - 3s 365us/step - loss: 0.4118\n",
      "Epoch 230/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.4112\n",
      "Epoch 231/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.4108\n",
      "Epoch 232/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.4109\n",
      "Epoch 233/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.4102\n",
      "Epoch 234/250\n",
      "7796/7796 [==============================] - 3s 382us/step - loss: 0.4099\n",
      "Epoch 235/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 0.4098\n",
      "Epoch 236/250\n",
      "7796/7796 [==============================] - 3s 379us/step - loss: 0.4095\n",
      "Epoch 237/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.4093\n",
      "Epoch 238/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.4086\n",
      "Epoch 239/250\n",
      "7796/7796 [==============================] - 3s 331us/step - loss: 0.4085\n",
      "Epoch 240/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 0.4078\n",
      "Epoch 241/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.4081\n",
      "Epoch 242/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7796/7796 [==============================] - 3s 353us/step - loss: 0.4075\n",
      "Epoch 243/250\n",
      "7796/7796 [==============================] - 3s 340us/step - loss: 0.4073\n",
      "Epoch 244/250\n",
      "7796/7796 [==============================] - 3s 365us/step - loss: 0.4069\n",
      "Epoch 245/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.4064\n",
      "Epoch 246/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.4062\n",
      "Epoch 247/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 0.4058\n",
      "Epoch 248/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.4054\n",
      "Epoch 249/250\n",
      "7796/7796 [==============================] - 3s 378us/step - loss: 0.4054\n",
      "Epoch 250/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.4053\n",
      "1949/1949 [==============================] - 0s 110us/step\n",
      "Epoch 1/250\n",
      "7796/7796 [==============================] - 3s 390us/step - loss: 143.2209\n",
      "Epoch 2/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 125.5209 0s - loss: 126\n",
      "Epoch 3/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 108.9843\n",
      "Epoch 4/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 92.9339\n",
      "Epoch 5/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 77.7548\n",
      "Epoch 6/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 63.8980\n",
      "Epoch 7/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 51.5527\n",
      "Epoch 8/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 40.8361\n",
      "Epoch 9/250\n",
      "7796/7796 [==============================] - 3s 330us/step - loss: 31.7115\n",
      "Epoch 10/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 24.2272\n",
      "Epoch 11/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 18.3128\n",
      "Epoch 12/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 13.8361\n",
      "Epoch 13/250\n",
      "7796/7796 [==============================] - 3s 357us/step - loss: 10.5657\n",
      "Epoch 14/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 8.2987\n",
      "Epoch 15/250\n",
      "7796/7796 [==============================] - 3s 357us/step - loss: 6.7979\n",
      "Epoch 16/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 5.8186\n",
      "Epoch 17/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 5.1506\n",
      "Epoch 18/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 4.6493\n",
      "Epoch 19/250\n",
      "7796/7796 [==============================] - 3s 380us/step - loss: 4.2511\n",
      "Epoch 20/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 3.9001\n",
      "Epoch 21/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 3.5993\n",
      "Epoch 22/250\n",
      "7796/7796 [==============================] - 3s 355us/step - loss: 3.3462\n",
      "Epoch 23/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 3.1292\n",
      "Epoch 24/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 2.9414\n",
      "Epoch 25/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 2.7730\n",
      "Epoch 26/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 2.6250\n",
      "Epoch 27/250\n",
      "7796/7796 [==============================] - 3s 374us/step - loss: 2.4932\n",
      "Epoch 28/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 2.3723\n",
      "Epoch 29/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 2.2685\n",
      "Epoch 30/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 2.1705\n",
      "Epoch 31/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 2.0810\n",
      "Epoch 32/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 1.9967\n",
      "Epoch 33/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 1.9190\n",
      "Epoch 34/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 1.8461\n",
      "Epoch 35/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 1.7793\n",
      "Epoch 36/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 1.7159\n",
      "Epoch 37/250\n",
      "7796/7796 [==============================] - 3s 379us/step - loss: 1.6577\n",
      "Epoch 38/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 1.6019\n",
      "Epoch 39/250\n",
      "7796/7796 [==============================] - 3s 365us/step - loss: 1.5512\n",
      "Epoch 40/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 1.5041\n",
      "Epoch 41/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 1.4591\n",
      "Epoch 42/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 1.4156\n",
      "Epoch 43/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 1.3753\n",
      "Epoch 44/250\n",
      "7796/7796 [==============================] - 3s 355us/step - loss: 1.3382\n",
      "Epoch 45/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 1.3047\n",
      "Epoch 46/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 1.2716\n",
      "Epoch 47/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 1.2410\n",
      "Epoch 48/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 1.2110\n",
      "Epoch 49/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 1.1832\n",
      "Epoch 50/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 1.1563\n",
      "Epoch 51/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 1.1309\n",
      "Epoch 52/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 1.1071\n",
      "Epoch 53/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 1.0845\n",
      "Epoch 54/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 1.0636\n",
      "Epoch 55/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 1.0434 1s - loss: 1 - \n",
      "Epoch 56/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 1.0236\n",
      "Epoch 57/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 1.0056\n",
      "Epoch 58/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.9876\n",
      "Epoch 59/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.9705\n",
      "Epoch 60/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.9546\n",
      "Epoch 61/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 0.9394\n",
      "Epoch 62/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 0.9251\n",
      "Epoch 63/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.9107\n",
      "Epoch 64/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.8970\n",
      "Epoch 65/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.8836\n",
      "Epoch 66/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.8705\n",
      "Epoch 67/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.8585\n",
      "Epoch 68/250\n",
      "7796/7796 [==============================] - 3s 384us/step - loss: 0.8463\n",
      "Epoch 69/250\n",
      "7796/7796 [==============================] - 3s 365us/step - loss: 0.8356\n",
      "Epoch 70/250\n",
      "7796/7796 [==============================] - 3s 365us/step - loss: 0.8244 0s - \n",
      "Epoch 71/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.8141\n",
      "Epoch 72/250\n",
      "7796/7796 [==============================] - 3s 365us/step - loss: 0.8046\n",
      "Epoch 73/250\n",
      "7796/7796 [==============================] - 3s 389us/step - loss: 0.7947\n",
      "Epoch 74/250\n",
      "7796/7796 [==============================] - 3s 374us/step - loss: 0.7855\n",
      "Epoch 75/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.7762\n",
      "Epoch 76/250\n",
      "7796/7796 [==============================] - 3s 357us/step - loss: 0.7678\n",
      "Epoch 77/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.7599\n",
      "Epoch 78/250\n",
      "7796/7796 [==============================] - 3s 376us/step - loss: 0.7520\n",
      "Epoch 79/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.7442\n",
      "Epoch 80/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.7368\n",
      "Epoch 81/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.7293\n",
      "Epoch 82/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.7225\n",
      "Epoch 83/250\n",
      "7796/7796 [==============================] - 3s 387us/step - loss: 0.7152\n",
      "Epoch 84/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.7086\n",
      "Epoch 85/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.7025\n",
      "Epoch 86/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.6960\n",
      "Epoch 87/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.6905\n",
      "Epoch 88/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.6850\n",
      "Epoch 89/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.6796\n",
      "Epoch 90/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 0.6741\n",
      "Epoch 91/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.6693\n",
      "Epoch 92/250\n",
      "7796/7796 [==============================] - 3s 368us/step - loss: 0.6649\n",
      "Epoch 93/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 0.6601\n",
      "Epoch 94/250\n",
      "7796/7796 [==============================] - 4s 453us/step - loss: 0.6554\n",
      "Epoch 95/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.6513\n",
      "Epoch 96/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 0.6464\n",
      "Epoch 97/250\n",
      "7796/7796 [==============================] - 3s 393us/step - loss: 0.6429\n",
      "Epoch 98/250\n",
      "7796/7796 [==============================] - 3s 386us/step - loss: 0.6388\n",
      "Epoch 99/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.6344\n",
      "Epoch 100/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.6304\n",
      "Epoch 101/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.6271\n",
      "Epoch 102/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.6233 0s - loss: 0.\n",
      "Epoch 103/250\n",
      "7796/7796 [==============================] - 3s 340us/step - loss: 0.6200\n",
      "Epoch 104/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.6168\n",
      "Epoch 105/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 0.6129\n",
      "Epoch 106/250\n",
      "7796/7796 [==============================] - 3s 374us/step - loss: 0.6099\n",
      "Epoch 107/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.6064\n",
      "Epoch 108/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.6034\n",
      "Epoch 109/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.6002\n",
      "Epoch 110/250\n",
      "7796/7796 [==============================] - 3s 355us/step - loss: 0.5971\n",
      "Epoch 111/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.5941\n",
      "Epoch 112/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.5912\n",
      "Epoch 113/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 0.5883\n",
      "Epoch 114/250\n",
      "7796/7796 [==============================] - 3s 375us/step - loss: 0.5855\n",
      "Epoch 115/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 0.5826\n",
      "Epoch 116/250\n",
      "7796/7796 [==============================] - 3s 407us/step - loss: 0.5804\n",
      "Epoch 117/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.5778\n",
      "Epoch 118/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.5754\n",
      "Epoch 119/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 0.5729\n",
      "Epoch 120/250\n",
      "7796/7796 [==============================] - 3s 385us/step - loss: 0.5704\n",
      "Epoch 121/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.5682\n",
      "Epoch 122/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 0.5657\n",
      "Epoch 123/250\n",
      "7796/7796 [==============================] - 3s 346us/step - loss: 0.5635\n",
      "Epoch 124/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.5614\n",
      "Epoch 125/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 0.5591 0s - \n",
      "Epoch 126/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.5572\n",
      "Epoch 127/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.5556\n",
      "Epoch 128/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.5532\n",
      "Epoch 129/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.5517\n",
      "Epoch 130/250\n",
      "7796/7796 [==============================] - 3s 393us/step - loss: 0.5499\n",
      "Epoch 131/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 0.5481\n",
      "Epoch 132/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.5464\n",
      "Epoch 133/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.5447\n",
      "Epoch 134/250\n",
      "7796/7796 [==============================] - 3s 402us/step - loss: 0.5428\n",
      "Epoch 135/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.5416\n",
      "Epoch 136/250\n",
      "7796/7796 [==============================] - 3s 374us/step - loss: 0.5398\n",
      "Epoch 137/250\n",
      "7796/7796 [==============================] - 3s 380us/step - loss: 0.5385\n",
      "Epoch 138/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.5368\n",
      "Epoch 139/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 0.5354\n",
      "Epoch 140/250\n",
      "7796/7796 [==============================] - 3s 371us/step - loss: 0.5339\n",
      "Epoch 141/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 0.5325\n",
      "Epoch 142/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.5308\n",
      "Epoch 143/250\n",
      "7796/7796 [==============================] - 3s 346us/step - loss: 0.5299\n",
      "Epoch 144/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 0.5284\n",
      "Epoch 145/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 0.5272\n",
      "Epoch 146/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 0.5263\n",
      "Epoch 147/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 0.5243\n",
      "Epoch 148/250\n",
      "7796/7796 [==============================] - 3s 355us/step - loss: 0.5236\n",
      "Epoch 149/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 0.5220\n",
      "Epoch 150/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.5218\n",
      "Epoch 151/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 0.5205\n",
      "Epoch 152/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 0.5192\n",
      "Epoch 153/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.5181\n",
      "Epoch 154/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.5168\n",
      "Epoch 155/250\n",
      "7796/7796 [==============================] - 3s 378us/step - loss: 0.5159\n",
      "Epoch 156/250\n",
      "7796/7796 [==============================] - 3s 376us/step - loss: 0.5149\n",
      "Epoch 157/250\n",
      "7796/7796 [==============================] - 3s 379us/step - loss: 0.5141\n",
      "Epoch 158/250\n",
      "7796/7796 [==============================] - 3s 393us/step - loss: 0.5126\n",
      "Epoch 159/250\n",
      "7796/7796 [==============================] - 3s 379us/step - loss: 0.5120\n",
      "Epoch 160/250\n",
      "7796/7796 [==============================] - 3s 385us/step - loss: 0.5109\n",
      "Epoch 161/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 0.5103 0\n",
      "Epoch 162/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.5093\n",
      "Epoch 163/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.5079\n",
      "Epoch 164/250\n",
      "7796/7796 [==============================] - 3s 383us/step - loss: 0.5074\n",
      "Epoch 165/250\n",
      "7796/7796 [==============================] - 3s 357us/step - loss: 0.5064\n",
      "Epoch 166/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.5055\n",
      "Epoch 167/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 0.5043\n",
      "Epoch 168/250\n",
      "7796/7796 [==============================] - 3s 388us/step - loss: 0.5040\n",
      "Epoch 169/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.5029\n",
      "Epoch 170/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.5024 1 - ETA: 0s -\n",
      "Epoch 171/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.5013\n",
      "Epoch 172/250\n",
      "7796/7796 [==============================] - 3s 375us/step - loss: 0.5004\n",
      "Epoch 173/250\n",
      "7796/7796 [==============================] - 3s 389us/step - loss: 0.4999\n",
      "Epoch 174/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.4988\n",
      "Epoch 175/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 0.4982\n",
      "Epoch 176/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 0.4976\n",
      "Epoch 177/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.4968\n",
      "Epoch 178/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7796/7796 [==============================] - 3s 340us/step - loss: 0.4961\n",
      "Epoch 179/250\n",
      "7796/7796 [==============================] - 3s 334us/step - loss: 0.4953\n",
      "Epoch 180/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.4945\n",
      "Epoch 181/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.4936\n",
      "Epoch 182/250\n",
      "7796/7796 [==============================] - 3s 389us/step - loss: 0.4934\n",
      "Epoch 183/250\n",
      "7796/7796 [==============================] - 3s 379us/step - loss: 0.4927\n",
      "Epoch 184/250\n",
      "7796/7796 [==============================] - 3s 368us/step - loss: 0.4921\n",
      "Epoch 185/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 0.4913\n",
      "Epoch 186/250\n",
      "7796/7796 [==============================] - 3s 381us/step - loss: 0.4907\n",
      "Epoch 187/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 0.4899\n",
      "Epoch 188/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 0.4894\n",
      "Epoch 189/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 0.4885\n",
      "Epoch 190/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 0.4880\n",
      "Epoch 191/250\n",
      "7796/7796 [==============================] - 3s 379us/step - loss: 0.4876\n",
      "Epoch 192/250\n",
      "7796/7796 [==============================] - 3s 368us/step - loss: 0.4872\n",
      "Epoch 193/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.4863\n",
      "Epoch 194/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.4857\n",
      "Epoch 195/250\n",
      "7796/7796 [==============================] - 3s 374us/step - loss: 0.4854\n",
      "Epoch 196/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.4847\n",
      "Epoch 197/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.4841\n",
      "Epoch 198/250\n",
      "7796/7796 [==============================] - 3s 391us/step - loss: 0.4835\n",
      "Epoch 199/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 0.4830\n",
      "Epoch 200/250\n",
      "7796/7796 [==============================] - 3s 394us/step - loss: 0.4825\n",
      "Epoch 201/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 0.4824\n",
      "Epoch 202/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.4814\n",
      "Epoch 203/250\n",
      "7796/7796 [==============================] - 3s 388us/step - loss: 0.4808 0s - loss\n",
      "Epoch 204/250\n",
      "7796/7796 [==============================] - 3s 382us/step - loss: 0.4805\n",
      "Epoch 205/250\n",
      "7796/7796 [==============================] - 3s 386us/step - loss: 0.4798\n",
      "Epoch 206/250\n",
      "7796/7796 [==============================] - 3s 383us/step - loss: 0.4794\n",
      "Epoch 207/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 0.4790\n",
      "Epoch 208/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 0.4785\n",
      "Epoch 209/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 0.4782\n",
      "Epoch 210/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 0.4774 0s - loss: 0.476\n",
      "Epoch 211/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 0.4773\n",
      "Epoch 212/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.4768\n",
      "Epoch 213/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.4764\n",
      "Epoch 214/250\n",
      "7796/7796 [==============================] - 3s 381us/step - loss: 0.4758\n",
      "Epoch 215/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 0.4752\n",
      "Epoch 216/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.4751\n",
      "Epoch 217/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.4743\n",
      "Epoch 218/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 0.4742\n",
      "Epoch 219/250\n",
      "7796/7796 [==============================] - 3s 374us/step - loss: 0.4739\n",
      "Epoch 220/250\n",
      "7796/7796 [==============================] - 3s 393us/step - loss: 0.4732\n",
      "Epoch 221/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 0.4729\n",
      "Epoch 222/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.4721\n",
      "Epoch 223/250\n",
      "7796/7796 [==============================] - 3s 374us/step - loss: 0.4717\n",
      "Epoch 224/250\n",
      "7796/7796 [==============================] - 3s 388us/step - loss: 0.4716\n",
      "Epoch 225/250\n",
      "7796/7796 [==============================] - 3s 385us/step - loss: 0.4711\n",
      "Epoch 226/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 0.4705\n",
      "Epoch 227/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.4705\n",
      "Epoch 228/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 0.4698\n",
      "Epoch 229/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.4695\n",
      "Epoch 230/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.4693\n",
      "Epoch 231/250\n",
      "7796/7796 [==============================] - 3s 340us/step - loss: 0.4689\n",
      "Epoch 232/250\n",
      "7796/7796 [==============================] - 3s 376us/step - loss: 0.4683\n",
      "Epoch 233/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 0.4677 0s - loss: 0.467\n",
      "Epoch 234/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.4680\n",
      "Epoch 235/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.4673\n",
      "Epoch 236/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 0.4667\n",
      "Epoch 237/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.4665\n",
      "Epoch 238/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.4662\n",
      "Epoch 239/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.4657\n",
      "Epoch 240/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.4652\n",
      "Epoch 241/250\n",
      "7796/7796 [==============================] - 3s 379us/step - loss: 0.4652\n",
      "Epoch 242/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.4650\n",
      "Epoch 243/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.4645\n",
      "Epoch 244/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.4642\n",
      "Epoch 245/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.4639\n",
      "Epoch 246/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.4633\n",
      "Epoch 247/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 0.4630\n",
      "Epoch 248/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.4627\n",
      "Epoch 249/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.4624\n",
      "Epoch 250/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.4621\n",
      "1949/1949 [==============================] - 0s 105us/step\n",
      "Epoch 1/250\n",
      "7796/7796 [==============================] - 3s 415us/step - loss: 129.1911\n",
      "Epoch 2/250\n",
      "7796/7796 [==============================] - 3s 340us/step - loss: 112.1540\n",
      "Epoch 3/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 96.3160\n",
      "Epoch 4/250\n",
      "7796/7796 [==============================] - 3s 418us/step - loss: 81.3747\n",
      "Epoch 5/250\n",
      "7796/7796 [==============================] - 3s 404us/step - loss: 67.4823\n",
      "Epoch 6/250\n",
      "7796/7796 [==============================] - 3s 375us/step - loss: 54.8745\n",
      "Epoch 7/250\n",
      "7796/7796 [==============================] - 3s 395us/step - loss: 43.7312\n",
      "Epoch 8/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 34.1533\n",
      "Epoch 9/250\n",
      "7796/7796 [==============================] - 3s 376us/step - loss: 26.1574\n",
      "Epoch 10/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 19.7752\n",
      "Epoch 11/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 14.8588\n",
      "Epoch 12/250\n",
      "7796/7796 [==============================] - 3s 379us/step - loss: 11.2141\n",
      "Epoch 13/250\n",
      "7796/7796 [==============================] - 3s 385us/step - loss: 8.6708\n",
      "Epoch 14/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 6.9870\n",
      "Epoch 15/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 5.9053\n",
      "Epoch 16/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 5.1881\n",
      "Epoch 17/250\n",
      "7796/7796 [==============================] - 3s 386us/step - loss: 4.6571\n",
      "Epoch 18/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 4.2322\n",
      "Epoch 19/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 3.8833\n",
      "Epoch 20/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 3.5793\n",
      "Epoch 21/250\n",
      "7796/7796 [==============================] - 3s 392us/step - loss: 3.3236\n",
      "Epoch 22/250\n",
      "7796/7796 [==============================] - 3s 342us/step - loss: 3.1089\n",
      "Epoch 23/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 2.9218\n",
      "Epoch 24/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 2.7574\n",
      "Epoch 25/250\n",
      "7796/7796 [==============================] - 3s 340us/step - loss: 2.6099\n",
      "Epoch 26/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 2.4771\n",
      "Epoch 27/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 2.3579\n",
      "Epoch 28/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 2.2517\n",
      "Epoch 29/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 2.1538\n",
      "Epoch 30/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 2.0646\n",
      "Epoch 31/250\n",
      "7796/7796 [==============================] - 3s 345us/step - loss: 1.9841\n",
      "Epoch 32/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 1.9070\n",
      "Epoch 33/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 1.8365\n",
      "Epoch 34/250\n",
      "7796/7796 [==============================] - 3s 355us/step - loss: 1.7732\n",
      "Epoch 35/250\n",
      "7796/7796 [==============================] - 3s 352us/step - loss: 1.7119\n",
      "Epoch 36/250\n",
      "7796/7796 [==============================] - 3s 348us/step - loss: 1.6533\n",
      "Epoch 37/250\n",
      "7796/7796 [==============================] - 3s 343us/step - loss: 1.5987\n",
      "Epoch 38/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 1.5475\n",
      "Epoch 39/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 1.5000\n",
      "Epoch 40/250\n",
      "7796/7796 [==============================] - 3s 368us/step - loss: 1.4548\n",
      "Epoch 41/250\n",
      "7796/7796 [==============================] - 3s 398us/step - loss: 1.4137\n",
      "Epoch 42/250\n",
      "7796/7796 [==============================] - 3s 398us/step - loss: 1.3750\n",
      "Epoch 43/250\n",
      "7796/7796 [==============================] - 3s 397us/step - loss: 1.3381\n",
      "Epoch 44/250\n",
      "7796/7796 [==============================] - 3s 376us/step - loss: 1.3031\n",
      "Epoch 45/250\n",
      "7796/7796 [==============================] - 3s 399us/step - loss: 1.2698\n",
      "Epoch 46/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 1.2388\n",
      "Epoch 47/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 1.2089\n",
      "Epoch 48/250\n",
      "7796/7796 [==============================] - 3s 353us/step - loss: 1.1808\n",
      "Epoch 49/250\n",
      "7796/7796 [==============================] - 3s 383us/step - loss: 1.1540\n",
      "Epoch 50/250\n",
      "7796/7796 [==============================] - 3s 418us/step - loss: 1.1296\n",
      "Epoch 51/250\n",
      "7796/7796 [==============================] - 4s 546us/step - loss: 1.1052\n",
      "Epoch 52/250\n",
      "7796/7796 [==============================] - 3s 411us/step - loss: 1.0824\n",
      "Epoch 53/250\n",
      "7796/7796 [==============================] - 4s 450us/step - loss: 1.0600\n",
      "Epoch 54/250\n",
      "7796/7796 [==============================] - 4s 462us/step - loss: 1.0401\n",
      "Epoch 55/250\n",
      "7796/7796 [==============================] - 3s 449us/step - loss: 1.0204\n",
      "Epoch 56/250\n",
      "7796/7796 [==============================] - 3s 401us/step - loss: 1.0020\n",
      "Epoch 57/250\n",
      "7796/7796 [==============================] - 3s 385us/step - loss: 0.9837\n",
      "Epoch 58/250\n",
      "7796/7796 [==============================] - 3s 393us/step - loss: 0.9661\n",
      "Epoch 59/250\n",
      "7796/7796 [==============================] - 3s 380us/step - loss: 0.9506\n",
      "Epoch 60/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 0.9351\n",
      "Epoch 61/250\n",
      "7796/7796 [==============================] - 3s 406us/step - loss: 0.9206\n",
      "Epoch 62/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 0.9062\n",
      "Epoch 63/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.8918\n",
      "Epoch 64/250\n",
      "7796/7796 [==============================] - 3s 378us/step - loss: 0.8789\n",
      "Epoch 65/250\n",
      "7796/7796 [==============================] - 3s 376us/step - loss: 0.8662\n",
      "Epoch 66/250\n",
      "7796/7796 [==============================] - 3s 388us/step - loss: 0.8532\n",
      "Epoch 67/250\n",
      "7796/7796 [==============================] - 3s 389us/step - loss: 0.8418\n",
      "Epoch 68/250\n",
      "7796/7796 [==============================] - 3s 379us/step - loss: 0.8301\n",
      "Epoch 69/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 0.8189\n",
      "Epoch 70/250\n",
      "7796/7796 [==============================] - 3s 368us/step - loss: 0.8082\n",
      "Epoch 71/250\n",
      "7796/7796 [==============================] - 3s 392us/step - loss: 0.7976\n",
      "Epoch 72/250\n",
      "7796/7796 [==============================] - 3s 351us/step - loss: 0.7878\n",
      "Epoch 73/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 0.7782\n",
      "Epoch 74/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.7682ETA: 0s - l\n",
      "Epoch 75/250\n",
      "7796/7796 [==============================] - 3s 355us/step - loss: 0.7602\n",
      "Epoch 76/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 0.7519\n",
      "Epoch 77/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 0.7432\n",
      "Epoch 78/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.7352\n",
      "Epoch 79/250\n",
      "7796/7796 [==============================] - 3s 370us/step - loss: 0.7280\n",
      "Epoch 80/250\n",
      "7796/7796 [==============================] - 3s 380us/step - loss: 0.7208\n",
      "Epoch 81/250\n",
      "7796/7796 [==============================] - 3s 375us/step - loss: 0.7136\n",
      "Epoch 82/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 0.7064\n",
      "Epoch 83/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.6999\n",
      "Epoch 84/250\n",
      "7796/7796 [==============================] - 3s 385us/step - loss: 0.6932\n",
      "Epoch 85/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.6869\n",
      "Epoch 86/250\n",
      "7796/7796 [==============================] - 3s 368us/step - loss: 0.6808\n",
      "Epoch 87/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 0.6751 0s - loss: 0.67\n",
      "Epoch 88/250\n",
      "7796/7796 [==============================] - 3s 390us/step - loss: 0.6694\n",
      "Epoch 89/250\n",
      "7796/7796 [==============================] - 3s 394us/step - loss: 0.6643\n",
      "Epoch 90/250\n",
      "7796/7796 [==============================] - 3s 378us/step - loss: 0.6590\n",
      "Epoch 91/250\n",
      "7796/7796 [==============================] - 3s 392us/step - loss: 0.6538\n",
      "Epoch 92/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.6489\n",
      "Epoch 93/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 0.6445\n",
      "Epoch 94/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 0.6404\n",
      "Epoch 95/250\n",
      "7796/7796 [==============================] - 3s 368us/step - loss: 0.6359\n",
      "Epoch 96/250\n",
      "7796/7796 [==============================] - 3s 392us/step - loss: 0.6320\n",
      "Epoch 97/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 0.6284\n",
      "Epoch 98/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.6242\n",
      "Epoch 99/250\n",
      "7796/7796 [==============================] - 3s 418us/step - loss: 0.6204\n",
      "Epoch 100/250\n",
      "7796/7796 [==============================] - 4s 459us/step - loss: 0.6171\n",
      "Epoch 101/250\n",
      "7796/7796 [==============================] - 3s 406us/step - loss: 0.6132\n",
      "Epoch 102/250\n",
      "7796/7796 [==============================] - 3s 380us/step - loss: 0.6099\n",
      "Epoch 103/250\n",
      "7796/7796 [==============================] - 3s 393us/step - loss: 0.6065\n",
      "Epoch 104/250\n",
      "7796/7796 [==============================] - 4s 461us/step - loss: 0.6035\n",
      "Epoch 105/250\n",
      "7796/7796 [==============================] - 3s 434us/step - loss: 0.6004\n",
      "Epoch 106/250\n",
      "7796/7796 [==============================] - 4s 451us/step - loss: 0.5972\n",
      "Epoch 107/250\n",
      "7796/7796 [==============================] - 3s 403us/step - loss: 0.5942 0s - loss: 0.\n",
      "Epoch 108/250\n",
      "7796/7796 [==============================] - 3s 420us/step - loss: 0.5914\n",
      "Epoch 109/250\n",
      "7796/7796 [==============================] - 3s 392us/step - loss: 0.5887\n",
      "Epoch 110/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 0.5861\n",
      "Epoch 111/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.5834\n",
      "Epoch 112/250\n",
      "7796/7796 [==============================] - 3s 333us/step - loss: 0.5811\n",
      "Epoch 113/250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7796/7796 [==============================] - 3s 352us/step - loss: 0.5784\n",
      "Epoch 114/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.5756\n",
      "Epoch 115/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.5728\n",
      "Epoch 116/250\n",
      "7796/7796 [==============================] - 3s 338us/step - loss: 0.5708\n",
      "Epoch 117/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.5684\n",
      "Epoch 118/250\n",
      "7796/7796 [==============================] - 3s 340us/step - loss: 0.5664\n",
      "Epoch 119/250\n",
      "7796/7796 [==============================] - 3s 335us/step - loss: 0.5640\n",
      "Epoch 120/250\n",
      "7796/7796 [==============================] - 3s 341us/step - loss: 0.5620\n",
      "Epoch 121/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 0.5604\n",
      "Epoch 122/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 0.5584\n",
      "Epoch 123/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 0.5563\n",
      "Epoch 124/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.5545\n",
      "Epoch 125/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 0.5529\n",
      "Epoch 126/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.5507\n",
      "Epoch 127/250\n",
      "7796/7796 [==============================] - 3s 433us/step - loss: 0.5494\n",
      "Epoch 128/250\n",
      "7796/7796 [==============================] - 3s 422us/step - loss: 0.5478\n",
      "Epoch 129/250\n",
      "7796/7796 [==============================] - 3s 372us/step - loss: 0.5462\n",
      "Epoch 130/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 0.5442\n",
      "Epoch 131/250\n",
      "7796/7796 [==============================] - 3s 346us/step - loss: 0.5432\n",
      "Epoch 132/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.5415\n",
      "Epoch 133/250\n",
      "7796/7796 [==============================] - 3s 381us/step - loss: 0.5398\n",
      "Epoch 134/250\n",
      "7796/7796 [==============================] - 4s 452us/step - loss: 0.5388\n",
      "Epoch 135/250\n",
      "7796/7796 [==============================] - 3s 386us/step - loss: 0.5369\n",
      "Epoch 136/250\n",
      "7796/7796 [==============================] - 3s 367us/step - loss: 0.5355\n",
      "Epoch 137/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.5344\n",
      "Epoch 138/250\n",
      "7796/7796 [==============================] - 3s 365us/step - loss: 0.5330\n",
      "Epoch 139/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.5320\n",
      "Epoch 140/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.5304\n",
      "Epoch 141/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.5296 0s\n",
      "Epoch 142/250\n",
      "7796/7796 [==============================] - 3s 383us/step - loss: 0.5282\n",
      "Epoch 143/250\n",
      "7796/7796 [==============================] - 3s 393us/step - loss: 0.5273\n",
      "Epoch 144/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 0.5260\n",
      "Epoch 145/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.5247 0s - loss: 0.5\n",
      "Epoch 146/250\n",
      "7796/7796 [==============================] - 3s 398us/step - loss: 0.5231\n",
      "Epoch 147/250\n",
      "7796/7796 [==============================] - 3s 383us/step - loss: 0.5228\n",
      "Epoch 148/250\n",
      "7796/7796 [==============================] - 3s 435us/step - loss: 0.5214\n",
      "Epoch 149/250\n",
      "7796/7796 [==============================] - 3s 374us/step - loss: 0.5204\n",
      "Epoch 150/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.5195\n",
      "Epoch 151/250\n",
      "7796/7796 [==============================] - 3s 385us/step - loss: 0.5185\n",
      "Epoch 152/250\n",
      "7796/7796 [==============================] - 4s 451us/step - loss: 0.5174\n",
      "Epoch 153/250\n",
      "7796/7796 [==============================] - 3s 429us/step - loss: 0.5165\n",
      "Epoch 154/250\n",
      "7796/7796 [==============================] - 3s 394us/step - loss: 0.5155\n",
      "Epoch 155/250\n",
      "7796/7796 [==============================] - 3s 382us/step - loss: 0.5145\n",
      "Epoch 156/250\n",
      "7796/7796 [==============================] - 3s 368us/step - loss: 0.5137\n",
      "Epoch 157/250\n",
      "7796/7796 [==============================] - 3s 359us/step - loss: 0.5126\n",
      "Epoch 158/250\n",
      "7796/7796 [==============================] - 3s 350us/step - loss: 0.5119\n",
      "Epoch 159/250\n",
      "7796/7796 [==============================] - 3s 390us/step - loss: 0.5109\n",
      "Epoch 160/250\n",
      "7796/7796 [==============================] - 3s 407us/step - loss: 0.5099\n",
      "Epoch 161/250\n",
      "7796/7796 [==============================] - ETA: 0s - loss: 0.509 - 3s 411us/step - loss: 0.5093\n",
      "Epoch 162/250\n",
      "7796/7796 [==============================] - 3s 426us/step - loss: 0.5085\n",
      "Epoch 163/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.5079\n",
      "Epoch 164/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.5067\n",
      "Epoch 165/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.5062\n",
      "Epoch 166/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.5053\n",
      "Epoch 167/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.5047\n",
      "Epoch 168/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.5036\n",
      "Epoch 169/250\n",
      "7796/7796 [==============================] - 3s 387us/step - loss: 0.5031\n",
      "Epoch 170/250\n",
      "7796/7796 [==============================] - 3s 406us/step - loss: 0.5022 0s - los\n",
      "Epoch 171/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.5012\n",
      "Epoch 172/250\n",
      "7796/7796 [==============================] - 3s 401us/step - loss: 0.5009\n",
      "Epoch 173/250\n",
      "7796/7796 [==============================] - 3s 399us/step - loss: 0.5003\n",
      "Epoch 174/250\n",
      "7796/7796 [==============================] - 3s 418us/step - loss: 0.4991\n",
      "Epoch 175/250\n",
      "7796/7796 [==============================] - 3s 364us/step - loss: 0.4990 0s - loss: 0\n",
      "Epoch 176/250\n",
      "7796/7796 [==============================] - 3s 404us/step - loss: 0.4982\n",
      "Epoch 177/250\n",
      "7796/7796 [==============================] - 3s 358us/step - loss: 0.4976\n",
      "Epoch 178/250\n",
      "7796/7796 [==============================] - 3s 434us/step - loss: 0.4968\n",
      "Epoch 179/250\n",
      "7796/7796 [==============================] - 3s 408us/step - loss: 0.4964\n",
      "Epoch 180/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.4957\n",
      "Epoch 181/250\n",
      "7796/7796 [==============================] - 4s 459us/step - loss: 0.4951\n",
      "Epoch 182/250\n",
      "7796/7796 [==============================] - 3s 419us/step - loss: 0.4945\n",
      "Epoch 183/250\n",
      "7796/7796 [==============================] - 3s 425us/step - loss: 0.4937\n",
      "Epoch 184/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.4935\n",
      "Epoch 185/250\n",
      "7796/7796 [==============================] - 3s 417us/step - loss: 0.4928\n",
      "Epoch 186/250\n",
      "7796/7796 [==============================] - 3s 416us/step - loss: 0.4919\n",
      "Epoch 187/250\n",
      "7796/7796 [==============================] - 3s 409us/step - loss: 0.4916\n",
      "Epoch 188/250\n",
      "7796/7796 [==============================] - 3s 366us/step - loss: 0.4912\n",
      "Epoch 189/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.4907\n",
      "Epoch 190/250\n",
      "7796/7796 [==============================] - 3s 354us/step - loss: 0.4901\n",
      "Epoch 191/250\n",
      "7796/7796 [==============================] - 3s 355us/step - loss: 0.4899\n",
      "Epoch 192/250\n",
      "7796/7796 [==============================] - 3s 440us/step - loss: 0.4892\n",
      "Epoch 193/250\n",
      "7796/7796 [==============================] - 3s 382us/step - loss: 0.4885\n",
      "Epoch 194/250\n",
      "7796/7796 [==============================] - 3s 362us/step - loss: 0.4879\n",
      "Epoch 195/250\n",
      "7796/7796 [==============================] - 3s 361us/step - loss: 0.4873\n",
      "Epoch 196/250\n",
      "7796/7796 [==============================] - 3s 408us/step - loss: 0.4873\n",
      "Epoch 197/250\n",
      "7796/7796 [==============================] - 3s 405us/step - loss: 0.4863\n",
      "Epoch 198/250\n",
      "7796/7796 [==============================] - 3s 394us/step - loss: 0.4862\n",
      "Epoch 199/250\n",
      "7796/7796 [==============================] - 3s 394us/step - loss: 0.4856\n",
      "Epoch 200/250\n",
      "7796/7796 [==============================] - 4s 482us/step - loss: 0.4853\n",
      "Epoch 201/250\n",
      "7796/7796 [==============================] - 3s 404us/step - loss: 0.4846\n",
      "Epoch 202/250\n",
      "7796/7796 [==============================] - 3s 432us/step - loss: 0.4842\n",
      "Epoch 203/250\n",
      "7796/7796 [==============================] - 3s 426us/step - loss: 0.4837 0s -\n",
      "Epoch 204/250\n",
      "7796/7796 [==============================] - 3s 406us/step - loss: 0.4832\n",
      "Epoch 205/250\n",
      "7796/7796 [==============================] - 3s 380us/step - loss: 0.4830\n",
      "Epoch 206/250\n",
      "7796/7796 [==============================] - 3s 376us/step - loss: 0.4824\n",
      "Epoch 207/250\n",
      "7796/7796 [==============================] - 3s 368us/step - loss: 0.4821\n",
      "Epoch 208/250\n",
      "7796/7796 [==============================] - 3s 377us/step - loss: 0.4816\n",
      "Epoch 209/250\n",
      "7796/7796 [==============================] - 3s 401us/step - loss: 0.4812\n",
      "Epoch 210/250\n",
      "7796/7796 [==============================] - 3s 418us/step - loss: 0.4807\n",
      "Epoch 211/250\n",
      "7796/7796 [==============================] - 4s 452us/step - loss: 0.4806 0s\n",
      "Epoch 212/250\n",
      "7796/7796 [==============================] - 3s 436us/step - loss: 0.4800\n",
      "Epoch 213/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.4795\n",
      "Epoch 214/250\n",
      "7796/7796 [==============================] - 3s 349us/step - loss: 0.4791\n",
      "Epoch 215/250\n",
      "7796/7796 [==============================] - 3s 336us/step - loss: 0.4788\n",
      "Epoch 216/250\n",
      "7796/7796 [==============================] - 3s 344us/step - loss: 0.4786\n",
      "Epoch 217/250\n",
      "7796/7796 [==============================] - 3s 363us/step - loss: 0.4781\n",
      "Epoch 218/250\n",
      "7796/7796 [==============================] - 3s 339us/step - loss: 0.4775\n",
      "Epoch 219/250\n",
      "7796/7796 [==============================] - 3s 381us/step - loss: 0.4771\n",
      "Epoch 220/250\n",
      "7796/7796 [==============================] - 3s 414us/step - loss: 0.4770\n",
      "Epoch 221/250\n",
      "7796/7796 [==============================] - 3s 402us/step - loss: 0.4766\n",
      "Epoch 222/250\n",
      "7796/7796 [==============================] - 3s 386us/step - loss: 0.4759\n",
      "Epoch 223/250\n",
      "7796/7796 [==============================] - 3s 374us/step - loss: 0.4758\n",
      "Epoch 224/250\n",
      "7796/7796 [==============================] - 3s 373us/step - loss: 0.4753\n",
      "Epoch 225/250\n",
      "7796/7796 [==============================] - 3s 407us/step - loss: 0.4748\n",
      "Epoch 226/250\n",
      "7796/7796 [==============================] - 3s 403us/step - loss: 0.4747\n",
      "Epoch 227/250\n",
      "7796/7796 [==============================] - 4s 456us/step - loss: 0.4743\n",
      "Epoch 228/250\n",
      "7796/7796 [==============================] - 4s 462us/step - loss: 0.4737\n",
      "Epoch 229/250\n",
      "7796/7796 [==============================] - 4s 484us/step - loss: 0.4734\n",
      "Epoch 230/250\n",
      "7796/7796 [==============================] - 4s 470us/step - loss: 0.4731\n",
      "Epoch 231/250\n",
      "7796/7796 [==============================] - 4s 520us/step - loss: 0.4729\n",
      "Epoch 232/250\n",
      "7796/7796 [==============================] - 4s 450us/step - loss: 0.4723\n",
      "Epoch 233/250\n",
      "7796/7796 [==============================] - 3s 384us/step - loss: 0.4722\n",
      "Epoch 234/250\n",
      "7796/7796 [==============================] - 3s 430us/step - loss: 0.4716 0s - loss: 0.469\n",
      "Epoch 235/250\n",
      "7796/7796 [==============================] - 3s 446us/step - loss: 0.4716\n",
      "Epoch 236/250\n",
      "7796/7796 [==============================] - 3s 404us/step - loss: 0.4712\n",
      "Epoch 237/250\n",
      "7796/7796 [==============================] - 4s 452us/step - loss: 0.4706\n",
      "Epoch 238/250\n",
      "7796/7796 [==============================] - 3s 360us/step - loss: 0.4705\n",
      "Epoch 239/250\n",
      "7796/7796 [==============================] - 3s 337us/step - loss: 0.4702\n",
      "Epoch 240/250\n",
      "7796/7796 [==============================] - 3s 356us/step - loss: 0.4700\n",
      "Epoch 241/250\n",
      "7796/7796 [==============================] - 3s 371us/step - loss: 0.4695\n",
      "Epoch 242/250\n",
      "7796/7796 [==============================] - 3s 388us/step - loss: 0.4690\n",
      "Epoch 243/250\n",
      "7796/7796 [==============================] - 3s 446us/step - loss: 0.4692\n",
      "Epoch 244/250\n",
      "7796/7796 [==============================] - 4s 454us/step - loss: 0.4687\n",
      "Epoch 245/250\n",
      "7796/7796 [==============================] - 3s 347us/step - loss: 0.4682\n",
      "Epoch 246/250\n",
      "7796/7796 [==============================] - 3s 379us/step - loss: 0.4680\n",
      "Epoch 247/250\n",
      "7796/7796 [==============================] - 3s 382us/step - loss: 0.4678\n",
      "Epoch 248/250\n",
      "7796/7796 [==============================] - 3s 369us/step - loss: 0.4675 0s -\n",
      "Epoch 249/250\n",
      "7796/7796 [==============================] - 4s 452us/step - loss: 0.4668\n",
      "Epoch 250/250\n",
      "7796/7796 [==============================] - 4s 457us/step - loss: 0.4668\n",
      "1949/1949 [==============================] - 0s 237us/step\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xm = X_train_scaled.values\n",
    "ym = y_train\n",
    "kf = KFold(n_splits=5)\n",
    "kf.get_n_splits(Xm)\n",
    "cvscores = []\n",
    "for i, (train, val) in enumerate(kf.split(Xm)):\n",
    "    model = Sequential()\n",
    "    ...#la regularization se debe incorporar a cada capa separadamente\n",
    "    moptimizer = Adadelta(lr=0.01)\n",
    "    idim=X_train_scaled.shape[1]\n",
    "    model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform',W_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('linear'))\n",
    "    model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "    model.fit(Xm[train], ym[train], epochs=250)\n",
    "    ...# evaluate the model\n",
    "    scores = model.evaluate(Xm[val], ym[val])\n",
    "    cvscores.append(scores)\n",
    "mse_cv = np.mean(cvscores)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.4115317242001191,\n",
       " 0.3742644849069428,\n",
       " 0.8357612235751625,\n",
       " 0.5041005475329031,\n",
       " 0.4887298948646142]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cvscores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=text-justify> En la parte superior obtenemos los resultados de los scores de <b>K=5</b> validaciones con sus respectivos modelos generados, es importante resaltar que en la mayoría de los modelos tuvimos un <b>Accuracy</b> promedio de 50, y en un modelo el tercero para ser mas específico tuvimos un <b>score</b> de 83, lo que nos indica que hay una buena relación de datos, pero que también hay una combinación que en el momento del entrenamiento puede ayudar mucho más para la optimización de nuestra red.\n",
    "    </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xm = X_train_scaled.values\n",
    "ym = y_train\n",
    "kf = KFold(n_splits=10)\n",
    "kf.get_n_splits(Xm)\n",
    "cvscores = []\n",
    "for i, (train, val) in enumerate(kf.split(Xm)):\n",
    "    model = Sequential()\n",
    "    ...#la regularization se debe incorporar a cada capa separadamente\n",
    "    moptimizer = Adadelta(lr=0.01)\n",
    "    idim=X_train_scaled.shape[1]\n",
    "    model.add(Dense(256,input_dim=idim,kernel_initializer='uniform',W_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('sigmoid'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform',W_regularizer=regularizers.l2(0.01)))\n",
    "    model.add(Activation('linear'))\n",
    "    model.compile(optimizer=moptimizer,loss='mean_squared_error')\n",
    "    model.fit(Xm[train], ym[train], epochs=250)\n",
    "    ...# evaluate the model\n",
    "    scores = model.evaluate(Xm[val], ym[val])\n",
    "    cvscores.append(scores)\n",
    "mse_cv = np.mean(cvscores)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
